{
    "docs": [
        {
            "location": "/",
            "text": "o2r web API documentation\n\n\n\n\nCurrent version of the API\n: \nv1\n\n\nAbout\n\n\nThe o2r web API acts as the interface between the \no2r\n \nmicroservices\n and the \nweb interface\n.\n\n\nThe API provides services around the executable research compendium (ERC), or \"compendium\" for short, which is documented \nin the ERC spec\n.\n\n\nGeneral notes\n\n\nThe API is implemented as a \nREST\nful API. The entrypoint for the current version is \n/api/v1\n.\n\n\nUnless specified otherwise, responses are always in JSON format.\nBody parameters in \nPOST\n requests are expected in \nmultipart/form-data\n format.\nRequests to the API should always be made with a secure connection using \nHTTPS\n.\nSome requests require \nauthentication\n with a specific \nuser level\n.\n\n\nWe also provide a \nsimple Postman collection\n (\ngetpostman.com\n), so that you can comfortably explore the API.\n\n\nLicense\n\n\n\n\nThe o2r Executable Research Compendium specification is licensed under \nCreative Commons CC0 1.0 Universal License\n, see file \nLICENSE\n.\nTo the extent possible under law, the people who associated CC0 with this work have waived all copyright and related or neighboring rights to this work.\nThis work is published from: Germany.",
            "title": "Home"
        },
        {
            "location": "/#o2r-web-api-documentation",
            "text": "Current version of the API :  v1",
            "title": "o2r web API documentation"
        },
        {
            "location": "/#about",
            "text": "The o2r web API acts as the interface between the  o2r   microservices  and the  web interface .  The API provides services around the executable research compendium (ERC), or \"compendium\" for short, which is documented  in the ERC spec .",
            "title": "About"
        },
        {
            "location": "/#general-notes",
            "text": "The API is implemented as a  REST ful API. The entrypoint for the current version is  /api/v1 .  Unless specified otherwise, responses are always in JSON format.\nBody parameters in  POST  requests are expected in  multipart/form-data  format.\nRequests to the API should always be made with a secure connection using  HTTPS .\nSome requests require  authentication  with a specific  user level .  We also provide a  simple Postman collection  ( getpostman.com ), so that you can comfortably explore the API.",
            "title": "General notes"
        },
        {
            "location": "/#license",
            "text": "The o2r Executable Research Compendium specification is licensed under  Creative Commons CC0 1.0 Universal License , see file  LICENSE .\nTo the extent possible under law, the people who associated CC0 with this work have waived all copyright and related or neighboring rights to this work.\nThis work is published from: Germany.",
            "title": "License"
        },
        {
            "location": "/compendium/upload/",
            "text": "Upload via API\n\n\nUpload a research compendium as a compressed \n.zip\n archive with an HTTP \nPOST\n request using \nmultipart/form-data\n.\n\n\nThe upload is only allowed for logged in users.\nTo run the upload from the command line, you must login on the website and inspect your browser's cookies.\nFind a cookie issued by \no2r.uni-muenster.de\n with the name \nconnect.sid\n.\nProvide the content of the cookie when making requests to the API as shown in the request example below.\n\n\nUpon successful extraction of archive and processing of the contents, the \nid\n for the new compendium is returned.\n\n\n\n\nRequired user level\n\n\nThe user creating a new compendium must have the required \nuser level\n.\n\n\n\n\ncurl -F \"compendium=@compendium.zip;type=application/zip\" \\\n    -F content_type=compendium https://\u2026/api/v1/compendium \\\n    --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/compendium \n\n\n\n\n200 OK\n\n{\"id\":\"a4Ndl\"}\n\n\n\n\n\n\nImportant\n\n\nAfter successful load from a public share, the \ncandidate process\n applies.\n\n\n\n\nBody parameters for compendium upload\n\n\n\n\ncompendium\n - The archive file\n\n\ncontent_type\n - Form of archive. One of the following:\n\n\ncompendium\n - compendium, which is expected to be complete and valid, for \nexamination\n of a compendium\n\n\nworkspace\n - formless workspace, for \ncreation\n of a compendium\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nIf a complete ERC is submitted as a workspace, it may result in an error, or the contained metadata and other files may be overwritten by the creation process.\n\n\n\n\nError responses for compendium upload\n\n\n400 Bad Request\n\n{\"error\":\"provided content_type not implemented\"}\n\n\n\n\n401 Unauthorized\n\n{\"error\":\"user is not authenticated\"}\n\n\n\n\n401 Unauthorized\n\n{\"error\":\"user level does not allow compendium creation\"}\n\n\n\n\n```json\n422 Unprocessable Entity\n\n\nFor local testing you can quickly upload some of the example compendia and workspaces from the \nerc-examples\n project.",
            "title": "API upload"
        },
        {
            "location": "/compendium/upload/#upload-via-api",
            "text": "Upload a research compendium as a compressed  .zip  archive with an HTTP  POST  request using  multipart/form-data .  The upload is only allowed for logged in users.\nTo run the upload from the command line, you must login on the website and inspect your browser's cookies.\nFind a cookie issued by  o2r.uni-muenster.de  with the name  connect.sid .\nProvide the content of the cookie when making requests to the API as shown in the request example below.  Upon successful extraction of archive and processing of the contents, the  id  for the new compendium is returned.   Required user level  The user creating a new compendium must have the required  user level .   curl -F \"compendium=@compendium.zip;type=application/zip\" \\\n    -F content_type=compendium https://\u2026/api/v1/compendium \\\n    --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/compendium   200 OK\n\n{\"id\":\"a4Ndl\"}   Important  After successful load from a public share, the  candidate process  applies.",
            "title": "Upload via API"
        },
        {
            "location": "/compendium/upload/#body-parameters-for-compendium-upload",
            "text": "compendium  - The archive file  content_type  - Form of archive. One of the following:  compendium  - compendium, which is expected to be complete and valid, for  examination  of a compendium  workspace  - formless workspace, for  creation  of a compendium      Warning  If a complete ERC is submitted as a workspace, it may result in an error, or the contained metadata and other files may be overwritten by the creation process.",
            "title": "Body parameters for compendium upload"
        },
        {
            "location": "/compendium/upload/#error-responses-for-compendium-upload",
            "text": "400 Bad Request\n\n{\"error\":\"provided content_type not implemented\"}  401 Unauthorized\n\n{\"error\":\"user is not authenticated\"}  401 Unauthorized\n\n{\"error\":\"user level does not allow compendium creation\"}  ```json\n422 Unprocessable Entity  For local testing you can quickly upload some of the example compendia and workspaces from the  erc-examples  project.",
            "title": "Error responses for compendium upload"
        },
        {
            "location": "/compendium/public_share/",
            "text": "Public share\n\n\nLoad a research compendium by submitting a link to a cloud resource using an HTTP \nPOST\n request using \nmultipart/form-data\n.\n\n\nCurrently, the following repositories are supported:\n\n\n\n\nSciebo\n\n\nZenodo\n\n\nZenodo Sandbox\n\n\n\n\nCommon\n\n\nAll repositories use the same API endpoint \nhttps://\u2026/api/v1/compendium\n, but with different required/optional parameters.\n\n\nThe upload is only allowed for logged in users.\nTo run the upload from the command line, login on the website and open you browser cookies.\nFind a cookie issued by \no2r.uni-muenster.de\n with the name \nconnect.sid\n.\nCopy the contents of the cookie into the request example below.\n\n\n\n\nRequired user level\n\n\nThe user creating a new compendium must have the required \nuser level\n.\n\n\n\n\nTo run the load from the command line, login on the website and open you browser cookies.\nFind a cookie issued by \no2r.uni-muenster.de\n with the name \nconnect.sid\n.\nCopy the contents of the cookie into the request example below.\n\n\nUpon successful download from the public share, the \nid\n for the new compendium is returned.\n\n\ncurl -F \"content_type=compendium\" \\\n    -F \"share_url=https://uni-muenster.sciebo.de/index.php/s/G8vxQ1h50V4HpuA\"  \\\n    --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/compendium\n\n\n\n\n200 OK\n\n{\"id\":\"b9Faz\"}\n\n\n\n\n\n\nImportant\n\n\nAfter successful load from a public share, the \ncandidate process\n applies.\n\n\n\n\nSciebo\n\n\nSciebo\n is a cloud storage service at North Rhine-Westphalian universities.\nAlthough it builds on ownCloud and the implementation might be able to handle any ownCloud link, only Sciebo's publish shares are supported by this API. \n\n\nFile selection\n\n\nDepending on the public share contents different processes are triggered:\n\n\n\n\nIf a file named \nbagit.txt\n is found, the directory will checked for Bagit validity\n\n\nIf a single zip file is found, the file will be extracted, if multiple zip files are found, an error is returned.\n\n\nIf a single subdirectory is found, the loader will use that subdirectory\n\n\nDepending on the value of \ncontent_type\n (see below), the public share contents are treated as a complete compendium or as a  workspace\n\n\n\n\nBody parameters for creating compendium from public share\n\n\n\n\nshare_url\n - The Sciebo link to the public share (required)\n\n\ncontent_type\n - Form of archive. One of the following (required):\n\n\ncompendium\n - complete compendium\n\n\nworkspace\n - formless workspace\n\n\n\n\n\n\npath\n - Path to a subdirectory in the public share (optional)\n\n\ndefault is \n/\n\n\n\n\n\n\n\n\nExamples\n\n\ncurl -F \"content_type=compendium\" \\\n    -F \"share_url=https://uni-muenster.sciebo.de/index.php/s/G8vxQ1h50V4HpuA\"  \\\n    -F \"path=/metatainer\" \\\n    --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/compendium\n\n\n\n\nError responses for creating compendium from public share\n\n\n401 Unauthorized\n\n{\"error\":\"unauthorized: user level does not allow compendium creation\"}\n\n\n\n\n403 Forbidden\n\n{\"error\":\"public share host is not allowed\"}\n\n\n\n\n422 Unprocessable Entity\n\n{\"error\":\"files with unsupported encoding detected: [{'file':'/tmp/o2r/compendium/ejpmi/data/test.txt','encoding':'Shift_JIS'}]\"}\n\n\n\n\nExample data\n\n\nFor testing purposes you can use the following public share, which contains a few ready-to-use compendia:\n\n\nhttps://uni-muenster.sciebo.de/index.php/s/7EoWgjLSFVV89AO\n\n\nZenodo\n\n\nBody parameters for creating a compendium from a Zenodo record\n\n\n\n\nIdentification of the Zenodo record, one of the folloing is required:\n\n\nshare_url\n - The link to the zenodo record (optional). May be a link to https://zenodo.org or https://doi.org\n\n\ndoi\n - A \nDOI\n resolving to the zenodo record (optional)\n\n\nzenodo_record_id\n - The ID of the zenodo record (optional)\n\n\n\n\n\n\ncontent_type\n - Form of archive. One of the following (required):\n\n\ncompendium\n - complete compendium for \ninspection\n\n\nworkspace\n - formless workspace for \ncreation\n\n\n\n\n\n\nfilename\n - Filename of your compendium. For now, only zip-files are supported. (optional)\n\n\nif no \nfilename\n is provided the first zip file is selected\n\n\nmultiple files are currently not supported\n\n\n\n\n\n\n\n\nThere must at least one url parameter that resolves to a zenodo record. I.e. one of the following:\n\n\nExamples\n\n\n\n\nZenodo Record URL (with optional filename parameter)\n\n\n\n\ncurl -F \"content_type=compendium\" \\\n    -F \"zenodo_url=https://sandbox.zenodo.org/record/69114\"  \\\n    -F \"filename=metatainer.zip\" \\\n    --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/compendium\n\n\n\n\n\n\nDOI\n\n\n\n\ncurl -F \"content_type=compendium\" \\\n    -F \"doi=10.5072/zenodo.69114\"  \\\n    --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/compendium\n\n\n\n\n\n\nZenodo Record ID\n\n\n\n\ncurl -F \"content_type=compendium\" \\\n    -F \"zenodo_record_id=69114\"  \\\n    --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/compendium\n\n\n\n\nIf the Zenodo record id is supplied through the \ndoi\n or \nzenodo_record_id\n parameter, or if the \nshare_url\n parameter is a \ndoi.org\n URL, a default base URL for the file download is used as selected by the API maintainer. This may be:\n\n\n\n\nhttps://zenodo.org\n or\n\n\nhttps://sandbox.zenodo.org\n\n\n\n\nError responses for creating compendium from a Zenodo record\n\n\n401 Unauthorized\n\n{\"error\":\"unauthorized: user level does not allow compendium creation\"}\n\n\n\n\n403 Forbidden\n\n{\"error\":\"host is not allowed\"}\n\n\n\n\n422 Unprocessable Entity\n\n{\"error\":\"public share URL is invalid\"}\n\n\n\n\n422 Unprocessable Entity\n\n{\"error\":\"DOI is invalid\"}\n\n\n\n\n422 Unprocessable Entity\n\n{\"error\":\"files with unsupported encoding detected: [{'file':'/tmp/o2r/compendium/ejpmi/data/test.txt','encoding':'Shift_JIS'}]\"}\n\n\n\n\nExample data\n\n\nFor testing purposes you can use the following public shares.\nThey contain the a compendium with metadata.\n\n\n\n\nSciebo: \nhttps://uni-muenster.sciebo.de/index.php/s/G8vxQ1h50V4HpuA\n\n\nZenodo: \nhttps://sandbox.zenodo.org/record/69114",
            "title": "Public share submission"
        },
        {
            "location": "/compendium/public_share/#public-share",
            "text": "Load a research compendium by submitting a link to a cloud resource using an HTTP  POST  request using  multipart/form-data .  Currently, the following repositories are supported:   Sciebo  Zenodo  Zenodo Sandbox",
            "title": "Public share"
        },
        {
            "location": "/compendium/public_share/#common",
            "text": "All repositories use the same API endpoint  https://\u2026/api/v1/compendium , but with different required/optional parameters.  The upload is only allowed for logged in users.\nTo run the upload from the command line, login on the website and open you browser cookies.\nFind a cookie issued by  o2r.uni-muenster.de  with the name  connect.sid .\nCopy the contents of the cookie into the request example below.   Required user level  The user creating a new compendium must have the required  user level .   To run the load from the command line, login on the website and open you browser cookies.\nFind a cookie issued by  o2r.uni-muenster.de  with the name  connect.sid .\nCopy the contents of the cookie into the request example below.  Upon successful download from the public share, the  id  for the new compendium is returned.  curl -F \"content_type=compendium\" \\\n    -F \"share_url=https://uni-muenster.sciebo.de/index.php/s/G8vxQ1h50V4HpuA\"  \\\n    --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/compendium  200 OK\n\n{\"id\":\"b9Faz\"}   Important  After successful load from a public share, the  candidate process  applies.",
            "title": "Common"
        },
        {
            "location": "/compendium/public_share/#sciebo",
            "text": "Sciebo  is a cloud storage service at North Rhine-Westphalian universities.\nAlthough it builds on ownCloud and the implementation might be able to handle any ownCloud link, only Sciebo's publish shares are supported by this API.",
            "title": "Sciebo"
        },
        {
            "location": "/compendium/public_share/#file-selection",
            "text": "Depending on the public share contents different processes are triggered:   If a file named  bagit.txt  is found, the directory will checked for Bagit validity  If a single zip file is found, the file will be extracted, if multiple zip files are found, an error is returned.  If a single subdirectory is found, the loader will use that subdirectory  Depending on the value of  content_type  (see below), the public share contents are treated as a complete compendium or as a  workspace",
            "title": "File selection"
        },
        {
            "location": "/compendium/public_share/#body-parameters-for-creating-compendium-from-public-share",
            "text": "share_url  - The Sciebo link to the public share (required)  content_type  - Form of archive. One of the following (required):  compendium  - complete compendium  workspace  - formless workspace    path  - Path to a subdirectory in the public share (optional)  default is  /",
            "title": "Body parameters for creating compendium from public share"
        },
        {
            "location": "/compendium/public_share/#examples",
            "text": "curl -F \"content_type=compendium\" \\\n    -F \"share_url=https://uni-muenster.sciebo.de/index.php/s/G8vxQ1h50V4HpuA\"  \\\n    -F \"path=/metatainer\" \\\n    --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/compendium",
            "title": "Examples"
        },
        {
            "location": "/compendium/public_share/#error-responses-for-creating-compendium-from-public-share",
            "text": "401 Unauthorized\n\n{\"error\":\"unauthorized: user level does not allow compendium creation\"}  403 Forbidden\n\n{\"error\":\"public share host is not allowed\"}  422 Unprocessable Entity\n\n{\"error\":\"files with unsupported encoding detected: [{'file':'/tmp/o2r/compendium/ejpmi/data/test.txt','encoding':'Shift_JIS'}]\"}",
            "title": "Error responses for creating compendium from public share"
        },
        {
            "location": "/compendium/public_share/#example-data",
            "text": "For testing purposes you can use the following public share, which contains a few ready-to-use compendia:  https://uni-muenster.sciebo.de/index.php/s/7EoWgjLSFVV89AO",
            "title": "Example data"
        },
        {
            "location": "/compendium/public_share/#zenodo",
            "text": "",
            "title": "Zenodo"
        },
        {
            "location": "/compendium/public_share/#body-parameters-for-creating-a-compendium-from-a-zenodo-record",
            "text": "Identification of the Zenodo record, one of the folloing is required:  share_url  - The link to the zenodo record (optional). May be a link to https://zenodo.org or https://doi.org  doi  - A  DOI  resolving to the zenodo record (optional)  zenodo_record_id  - The ID of the zenodo record (optional)    content_type  - Form of archive. One of the following (required):  compendium  - complete compendium for  inspection  workspace  - formless workspace for  creation    filename  - Filename of your compendium. For now, only zip-files are supported. (optional)  if no  filename  is provided the first zip file is selected  multiple files are currently not supported     There must at least one url parameter that resolves to a zenodo record. I.e. one of the following:",
            "title": "Body parameters for creating a compendium from a Zenodo record"
        },
        {
            "location": "/compendium/public_share/#examples_1",
            "text": "Zenodo Record URL (with optional filename parameter)   curl -F \"content_type=compendium\" \\\n    -F \"zenodo_url=https://sandbox.zenodo.org/record/69114\"  \\\n    -F \"filename=metatainer.zip\" \\\n    --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/compendium   DOI   curl -F \"content_type=compendium\" \\\n    -F \"doi=10.5072/zenodo.69114\"  \\\n    --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/compendium   Zenodo Record ID   curl -F \"content_type=compendium\" \\\n    -F \"zenodo_record_id=69114\"  \\\n    --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/compendium  If the Zenodo record id is supplied through the  doi  or  zenodo_record_id  parameter, or if the  share_url  parameter is a  doi.org  URL, a default base URL for the file download is used as selected by the API maintainer. This may be:   https://zenodo.org  or  https://sandbox.zenodo.org",
            "title": "Examples"
        },
        {
            "location": "/compendium/public_share/#error-responses-for-creating-compendium-from-a-zenodo-record",
            "text": "401 Unauthorized\n\n{\"error\":\"unauthorized: user level does not allow compendium creation\"}  403 Forbidden\n\n{\"error\":\"host is not allowed\"}  422 Unprocessable Entity\n\n{\"error\":\"public share URL is invalid\"}  422 Unprocessable Entity\n\n{\"error\":\"DOI is invalid\"}  422 Unprocessable Entity\n\n{\"error\":\"files with unsupported encoding detected: [{'file':'/tmp/o2r/compendium/ejpmi/data/test.txt','encoding':'Shift_JIS'}]\"}",
            "title": "Error responses for creating compendium from a Zenodo record"
        },
        {
            "location": "/compendium/public_share/#example-data_1",
            "text": "For testing purposes you can use the following public shares.\nThey contain the a compendium with metadata.   Sciebo:  https://uni-muenster.sciebo.de/index.php/s/G8vxQ1h50V4HpuA  Zenodo:  https://sandbox.zenodo.org/record/69114",
            "title": "Example data"
        },
        {
            "location": "/compendium/candidate/",
            "text": "Candidate process\n\n\nAfter uploading a compendium is \nnot\n instantly publicly available.\nIt is merely a \ncandidate\n, because metadata still must be completed for the compendium to be valid.\n\n\nThe following process models this intermediate state of a compendium.\n\n\nCreation and view\n\n\nCandidates can be identified by the property \ncandidate\n.\nIt is set to \ntrue\n after creating a new compendium by \nupload\n or \npublic share submission\n \nand\n the authoring user having reviewed the metadata.\n\n\n\n\nNote\n\n\nIt is not possible to circumvent the metadata review.\nOnly a successful \nmetadata update\n can set \ncandidate: true\n.\n\n\n\n\nExample:\n\n\n{\n  \"id\":\"12345\",\n  \"metadata\": \u2026 ,\n  \"created\": \"2016-08-01T13:57:40.760Z\",\n  \"files\": \u2026,\n  \"candidate\": true\n}\n\n\n\n\nOnly the creating user and users with \nrequired level\n can view a candidate and see the \ncandidate\n property while it is \ntrue\n.\n\n\nWhen accessing a \nlist of compendia\n for a specific user \nas that user\n, then this list will be extended by available candidates.\nThe candidates may be added to the response independently from any pagination settings, i.e. if a client requests the first 10 compendia for a user having two candidates, the client should be prepared to handle 12 items in the response.\n\n\nMetadata review and saving\n\n\nAfter the user has reviewed and potentially updated the metadata as required and \nsaved them\n successfully, then the candidate status is changed (\ncandidate: false\n) and the compendium is publicly available.\n\n\nThe \ncandidate\n property is not exposed any more if it is \nfalse\n.\n\n\nIt is \nnot\n possible to save invalid metadata or to manually change the \ncandidate\n property, therefore a compendium cannot become a candidate again after successful completion of the creation.\n\n\nDeletion\n\n\nUnlike published compendia, a candidate can be deleted by a the authoring user, see \ndelete compendium\n.",
            "title": "Candidates"
        },
        {
            "location": "/compendium/candidate/#candidate-process",
            "text": "After uploading a compendium is  not  instantly publicly available.\nIt is merely a  candidate , because metadata still must be completed for the compendium to be valid.  The following process models this intermediate state of a compendium.",
            "title": "Candidate process"
        },
        {
            "location": "/compendium/candidate/#creation-and-view",
            "text": "Candidates can be identified by the property  candidate .\nIt is set to  true  after creating a new compendium by  upload  or  public share submission   and  the authoring user having reviewed the metadata.   Note  It is not possible to circumvent the metadata review.\nOnly a successful  metadata update  can set  candidate: true .   Example:  {\n  \"id\":\"12345\",\n  \"metadata\": \u2026 ,\n  \"created\": \"2016-08-01T13:57:40.760Z\",\n  \"files\": \u2026,\n  \"candidate\": true\n}  Only the creating user and users with  required level  can view a candidate and see the  candidate  property while it is  true .  When accessing a  list of compendia  for a specific user  as that user , then this list will be extended by available candidates.\nThe candidates may be added to the response independently from any pagination settings, i.e. if a client requests the first 10 compendia for a user having two candidates, the client should be prepared to handle 12 items in the response.",
            "title": "Creation and view"
        },
        {
            "location": "/compendium/candidate/#metadata-review-and-saving",
            "text": "After the user has reviewed and potentially updated the metadata as required and  saved them  successfully, then the candidate status is changed ( candidate: false ) and the compendium is publicly available.  The  candidate  property is not exposed any more if it is  false .  It is  not  possible to save invalid metadata or to manually change the  candidate  property, therefore a compendium cannot become a candidate again after successful completion of the creation.",
            "title": "Metadata review and saving"
        },
        {
            "location": "/compendium/candidate/#deletion",
            "text": "Unlike published compendia, a candidate can be deleted by a the authoring user, see  delete compendium .",
            "title": "Deletion"
        },
        {
            "location": "/compendium/view/",
            "text": "View compendium\n\n\nList compendia\n\n\nWill return up to 100 results by default.\n\n\ncurl https://\u2026/api/v1/compendium?limit=100&start=2\n\n\nGET /api/v1/compendium?limit=100&start=2\n\n\n200 OK\n\n{\n  \"results\":[\n    \"nkm4b\",\n    \"asdis\",\n    \"nb2sm\",\n    \u2026\n  ]\n}\n\n\n\n\nYou can also filter the results:\n\n\n\n\nFilter by \nuser\n:\n\n\n\n\ncurl https://\u2026/api/v1/compendium?user=0000-0001-6021-1617\n\n\nGET /api/v1/compendium?user=0000-0001-6021-1617\n\n\n\n\nFilter by \ndoi\n:\n\n\n\n\ncurl https://\u2026/api/v1/compendium?doi=10.9999%2Ftest\n\n\nGET /api/v1/compendium?doi=10.9999%2Ftest\n\n\n200 OK\n\n{\n  \"results\":[\n    \"nkm4b\",\n    \"nb2sm\"\n  ]\n}\n\n\n\n\nURL parameters for compendium lists\n\n\n\n\njob_id\n - Comma-separated list of related job ids to filter by.\n\n\nuser\n - Public user identifier to filter by.\n\n\ndoi\n - A \nDOI\n to filter by.\n\n\nstart\n - Starting point of the result list. \nstart - 1\n results are skipped. Defaults to \n1\n.\n\n\nlimit\n - Limits the number of results in the response. Defaults to \n100\n.\n\n\n\n\nError responses for compendium lists\n\n\n404 Not Found\n\n{\"error\":\"no compendium found\"}\n\n\n\n\nView single compendium\n\n\nThis includes the complete metadata set, related job ids and a tree representation of the included \nfiles\n. The \ncreated\n timestamp refers to the upload of the compendium. It is formated as ISO8601.\n\n\ncurl https://\u2026/api/v1/$ID\n\n\nGET /api/v1/compendium/:id\n\n\n200 OK\n\n{\n  \"id\":\"comid\",\n  \"metadata\": \u2026 ,\n  \"created\": \"2016-08-01T13:57:40.760Z\",\n  \"files\": \u2026\n }\n\n\n\n\nURL parameters for single compendium view\n\n\n\n\n:id\n - the compendiums id\n\n\n\n\nError responses for single compendium view\n\n\n404 Not Found\n\n{\"error\":\"no compendium with this id\"}\n\n\n\n\nList related execution jobs\n\n\ncurl https://\u2026/api/v1/compendium/$ID/jobs\n\n\nGET /api/v1/compendium/:id/jobs\n\n\n200 OK\n{\n  \"results\":[\n    \"nkm4L\",\n    \"asdi5\",\n    \"nb2sg\",\n    \u2026\n  ]\n}\n\n\n\n\nURL parameters for related execution jobs\n\n\n\n\n:id\n - compendium id that the results should be related to\n\n\n\n\nError response for related execution jobs\n\n\n404 Not Found\n\n{\"error\":\"no job found\"}",
            "title": "View"
        },
        {
            "location": "/compendium/view/#view-compendium",
            "text": "",
            "title": "View compendium"
        },
        {
            "location": "/compendium/view/#list-compendia",
            "text": "Will return up to 100 results by default.  curl https://\u2026/api/v1/compendium?limit=100&start=2  GET /api/v1/compendium?limit=100&start=2  200 OK\n\n{\n  \"results\":[\n    \"nkm4b\",\n    \"asdis\",\n    \"nb2sm\",\n    \u2026\n  ]\n}  You can also filter the results:   Filter by  user :   curl https://\u2026/api/v1/compendium?user=0000-0001-6021-1617  GET /api/v1/compendium?user=0000-0001-6021-1617   Filter by  doi :   curl https://\u2026/api/v1/compendium?doi=10.9999%2Ftest  GET /api/v1/compendium?doi=10.9999%2Ftest  200 OK\n\n{\n  \"results\":[\n    \"nkm4b\",\n    \"nb2sm\"\n  ]\n}",
            "title": "List compendia"
        },
        {
            "location": "/compendium/view/#url-parameters-for-compendium-lists",
            "text": "job_id  - Comma-separated list of related job ids to filter by.  user  - Public user identifier to filter by.  doi  - A  DOI  to filter by.  start  - Starting point of the result list.  start - 1  results are skipped. Defaults to  1 .  limit  - Limits the number of results in the response. Defaults to  100 .",
            "title": "URL parameters for compendium lists"
        },
        {
            "location": "/compendium/view/#error-responses-for-compendium-lists",
            "text": "404 Not Found\n\n{\"error\":\"no compendium found\"}",
            "title": "Error responses for compendium lists"
        },
        {
            "location": "/compendium/view/#view-single-compendium",
            "text": "This includes the complete metadata set, related job ids and a tree representation of the included  files . The  created  timestamp refers to the upload of the compendium. It is formated as ISO8601.  curl https://\u2026/api/v1/$ID  GET /api/v1/compendium/:id  200 OK\n\n{\n  \"id\":\"comid\",\n  \"metadata\": \u2026 ,\n  \"created\": \"2016-08-01T13:57:40.760Z\",\n  \"files\": \u2026\n }",
            "title": "View single compendium"
        },
        {
            "location": "/compendium/view/#url-parameters-for-single-compendium-view",
            "text": ":id  - the compendiums id",
            "title": "URL parameters for single compendium view"
        },
        {
            "location": "/compendium/view/#error-responses-for-single-compendium-view",
            "text": "404 Not Found\n\n{\"error\":\"no compendium with this id\"}",
            "title": "Error responses for single compendium view"
        },
        {
            "location": "/compendium/view/#list-related-execution-jobs",
            "text": "curl https://\u2026/api/v1/compendium/$ID/jobs  GET /api/v1/compendium/:id/jobs  200 OK\n{\n  \"results\":[\n    \"nkm4L\",\n    \"asdi5\",\n    \"nb2sg\",\n    \u2026\n  ]\n}",
            "title": "List related execution jobs"
        },
        {
            "location": "/compendium/view/#url-parameters-for-related-execution-jobs",
            "text": ":id  - compendium id that the results should be related to",
            "title": "URL parameters for related execution jobs"
        },
        {
            "location": "/compendium/view/#error-response-for-related-execution-jobs",
            "text": "404 Not Found\n\n{\"error\":\"no job found\"}",
            "title": "Error response for related execution jobs"
        },
        {
            "location": "/compendium/delete/",
            "text": "Delete compendium\n\n\nTo delete a compendium \ncandidate\n, an HTTP \nDELETE\n request can be send to the compendium endpoint.\n\n\n\n\nImportant\n\n\nOnce a compendium is not a candidate anymore, it \ncannot\n be deleted via the API.\n\n\n\n\n\n\nRequired user level\n\n\nThe user deleting a candidate must be the author or have the required \nuser level\n.\n\n\n\n\nRequest\n\n\nThe following request deletes the compendium with the identifier \n12345\n, including metadata and files.\n\n\ncurl -X DELETE https://\u2026/api/v1/compendium/12345 \\\n    --cookie \"connect.sid=<code string here>\"\n\n\n\n\nResponse\n\n\nThe response has an HTTP status of \n204\n and an empty body for successful deletion.\n\n\n204 OK\n\n\n\n\n\nError responses for compendium delete\n\n\n401 Unauthorized\n\n{\"error\":\"not authorized\"}\n\n\n\n\n403 Forbidden\n\n{\"error\":\"user level not sufficient to delete compendium\"}\n\n\n\n\n404 Not Found\n\n{\"error\":\"compendium not found\"}",
            "title": "Delete"
        },
        {
            "location": "/compendium/delete/#delete-compendium",
            "text": "To delete a compendium  candidate , an HTTP  DELETE  request can be send to the compendium endpoint.   Important  Once a compendium is not a candidate anymore, it  cannot  be deleted via the API.    Required user level  The user deleting a candidate must be the author or have the required  user level .",
            "title": "Delete compendium"
        },
        {
            "location": "/compendium/delete/#request",
            "text": "The following request deletes the compendium with the identifier  12345 , including metadata and files.  curl -X DELETE https://\u2026/api/v1/compendium/12345 \\\n    --cookie \"connect.sid=<code string here>\"",
            "title": "Request"
        },
        {
            "location": "/compendium/delete/#response",
            "text": "The response has an HTTP status of  204  and an empty body for successful deletion.  204 OK",
            "title": "Response"
        },
        {
            "location": "/compendium/delete/#error-responses-for-compendium-delete",
            "text": "401 Unauthorized\n\n{\"error\":\"not authorized\"}  403 Forbidden\n\n{\"error\":\"user level not sufficient to delete compendium\"}  404 Not Found\n\n{\"error\":\"compendium not found\"}",
            "title": "Error responses for compendium delete"
        },
        {
            "location": "/compendium/download/",
            "text": "Download compendium\n\n\nDownload compendium files as an archive.\n\n\n\n\nWarning\n\n\nThis download feature does \nnot\n provide access to complete and valid compendia, because it does not comprise an update of the \npackaging\n, while it does include \nbrokered metadata files\n.\nTo download a valid compendium, create a \nshipment\n with the appropriate recipient.\n\n\n\n\nSupported formats are as follows:\n\n\n\n\nzip\n\n\ntar\n\n\ntar.gz\n\n\n\n\nRequests\n\n\nGET /api/v1/compendium/$ID.zip\n\n\nGET /api/v1/compendium/:id.zip\nGET /api/v1/compendium/:id.tar\nGET /api/v1/compendium/:id.tar.gz\nGET /api/v1/compendium/:id.tar?gzip\nGET /api/v1/compendium/:id.zip?image=false\n\n\n\n\nURL parameters for compendium download\n\n\n\n\n:id\n - the compendiums id\n\n\n?gzip\n - \nonly for .tar endpoint\n - compress tarball with gzip\n\n\n?image=true\n or \n?image=false\n - include tarball of Docker image in the archive, default is \ntrue\n\n\n\n\nResponse\n\n\nThe response is a file attachment. The suggested file name is available in the HTTP header \ncontent-disposition\n using the respective file extension for a file named with the compendium identifier (e.g. \nwdpV9.zip\n, \nUh1o0.tar\n, or \nLBIt1.tar.gz\n).\n\n\nThe \ncontent-type\n header also reflects the respective format, which can take the following values:\n\n\n\n\napplication/zip\n for ZIP archive\n\n\napplication/x-tar\n for TAR archive\n\n\napplication/octet-stream\n for gzipped TAR\n\n\n\n\n200 OK\nContent-Type: application/zip\nTransfer-Encoding: chunked\nContent-Disposition: attachment; filename=\"$ID.zip\"\nX-Response-Time: 13.556ms\n\n\n\n\nThe zip file contains a comment with the original URL.\n\n\n$ unzip -z CXE1c.zip\nArchive:  CXE1c.zip\nCreated by o2r [https://\u2026/api/v1/compendium/CXE1c.zip]\n\n\n\n\nError responses for compendium download\n\n\n404 Not Found\n\n{\"error\":\"no compendium with this id\"}\n\n\n\n\n400 Bad Request\n\n{\"error\":\"no job found for this compendium, run a job before downloading with image\"}",
            "title": "Download"
        },
        {
            "location": "/compendium/download/#download-compendium",
            "text": "Download compendium files as an archive.   Warning  This download feature does  not  provide access to complete and valid compendia, because it does not comprise an update of the  packaging , while it does include  brokered metadata files .\nTo download a valid compendium, create a  shipment  with the appropriate recipient.   Supported formats are as follows:   zip  tar  tar.gz",
            "title": "Download compendium"
        },
        {
            "location": "/compendium/download/#requests",
            "text": "GET /api/v1/compendium/$ID.zip  GET /api/v1/compendium/:id.zip\nGET /api/v1/compendium/:id.tar\nGET /api/v1/compendium/:id.tar.gz\nGET /api/v1/compendium/:id.tar?gzip\nGET /api/v1/compendium/:id.zip?image=false",
            "title": "Requests"
        },
        {
            "location": "/compendium/download/#url-parameters-for-compendium-download",
            "text": ":id  - the compendiums id  ?gzip  -  only for .tar endpoint  - compress tarball with gzip  ?image=true  or  ?image=false  - include tarball of Docker image in the archive, default is  true",
            "title": "URL parameters for compendium download"
        },
        {
            "location": "/compendium/download/#response",
            "text": "The response is a file attachment. The suggested file name is available in the HTTP header  content-disposition  using the respective file extension for a file named with the compendium identifier (e.g.  wdpV9.zip ,  Uh1o0.tar , or  LBIt1.tar.gz ).  The  content-type  header also reflects the respective format, which can take the following values:   application/zip  for ZIP archive  application/x-tar  for TAR archive  application/octet-stream  for gzipped TAR   200 OK\nContent-Type: application/zip\nTransfer-Encoding: chunked\nContent-Disposition: attachment; filename=\"$ID.zip\"\nX-Response-Time: 13.556ms  The zip file contains a comment with the original URL.  $ unzip -z CXE1c.zip\nArchive:  CXE1c.zip\nCreated by o2r [https://\u2026/api/v1/compendium/CXE1c.zip]",
            "title": "Response"
        },
        {
            "location": "/compendium/download/#error-responses-for-compendium-download",
            "text": "404 Not Found\n\n{\"error\":\"no compendium with this id\"}  400 Bad Request\n\n{\"error\":\"no job found for this compendium, run a job before downloading with image\"}",
            "title": "Error responses for compendium download"
        },
        {
            "location": "/compendium/metadata/",
            "text": "Compendium metadata\n\n\nBasics\n\n\nMetadata in a compendium is stored in a directory \n.erc\n. This directory contains the normative metadata documents using a file naming scheme \n<metadata_model>.<format>\n, sometimes prepended with \nmetadata_\n for clarity, e.g. \nmetadata_raw.json\n, \nmetadata_o2r.json\n, \nzenodo.json\n, or \ndatacite.xml\n.\n\n\nA copy of the files in this directory is kept in database for easier access, so every compendium returned by the API can contain different sub-properties in the metadata property.\n\nThis API always returns the database copy of the metadata elements.\n\nYou can download the respective files to access the normative metadata documents.\n\n\nMetadata formats\n\n\nThe files are available on demand, but metadata variants are created after each metadata update.\n\n\nThe sub-properties of the \nmetadata\n and their content are\n\n\n\n\nraw\n contains raw metadata extracted automatically\n\n\no2r\n holds the \nmain information for display\n and is modelled according the the o2r metadata model. This metadata is reviewed by the user and the basis for translating to other metadata formats and also for \nsearch\n.\n\n\nzenodo\n holds \nZenodo\n metadata for shipments made to Zenodo and is translated from \no2r\n metadata\n\n\n\n\n\n\nNote\n\n\nThe information in each sub-property are subject to independent workflows and may differ from one another.\nThe term \nbrokering\n is used for translation from one metadata format into another.\n\n\n\n\nGet all compendium metadata\n\n\ncurl https://\u2026/api/v1/$ID\n\n\nGET /api/v1/compendium/:id\n\n\n200 OK\n\n{\n  \"id\":\"compendium_id\",\n  \"metadata\": {\n    \"raw\": {\n      \"title\": \"Programming with Data. Springer, New York, 1998. ISBN 978-0-387-98503-9.\",\n      \"author\": \"John M. Chambers.   \"\n    },\n    \"o2r\": {\n      \"title\": \"Programming with Data\",\n      \"creator\": \"John M. Chambers\",\n      \"year\": 1998\n    },\n    \"zenodo\": {\n      \u2026\n    }\n  },\n  \"created\": \u2026,\n  \"files\": \u2026\n}\n\n\n\n\nGet o2r metadata\n\n\nThe following endpoint allows to access \nonly\n the normative o2r-metadata element:\n\n\ncurl https://\u2026/api/v1/$ID/metadata\n\n\nGET /api/v1/compendium/:id/metadata\n\n\n200 OK\n\n{\n  \"id\":\"compendium_id\",\n  \"metadata\": {\n    \"o2r\": {\n      \"title\": \"Programming with Data\",\n      \"creator\": \"John M. Chambers\",\n      \"year\": 1998\n    }\n  }\n}\n\n\n\n\nURL parameters\n\n\n\n\n:id\n - compendium id\n\n\n\n\nSpatial metadata\n\n\nFor discovery purposes, the metadata includes extracted \nGeoJSON\n bounding boxes based on data files in a workspace.\n\n\nCurrently supported spatial data sources:\n\n\n\n\nshapefiles\n\n\n\n\nThe following structure is made available per file:\n\n\n    \"spatial\": {\n        \"files\": [\n            {\n                \"geojson\": {\n                    \"bbox\": [\n                        -2.362060546875,\n                        52.0862573323384,\n                        -1.285400390625,\n                        52.649729197309426\n                    ],\n                    \"geometry\": {\n                        \"coordinates\": [\n                            [\n                                [\n                                    -2.362060546875,\n                                    52.0862573323384\n                                ],\n                                [\n                                    -1.285400390625,\n                                    52.649729197309426\n                                ]\n                            ]\n                        ],\n                        \"type\": \"Polygon\"\n                    },\n                    \"type\": \"Feature\"\n                },\n                \"source_file\": \"path/to/file1.geojson\"\n            },\n            {\n                \"geojson\": {\n                    \"bbox\": [\n                        7.595369517803192,\n                        51.96245837645124,\n                        7.62162297964096,\n                        51.96966694957956\n                    ],\n                    \"geometry\": {\n                        \"coordinates\": [\n                            [\n                                [\n                                    7.595369517803192,\n                                    51.96245837645124\n                                ],\n                                [\n                                    7.62162297964096,\n                                    51.96966694957956\n                                ]\n                            ]\n                        ],\n                        \"type\": \"Polygon\"\n                    },\n                    \"type\": \"Feature\"\n                },\n                \"source_file\": \"path/to/file2.shp\"\n            }\n        ],\n        \"union\": {\n            \"geojson\": {\n                \"bbox\": [\n                    -2.362060546875,\n                    51.96245837645124,\n                    7.62162297964096,\n                    51.96245837645124\n                ],\n                \"geometry\": {\n                    \"coordinates\": [\n                        [\n                            -2.362060546875,\n                            51.96245837645124\n                        ],\n                        [\n                            7.62162297964096,\n                            51.96245837645124\n                        ],\n                        [\n                            7.62162297964096,\n                            52.649729197309426\n                        ],\n                        [\n                            -2.362060546875,\n                            52.649729197309426\n                        ]\n                    ],\n                    \"type\": \"Polygon\"\n                },\n                \"type\": \"Feature\"\n            }\n        }\n    }\n\n\n\n\nThe \nspatial\n key has a \nunion\n bounding box, that wraps all extracted bounding boxes.\n\n\nUpdate metadata\n\n\nThe following endpoint can be used to update the \no2r\n metadata elements.\nAll other metadata sub-properties are only updated by the platform itself, i.e. brokered metadata.\nAfter creation the metadata is persisted to both files and database, so updating the metadata via this endpoint allows to trigger a brokering process and to retrieve different metadata formats either via this metadata API or via downloading the respective file using the \ndownload endpoint\n.\n\n\n\n\nMetadata update rights\n\n\nOnly authors of a compendium or users with the required \nuser level\n can update a compendium's metadata.\n\n\n\n\nMetadata update request\n\n\ncurl -H 'Content-Type: application/json' \\\n  -X PUT \\\n  --cookie \"connect.sid=<code string here>\" \\\n  -d '{ \"o2r\": { \"title\": \"Blue Book\" } }' \\\n  /api/v1/compendium/:id/metadata\n\n\n\n\nThe request will \noverwrite\n the existing metadata properties, so the \nfull\n o2r metadata must be put with a JSON object called \no2r\n at the root, even if only specific fields are changed.\n\n\n\n\nNote\n\n\nThis endpoint allows only to update the \nmetadata.o2r\n elements. All other properties of \n\n\n\n\nURL parameters\n\n\n\n\n:id\n - compendium id\n\n\n\n\nMetadata update response\n\n\nThe response contains an excerpt of a compendium with only the o2r metadata property.\n\n\n200 OK\n\n{\n  \"id\":\"compendium_id\",\n  \"metadata\": {\n    \"o2r\": {\n      \"title\": \"Blue Book\"\n    }\n  }\n}\n\n\n\n\nMetadata update error responses\n\n\n401 Unauthorized\n\n{\"error\":\"not authorized\"}\n\n\n\n\n400 Bad Request\n\n\"SyntaxError [...]\"\n\n\n\n\n422 Unprocessable Entity\n\n{\"error\":\"JSON with root element 'o2r' required\"}\n\n\n\n\nOther metadata properties\n\n\nBesides the \nmetadata\n element, a compendium persists some additional properties to reduce computation on the server, and to allows client applications to improve the user experience.\n\n\n\n\nbag\n - a boolean showing if the uploaded artefact was detected as a BagIt bag (detection file: \nbagit.txt\n)\n\n\ncompendium\n - a boolean showing if the uploaded artefact was detected as a compendium (detection file: \nerc.yml\n)\n\n\n\n\nExample:\n\n\n(Properties \nmetadata\n and \nfiles\n not shown for brevity.)\n\n\n{\n\n    \"id\": \"U9IZ7\",\n    \"metadata\": {},\n    \"created\": \"2017-01-01T00:00:42.000Z\",\n    \"user\": \"0000-0001-6021-1617\",\n    \"bag\": false,\n    \"compendium\": false,\n    \"files\": {}\n}",
            "title": "Metadata"
        },
        {
            "location": "/compendium/metadata/#compendium-metadata",
            "text": "",
            "title": "Compendium metadata"
        },
        {
            "location": "/compendium/metadata/#basics",
            "text": "Metadata in a compendium is stored in a directory  .erc . This directory contains the normative metadata documents using a file naming scheme  <metadata_model>.<format> , sometimes prepended with  metadata_  for clarity, e.g.  metadata_raw.json ,  metadata_o2r.json ,  zenodo.json , or  datacite.xml .  A copy of the files in this directory is kept in database for easier access, so every compendium returned by the API can contain different sub-properties in the metadata property. This API always returns the database copy of the metadata elements. \nYou can download the respective files to access the normative metadata documents.",
            "title": "Basics"
        },
        {
            "location": "/compendium/metadata/#metadata-formats",
            "text": "The files are available on demand, but metadata variants are created after each metadata update.  The sub-properties of the  metadata  and their content are   raw  contains raw metadata extracted automatically  o2r  holds the  main information for display  and is modelled according the the o2r metadata model. This metadata is reviewed by the user and the basis for translating to other metadata formats and also for  search .  zenodo  holds  Zenodo  metadata for shipments made to Zenodo and is translated from  o2r  metadata    Note  The information in each sub-property are subject to independent workflows and may differ from one another.\nThe term  brokering  is used for translation from one metadata format into another.",
            "title": "Metadata formats"
        },
        {
            "location": "/compendium/metadata/#get-all-compendium-metadata",
            "text": "curl https://\u2026/api/v1/$ID  GET /api/v1/compendium/:id  200 OK\n\n{\n  \"id\":\"compendium_id\",\n  \"metadata\": {\n    \"raw\": {\n      \"title\": \"Programming with Data. Springer, New York, 1998. ISBN 978-0-387-98503-9.\",\n      \"author\": \"John M. Chambers.   \"\n    },\n    \"o2r\": {\n      \"title\": \"Programming with Data\",\n      \"creator\": \"John M. Chambers\",\n      \"year\": 1998\n    },\n    \"zenodo\": {\n      \u2026\n    }\n  },\n  \"created\": \u2026,\n  \"files\": \u2026\n}",
            "title": "Get all compendium metadata"
        },
        {
            "location": "/compendium/metadata/#get-o2r-metadata",
            "text": "The following endpoint allows to access  only  the normative o2r-metadata element:  curl https://\u2026/api/v1/$ID/metadata  GET /api/v1/compendium/:id/metadata  200 OK\n\n{\n  \"id\":\"compendium_id\",\n  \"metadata\": {\n    \"o2r\": {\n      \"title\": \"Programming with Data\",\n      \"creator\": \"John M. Chambers\",\n      \"year\": 1998\n    }\n  }\n}",
            "title": "Get o2r metadata"
        },
        {
            "location": "/compendium/metadata/#url-parameters",
            "text": ":id  - compendium id",
            "title": "URL parameters"
        },
        {
            "location": "/compendium/metadata/#spatial-metadata",
            "text": "For discovery purposes, the metadata includes extracted  GeoJSON  bounding boxes based on data files in a workspace.  Currently supported spatial data sources:   shapefiles   The following structure is made available per file:      \"spatial\": {\n        \"files\": [\n            {\n                \"geojson\": {\n                    \"bbox\": [\n                        -2.362060546875,\n                        52.0862573323384,\n                        -1.285400390625,\n                        52.649729197309426\n                    ],\n                    \"geometry\": {\n                        \"coordinates\": [\n                            [\n                                [\n                                    -2.362060546875,\n                                    52.0862573323384\n                                ],\n                                [\n                                    -1.285400390625,\n                                    52.649729197309426\n                                ]\n                            ]\n                        ],\n                        \"type\": \"Polygon\"\n                    },\n                    \"type\": \"Feature\"\n                },\n                \"source_file\": \"path/to/file1.geojson\"\n            },\n            {\n                \"geojson\": {\n                    \"bbox\": [\n                        7.595369517803192,\n                        51.96245837645124,\n                        7.62162297964096,\n                        51.96966694957956\n                    ],\n                    \"geometry\": {\n                        \"coordinates\": [\n                            [\n                                [\n                                    7.595369517803192,\n                                    51.96245837645124\n                                ],\n                                [\n                                    7.62162297964096,\n                                    51.96966694957956\n                                ]\n                            ]\n                        ],\n                        \"type\": \"Polygon\"\n                    },\n                    \"type\": \"Feature\"\n                },\n                \"source_file\": \"path/to/file2.shp\"\n            }\n        ],\n        \"union\": {\n            \"geojson\": {\n                \"bbox\": [\n                    -2.362060546875,\n                    51.96245837645124,\n                    7.62162297964096,\n                    51.96245837645124\n                ],\n                \"geometry\": {\n                    \"coordinates\": [\n                        [\n                            -2.362060546875,\n                            51.96245837645124\n                        ],\n                        [\n                            7.62162297964096,\n                            51.96245837645124\n                        ],\n                        [\n                            7.62162297964096,\n                            52.649729197309426\n                        ],\n                        [\n                            -2.362060546875,\n                            52.649729197309426\n                        ]\n                    ],\n                    \"type\": \"Polygon\"\n                },\n                \"type\": \"Feature\"\n            }\n        }\n    }  The  spatial  key has a  union  bounding box, that wraps all extracted bounding boxes.",
            "title": "Spatial metadata"
        },
        {
            "location": "/compendium/metadata/#update-metadata",
            "text": "The following endpoint can be used to update the  o2r  metadata elements.\nAll other metadata sub-properties are only updated by the platform itself, i.e. brokered metadata.\nAfter creation the metadata is persisted to both files and database, so updating the metadata via this endpoint allows to trigger a brokering process and to retrieve different metadata formats either via this metadata API or via downloading the respective file using the  download endpoint .   Metadata update rights  Only authors of a compendium or users with the required  user level  can update a compendium's metadata.",
            "title": "Update metadata"
        },
        {
            "location": "/compendium/metadata/#metadata-update-request",
            "text": "curl -H 'Content-Type: application/json' \\\n  -X PUT \\\n  --cookie \"connect.sid=<code string here>\" \\\n  -d '{ \"o2r\": { \"title\": \"Blue Book\" } }' \\\n  /api/v1/compendium/:id/metadata  The request will  overwrite  the existing metadata properties, so the  full  o2r metadata must be put with a JSON object called  o2r  at the root, even if only specific fields are changed.   Note  This endpoint allows only to update the  metadata.o2r  elements. All other properties of",
            "title": "Metadata update request"
        },
        {
            "location": "/compendium/metadata/#url-parameters_1",
            "text": ":id  - compendium id",
            "title": "URL parameters"
        },
        {
            "location": "/compendium/metadata/#metadata-update-response",
            "text": "The response contains an excerpt of a compendium with only the o2r metadata property.  200 OK\n\n{\n  \"id\":\"compendium_id\",\n  \"metadata\": {\n    \"o2r\": {\n      \"title\": \"Blue Book\"\n    }\n  }\n}",
            "title": "Metadata update response"
        },
        {
            "location": "/compendium/metadata/#metadata-update-error-responses",
            "text": "401 Unauthorized\n\n{\"error\":\"not authorized\"}  400 Bad Request\n\n\"SyntaxError [...]\"  422 Unprocessable Entity\n\n{\"error\":\"JSON with root element 'o2r' required\"}",
            "title": "Metadata update error responses"
        },
        {
            "location": "/compendium/metadata/#other-metadata-properties",
            "text": "Besides the  metadata  element, a compendium persists some additional properties to reduce computation on the server, and to allows client applications to improve the user experience.   bag  - a boolean showing if the uploaded artefact was detected as a BagIt bag (detection file:  bagit.txt )  compendium  - a boolean showing if the uploaded artefact was detected as a compendium (detection file:  erc.yml )   Example:  (Properties  metadata  and  files  not shown for brevity.)  {\n\n    \"id\": \"U9IZ7\",\n    \"metadata\": {},\n    \"created\": \"2017-01-01T00:00:42.000Z\",\n    \"user\": \"0000-0001-6021-1617\",\n    \"bag\": false,\n    \"compendium\": false,\n    \"files\": {}\n}",
            "title": "Other metadata properties"
        },
        {
            "location": "/compendium/files/",
            "text": "Compendium file listing\n\n\nThe file listing is returned in the single view of a job or compendium. It includes the complete content of the bagtainer in its current state. If a job has been run and the programm outputs new data, this new data will be included as well.\n\n\nFile listings are represented as a Object. The file structure for a synthetic job \nnj141\n is as follows.\n\n\nnj141\n\u251c\u2500\u2500 bagit.txt\n\u2514\u2500\u2500 data\n    \u251c\u2500\u2500 paper.Rmd\n    \u2514\u2500\u2500 Dockerfile\n\n\n\n\nwill be represented as\n\n\n{\n  \"path\": \"/api/v1/job/nj141/data\",\n  \"name\": \"nj141\",\n  \"children\": [\n    {\n      \"path\": \"/api/v1/job/nj141/data/bagit.txt\",\n      \"name\": \"bagit.xt\",\n      \"type\": \"text/plain\",\n      \"size\": 55\n    },\n    {\n      \"path\": \"/api/v1/job/nj141/data/data\",\n      \"name\": \"data\",\n      \"children\": [\n        {\n          \"path\": \"/api/v1/job/nj141/data/data/paper.Rmd\",\n          \"name\": \"paper.Rmd\",\n          \"type\": \"text/plain\",\n          \"size\": 346512\n        }\n        {\n          \"path\": \"/api/v1/job/nj141/data/data/Dockerfile\",\n          \"name\": \"Dockerfile\",\n          \"type\": \"text/plain\",\n          \"size\": 1729\n        }\n      ]\n    }\n  ]\n}\n\n\n\n\npath\n property\n\n\nThe \npath\n property for each file in the listing is a link to the raw file. Additionally the \nGET\n parameter \n?size=\u2026\n can be appended to retrieve previews of the files. In the case of Images (\npng\n, \njpg\n, \ngif\n, \ntiff\n), the value defines the maximum width/height. For text files (\ntxt\n, \ncsv\n, scripts), the value defines the amount of lines returned.\n\n\ntype\n property\n\n\nThe \ntype\n property is a best guess for the MIME type of the file content. It is a result of the files extension. Look at the list of extension to type mapping below.\n\n\nFile extension to MIME type mappings\n\n\nThis list contains the custom mapping of file extensions to MIME types used in the server.\n\n\n\n\n\n\n\n\nExtension\n\n\nMIME type\n\n\n\n\n\n\n\n\n\n\n.R\n, \n.r\n\n\nscript/x-R",
            "title": "Files in a compendium"
        },
        {
            "location": "/compendium/files/#compendium-file-listing",
            "text": "The file listing is returned in the single view of a job or compendium. It includes the complete content of the bagtainer in its current state. If a job has been run and the programm outputs new data, this new data will be included as well.  File listings are represented as a Object. The file structure for a synthetic job  nj141  is as follows.  nj141\n\u251c\u2500\u2500 bagit.txt\n\u2514\u2500\u2500 data\n    \u251c\u2500\u2500 paper.Rmd\n    \u2514\u2500\u2500 Dockerfile  will be represented as  {\n  \"path\": \"/api/v1/job/nj141/data\",\n  \"name\": \"nj141\",\n  \"children\": [\n    {\n      \"path\": \"/api/v1/job/nj141/data/bagit.txt\",\n      \"name\": \"bagit.xt\",\n      \"type\": \"text/plain\",\n      \"size\": 55\n    },\n    {\n      \"path\": \"/api/v1/job/nj141/data/data\",\n      \"name\": \"data\",\n      \"children\": [\n        {\n          \"path\": \"/api/v1/job/nj141/data/data/paper.Rmd\",\n          \"name\": \"paper.Rmd\",\n          \"type\": \"text/plain\",\n          \"size\": 346512\n        }\n        {\n          \"path\": \"/api/v1/job/nj141/data/data/Dockerfile\",\n          \"name\": \"Dockerfile\",\n          \"type\": \"text/plain\",\n          \"size\": 1729\n        }\n      ]\n    }\n  ]\n}",
            "title": "Compendium file listing"
        },
        {
            "location": "/compendium/files/#path-property",
            "text": "The  path  property for each file in the listing is a link to the raw file. Additionally the  GET  parameter  ?size=\u2026  can be appended to retrieve previews of the files. In the case of Images ( png ,  jpg ,  gif ,  tiff ), the value defines the maximum width/height. For text files ( txt ,  csv , scripts), the value defines the amount of lines returned.",
            "title": "path property"
        },
        {
            "location": "/compendium/files/#type-property",
            "text": "The  type  property is a best guess for the MIME type of the file content. It is a result of the files extension. Look at the list of extension to type mapping below.",
            "title": "type property"
        },
        {
            "location": "/compendium/files/#file-extension-to-mime-type-mappings",
            "text": "This list contains the custom mapping of file extensions to MIME types used in the server.     Extension  MIME type      .R ,  .r  script/x-R",
            "title": "File extension to MIME type mappings"
        },
        {
            "location": "/compendium/substitute/",
            "text": "Substitute two compendia\n\n\nSubstitution is the combination of an base ERC and an overlay ERC.\nA user can choose files from the overlay ERC that will replace files of the base ERC or will be uniquely added.\n\n\nCreate substitution\n\n\nCreate substitution\n will produce a new ERC with metadata, saved to MongoDB.\nA substitution will be created with an HTTP \nPOST\n request using \nmultipart/form-data\n and content-type \nJSON\n. Required are the IDs of the base and overlay ERC and at least one pair of substitution files, consisting of a base and an overlayfile.\n\n\nRequest\n\n\nPOST /api/v1/substitution\n\n\ninput of request-body for substitution\n\n\n{\n  \"base\": \"G92NL\",\n  \"overlay\": \"9fCTR\",\n  \"substitutionFiles\": [\n    {\n      \"base\": \"climate-timeseries.csv\",\n      \"overlay\": \"mytimeseries_data.csv\"\n    }\n  ]\n}\n\n\n\n\nRequest body properties\n\n\n\n\nbase\n - id of the base ERC\n\n\noverlay\n - id of the overlay ERC\n\n\nsubstitutionFiles\n - array of file substitutions specified by \nbase\n and \noverlay\n\n\nbase\n - filename of the file from the base ERC\n\n\noverlay\n - filename of the overlay ERC that will be exchanged for the original file\n\n\n\n\n\n\nRequired user level\n\n\nThe user creating a new substitution must have the required \nuser level\n.\n\n\n\n\nResponse\n\n\n201 CREATED\n\n{\n  \"id\": \"oMMFn\"\n}\n\n\n\n\nError responses\n\n\n401 Unauthorized\n\n{\"error\":\"not authenticated\"}\n\n\n\n\n401 Unauthorized\n\n{\"error\":\"not allowed\"}\n\n\n\n\n404 Not Found\n\n{\"error\":\"base ERC not found\"}\n\n\n\n\n404 Not Found\n\n{\"error\":\"overlay ERC not found\"}\n\n\n\n\nRun substitution\n\n\nRun substitution\n will run the analysis of a substitution in a docker container.\nThis is executed by a \njob\n.\n\n\nView substituted Compendium\n\n\nRequest\n\n\ncurl https://.../api/v1/compendium/$ID\n\n\nGET /api/v1/compendium/:id\n\n\nThis request will be handled as a GET-request of an usual compendium. ( \nClick for more information.\n )\n\n\nResponse\n\n\nA substituted ERC will be saved as a usual ERC, but with additional metadata specifying this as a substituted ERC and giving information about the substitution.\n\n\nExample 01 - in case there are no conflicts between filenames of any basefile and overlayfile :\n\n\n200 OK\n\n{\n  \"id\": \"oMMFn\",\n  ...\n  \"metadata\": {\n      ...\n      \"substituted\": true,\n      \"substitution\": {\n          \"base\": \"G92NL\",\n          \"overlay\": \"9fCTR\",\n          \"substitutionFiles\": [\n            {\n              \"base\": \"climate-timeseries.csv\",\n              \"overlay\": \"mytimeseries_data.csv\",\n              \"filename\": \"climate-timeseries.csv\"\n            }\n          ]\n      },\n      ...\n      },\n  ...\n}\n\n\n\n\nExample 02 - in case the overlayfile has the same filename as one of the existing basefiles :\n\n\n200 OK\n\n{\n  \"id\": \"oMMFn\",\n  ...\n  \"metadata\": {\n      ...\n      \"substituted\": true,\n      \"substitution\": {\n          \"base\": \"G92NL\",\n          \"overlay\": \"9fCTR\",\n          \"substitutionFiles\": [\n            {\n              \"base\": \"climate-timeseries.csv\",\n              \"overlay\": \"input.csv\",\n              \"filename\": \"overlay_input.csv\"\n            }\n          ]\n      },\n      ...\n      },\n  ...\n}\n\n\n\n\nResponse additional metadata\n\n\n\n\nsubstituted\n - will be set \ntrue\n\n\nsubstitution\n - object, specifying information about the substitution\n\n\nbase\n - id of the base ERC\n\n\noverlay\n - id of the overlay ERC\n\n\nsubstitutionFiles\n - array of file substitutions specified by \nbase\n and \noverlay\n\n\nbase\n - filename of the file from the base ERC\n\n\noverlay\n - filename of the file from the overlay ERC\n\n\nfilename\n - as seen in the examples above, \nfilename\n will be created if there is a conflict with any basefilename and an overlayfilename. In this case the overlayfilename will get an additional \"\noverlay_\n\" prepended (see Example 02). \n(optional add)\n\n\n\n\n\n\n\n\nList substituted Compendia\n\n\nRequest\n\n\ncurl https://.../api/v1/substitution\n\n\nGET /api/v1/substitution\n\n\nResponse\n\n\nResult will be a list of compendia ids that have been substituted\n\n\n200 OK\n\n{\n  \"results\":[\n    \"oMMFn\",\n    \"asdi5\",\n    \"nb2sg\",\n    \u2026\n  ]\n}\n\n\n\n\nFilter results with following parameters:\n\n\ncurl https://.../api/v1/substitution?base=$BASE_ID&overlay=$OVERLAY_ID\n\n\nGET /api/v1/substitution?base=base_id&overlay=overlay_id\n\n\n\n\nFilter by \nbase\n:\n\n\n\n\ncurl https://.../api/v1/substitution?base=jfL3w\n\n\nGET /api/v1/substitution?base=jfL3w\n\n\nResult will be a list of compendia ids that have been substituted out of a choosen base ERC\n\n\n200 OK\n\n{\n  \"results\":[\n    \"wGmFn\",\n    \u2026\n  ]\n}\n\n\n\n\n\n\nFilter by \noverlay\n:\n\n\n\n\ncurl https://.../api/v1/substitution?overlay=as4Kj\n\n\nGET /api/v1/substitution?overlay=as4Kj\n\n\nResult will be a list of compendia ids that have been substituted out of a choosen overlay ERC\n\n\n200 OK\n\n{\n  \"results\":[\n    \"9pQ34\",\n    \"1Tnd3\",\n    \u2026\n  ]\n}\n\n\n\n\n\n\nFilter by \nbase\n and \noverlay\n:\n\n\n\n\ncurl https://.../api/v1/substitution?base=lO3Td&overlay=as4Kj\n\n\nGET /api/v1/substitution?base=lO3Td&overlay=as4Kj\n\n\nResult will be a list of compendia ids that have been substituted out of a choosen base and overlay ERC\n\n\n200 OK\n\n{\n  \"results\":[\n    \"9pQ34\",\n    \u2026\n  ]\n}\n\n\n\n\nError responses\n\n\n401 Unauthorized\n\n{\"error\":\"not authenticated\"}\n\n\n\n\n401 Unauthorized\n\n{\"error\":\"not allowed\"}\n\n\n\n\n404 Not Found\n\n{\"error\":\"base ERC not found\"}\n\n\n\n\n404 Not Found\n\n{\"error\":\"overlay ERC not found\"}\n\n\n\n\nURL parameters for substituted compendium lists\n\n\n\n\n:base\n - id of the base ERC that the results should be related to\n\n\n:overlay\n - id of the base ERC that the results should be related to",
            "title": "Substitution"
        },
        {
            "location": "/compendium/substitute/#substitute-two-compendia",
            "text": "Substitution is the combination of an base ERC and an overlay ERC.\nA user can choose files from the overlay ERC that will replace files of the base ERC or will be uniquely added.",
            "title": "Substitute two compendia"
        },
        {
            "location": "/compendium/substitute/#create-substitution",
            "text": "Create substitution  will produce a new ERC with metadata, saved to MongoDB.\nA substitution will be created with an HTTP  POST  request using  multipart/form-data  and content-type  JSON . Required are the IDs of the base and overlay ERC and at least one pair of substitution files, consisting of a base and an overlayfile.",
            "title": "Create substitution"
        },
        {
            "location": "/compendium/substitute/#request",
            "text": "POST /api/v1/substitution  input of request-body for substitution  {\n  \"base\": \"G92NL\",\n  \"overlay\": \"9fCTR\",\n  \"substitutionFiles\": [\n    {\n      \"base\": \"climate-timeseries.csv\",\n      \"overlay\": \"mytimeseries_data.csv\"\n    }\n  ]\n}",
            "title": "Request"
        },
        {
            "location": "/compendium/substitute/#request-body-properties",
            "text": "base  - id of the base ERC  overlay  - id of the overlay ERC  substitutionFiles  - array of file substitutions specified by  base  and  overlay  base  - filename of the file from the base ERC  overlay  - filename of the overlay ERC that will be exchanged for the original file    Required user level  The user creating a new substitution must have the required  user level .",
            "title": "Request body properties"
        },
        {
            "location": "/compendium/substitute/#response",
            "text": "201 CREATED\n\n{\n  \"id\": \"oMMFn\"\n}",
            "title": "Response"
        },
        {
            "location": "/compendium/substitute/#error-responses",
            "text": "401 Unauthorized\n\n{\"error\":\"not authenticated\"}  401 Unauthorized\n\n{\"error\":\"not allowed\"}  404 Not Found\n\n{\"error\":\"base ERC not found\"}  404 Not Found\n\n{\"error\":\"overlay ERC not found\"}",
            "title": "Error responses"
        },
        {
            "location": "/compendium/substitute/#run-substitution",
            "text": "Run substitution  will run the analysis of a substitution in a docker container.\nThis is executed by a  job .",
            "title": "Run substitution"
        },
        {
            "location": "/compendium/substitute/#view-substituted-compendium",
            "text": "",
            "title": "View substituted Compendium"
        },
        {
            "location": "/compendium/substitute/#request_1",
            "text": "curl https://.../api/v1/compendium/$ID  GET /api/v1/compendium/:id  This request will be handled as a GET-request of an usual compendium. (  Click for more information.  )",
            "title": "Request"
        },
        {
            "location": "/compendium/substitute/#response_1",
            "text": "A substituted ERC will be saved as a usual ERC, but with additional metadata specifying this as a substituted ERC and giving information about the substitution.  Example 01 - in case there are no conflicts between filenames of any basefile and overlayfile :  200 OK\n\n{\n  \"id\": \"oMMFn\",\n  ...\n  \"metadata\": {\n      ...\n      \"substituted\": true,\n      \"substitution\": {\n          \"base\": \"G92NL\",\n          \"overlay\": \"9fCTR\",\n          \"substitutionFiles\": [\n            {\n              \"base\": \"climate-timeseries.csv\",\n              \"overlay\": \"mytimeseries_data.csv\",\n              \"filename\": \"climate-timeseries.csv\"\n            }\n          ]\n      },\n      ...\n      },\n  ...\n}  Example 02 - in case the overlayfile has the same filename as one of the existing basefiles :  200 OK\n\n{\n  \"id\": \"oMMFn\",\n  ...\n  \"metadata\": {\n      ...\n      \"substituted\": true,\n      \"substitution\": {\n          \"base\": \"G92NL\",\n          \"overlay\": \"9fCTR\",\n          \"substitutionFiles\": [\n            {\n              \"base\": \"climate-timeseries.csv\",\n              \"overlay\": \"input.csv\",\n              \"filename\": \"overlay_input.csv\"\n            }\n          ]\n      },\n      ...\n      },\n  ...\n}",
            "title": "Response"
        },
        {
            "location": "/compendium/substitute/#response-additional-metadata",
            "text": "substituted  - will be set  true  substitution  - object, specifying information about the substitution  base  - id of the base ERC  overlay  - id of the overlay ERC  substitutionFiles  - array of file substitutions specified by  base  and  overlay  base  - filename of the file from the base ERC  overlay  - filename of the file from the overlay ERC  filename  - as seen in the examples above,  filename  will be created if there is a conflict with any basefilename and an overlayfilename. In this case the overlayfilename will get an additional \" overlay_ \" prepended (see Example 02).  (optional add)",
            "title": "Response additional metadata"
        },
        {
            "location": "/compendium/substitute/#list-substituted-compendia",
            "text": "",
            "title": "List substituted Compendia"
        },
        {
            "location": "/compendium/substitute/#request_2",
            "text": "curl https://.../api/v1/substitution  GET /api/v1/substitution",
            "title": "Request"
        },
        {
            "location": "/compendium/substitute/#response_2",
            "text": "Result will be a list of compendia ids that have been substituted  200 OK\n\n{\n  \"results\":[\n    \"oMMFn\",\n    \"asdi5\",\n    \"nb2sg\",\n    \u2026\n  ]\n}",
            "title": "Response"
        },
        {
            "location": "/compendium/substitute/#filter-results-with-following-parameters",
            "text": "curl https://.../api/v1/substitution?base=$BASE_ID&overlay=$OVERLAY_ID  GET /api/v1/substitution?base=base_id&overlay=overlay_id   Filter by  base :   curl https://.../api/v1/substitution?base=jfL3w  GET /api/v1/substitution?base=jfL3w  Result will be a list of compendia ids that have been substituted out of a choosen base ERC  200 OK\n\n{\n  \"results\":[\n    \"wGmFn\",\n    \u2026\n  ]\n}   Filter by  overlay :   curl https://.../api/v1/substitution?overlay=as4Kj  GET /api/v1/substitution?overlay=as4Kj  Result will be a list of compendia ids that have been substituted out of a choosen overlay ERC  200 OK\n\n{\n  \"results\":[\n    \"9pQ34\",\n    \"1Tnd3\",\n    \u2026\n  ]\n}   Filter by  base  and  overlay :   curl https://.../api/v1/substitution?base=lO3Td&overlay=as4Kj  GET /api/v1/substitution?base=lO3Td&overlay=as4Kj  Result will be a list of compendia ids that have been substituted out of a choosen base and overlay ERC  200 OK\n\n{\n  \"results\":[\n    \"9pQ34\",\n    \u2026\n  ]\n}",
            "title": "Filter results with following parameters:"
        },
        {
            "location": "/compendium/substitute/#error-responses_1",
            "text": "401 Unauthorized\n\n{\"error\":\"not authenticated\"}  401 Unauthorized\n\n{\"error\":\"not allowed\"}  404 Not Found\n\n{\"error\":\"base ERC not found\"}  404 Not Found\n\n{\"error\":\"overlay ERC not found\"}",
            "title": "Error responses"
        },
        {
            "location": "/compendium/substitute/#url-parameters-for-substituted-compendium-lists",
            "text": ":base  - id of the base ERC that the results should be related to  :overlay  - id of the base ERC that the results should be related to",
            "title": "URL parameters for substituted compendium lists"
        },
        {
            "location": "/job/",
            "text": "Execute a compendium\n\n\nExecution jobs are used to run the analysis in a compendium. When a new execution job is started, the contents of the research compendium are cloned to create a trackable execution. The status information, logs and final working directory data are saved in their final state, so that they can be reviewed later on.\n\n\nAll execution jobs are tied to a single research compendium and reflect the execution history of that research compendium.\n\n\nA trivial execution job would be a completely unmodified research compendium, to test the executability/reproducibility of the contained data and code.\n\n\nState of a job\n\n\nThe property \n>job>.state\n shows the overall state of a job.\n\n\nThe status will be one of following:\n\n\n\n\nsuccess\n - if state of all steps is \nsuccess\n.\n\n\nfailure\n - if state of at least one step is \nfailure\n.\n\n\nrunning\n - if state of at least one step is \nrunning\n and no state is \nfailure\n.\n\n\n\n\nMore information about \nsteps\n can be found in subsection \nSteps\n of section \nView single job\n.\n\n\nSteps of a job\n\n\nOne job consists of a series of steps. All of these steps can be in one of three status: \nrunning\n, \nfailure\n, or \nsuccess\n. The are executed in order.\n\n\n\n\nvalidate_bag\n\n  Validate the BagIt bag based on the npm library \nbagit\n.\n\n\nvalidate_compendium\n\n  Parses and validate the bagtainer configuration and metadata.\n\n\nimage_prepare\n\n  Create an archive of the payload of the BagIt bag, which allows to build and run the image also on remote Docker hosts.\n\n\nimage_build\n\n  Send the bag's payload as a tarballed archive to Docker to build an image, which is tagged \nerc:<job_id>\n.\n\n\nimage_execute\n\n  Run the container and return based on status code of program that ran inside the container.\n\n\ncheck\n\n  Run a check on the contents of the container. Validate the results of the executed calculations.\n\n\ncleanup\n\n  Remove image or job files (depending on server-side settings).\n\n\n\n\nThe step status is one of:\n\n\n\n\nqueued\n\n\nrunning\n\n\nsuccess\n\n\nfailure\n\n\nwarning\n\n\nskipped\n\n\n\n\nNew job\n\n\nCreate and run a new execution job with an HTTP \nPOST\n request using \nmultipart/form-data\n.\nRequires a \ncompendium_id\n.\n\n\ncurl -F compendium_id=$ID https://\u2026/api/v1/job\n\n\nPOST /api/v1/job\n\n\n200 OK\n\n{\"job_id\":\"ngK4m\"}\n\n\n\n\nBody parameters for new jobs\n\n\n\n\ncompendium_id\n (\nstring\n): \nRequired\n The identifier of the compendium to base this job on.\n\n\n\n\nError responses for new jobs\n\n\n404 Not Found\n\n{\"error\":\"no compendium with this ID found\"}\n\n\n\n\n500 Internal Server Error\n\n{\"error\":\"could not create job\"}\n\n\n\n\nList jobs\n\n\nLists jobs with filtering and pagination, returning up to 100 results by default.\n\n\nResults will be sorted by descending date of last change. The content of the response can be limited to certain properties of each result by providing a list of fields, i.e. the parameter \nfields\n.\n\n\nResults can be filtered:\n\n\n\n\nby \ncompendium_id\n i.e. \ncompendium_id=a4Dnm\n,\n\n\nby \nstatus\n i.e. \nstatus=success\n or\n\n\nby \nuser\n i.e. \nuser=0000-0000-0000-0001\n\n\n\n\ncurl https://\u2026/api/v1/job?limit=100&start=2&compendium_id=$ID&status=success&fields=status\n\n\nGET /api/v1/job?limit=100&start=2&compendium_id=a4Dnm&status=success\n\n\n200 OK\n\n{\n  \"results\":[\n    \"nkm4L\",\n    \"asdi5\",\n    \"nb2sg\",\n    \u2026\n  ]\n}\n\n\n\n\nThe overall job state can be added to the job list response:\n\n\nGET /api/v1/job?limit=100&start=2&compendium_id=a4Dnm&status=success&fields=status\n\n\n200 OK\n\n{\n  \"results\":[\n    {\n      \"id\":\"nkm4L\",\n      \"status\":\"failure\"\n    },\n    {\n      \"id\":\"asdi5\",\n      \"status\":\"success\"\n    },\n    {\n      \"id\":\"nb2sg\",\n      \"status\":\"running\"\n    },\n    \u2026\n  ]\n}\n\n\n\n\nGET query parameters for listing jobs\n\n\n\n\ncompendium_id\n - Comma-separated list of related compendium ids to filter by.\n\n\nstart\n - Starting point of the result list. \nstart - 1\n results are skipped. Defaults to 1.\n\n\nlimit\n - Limits the number of results in the response. Defaults to 100.\n\n\nstatus\n - Specify status to filter by. Can contain following \nstatus\n: \nsuccess\n, \nfailure\n, \nrunning\n.\n\n\nuser\n - Public user identifier to filter by.\n\n\nfields\n - Specify if/which additional attributes results should contain. Can contain following \nfields\n: \nstatus\n. Defaults to none.\n\n\n\n\nView single job\n\n\nView details for a single job. The file listing format is described in \ncompendium files\n\n\ncurl https://\u2026/api/v1/job/$ID?details=all\n\n\nGET /api/v1/job/:id?details=all\n\n\n200 OK\n\n{\n  \"id\": \"nkm4L\",\n  \"compendium_id\": \"a4Dnm\",\n  \"user\": \"0000-0001-6021-1617\",\n  \"status\": \"failure\",\n  \"steps\": {\n    \"validate-bag\": {\n      \"status\":\"skipped\",\n      \"text\": \"bag validation during job execution is disabled\"\n    },\n    \"validate_compendium\": {\n      \"text\": \"compendium is invalid, but execution may continue\",\n      \"status\": \"failure\",\n      \"start\": \"2017-10-23T08:44:30.768Z\",\n      \"end\": \"2017-10-23T08:44:30.785Z\"\n    },\n    \"image_prepare\": {\n     \"text\": \"payload with 12800 total bytes\",\n     \"status\": \"success\",\n     \"start\": \"2017-10-23T08:44:30.789Z\",\n     \"end\": \"2017-10-23T08:44:31.013Z\"\n    },\n    \"image_build\": {\n      \"text\": \"Step 1/6 : FROM alpine\\nStep 3/6 : ENV HOST 127.0.0.1\\nSuccessfully tagged erc:nkm4L\\n\",\n      \"status\": \"success\",\n      \"start\": \"2017-10-23T08:44:31.043Z\",\n      \"end\": \"2017-10-23T08:44:31.405Z\"\n    },\n    \"image_execute\": {\n      \"text\": \"PING 127.0.0.1 (127.0.0.1): 56 data bytes\\r\\n64 bytes from 127.0.0.1: seq=0 ttl=64 [TRUNCATED FOR EXAMPLE]\",\n      \"status\": \"success\",\n      \"start\": \"2017-10-23T08:44:31.561Z\",\n      \"end\": \"2017-10-23T08:45:01.160Z\",\n      \"statuscode\": 0\n    },\n    \"check\": {\n      \"status\": \"success\",\n      \"images\": [\n        {\n          \"imageIndex\": 0,\n          \"resizeOperationCode\": 0,\n          \"compareResults\": {\n            \"differences\": 0,\n            \"dimension\": 1290240\n          }\n        }\n      ],\n      \"display\": {\n        \"diff\": \"[merged HTML with difference highlighting for images]\"\n      },\n      \"start\": \"2017-10-23T08:45:01.168Z\",\n      \"end\": \"2017-10-23T08:45:02.193Z\",\n      \"errors\": []\n    },\n    \"cleanup\": {\n      \"text\": \"Done: removed container.\\nDone: kept image with tag erc:nkm4L for job nkm4L\\nDone: deleted tmp payload file.\",\n      \"status\": \"success\",\n      \"start\": \"2017-10-23T08:45:01.201Z\",\n      \"end\": \"2017-10-23T08:45:01.226Z\"\n    }\n  },  \n  \"createdAt\": \"2017-10-23T08:44:30.693Z\",\n  \"updatedAt\": \"2017-10-23T08:45:01.237Z\"\n}\n\n\n\n\nURL parameters for single job view\n\n\n\n\n:id\n - id of the job to be viewed\n\n\ndetails\n - Details of steps to be loaded.  \n\n\n\n\nBy default, only \nstatus\n, \nstart\n and \nend\n of any step will be loaded.\n\n\ndetails\n may either be \nall\n, or a comma separated list of one or more step identifiers. Any other step values for \ndetails\n than the listed ones will return the default (e.g. \ndetails=no\n).\n\n\nSteps\n\n\nThe answer will contain information regarding the job steps.\n\n\nAdditional explanations to their status will be transmitted in the \ntext\n property. The \nstart\n and \nend\n timestamps indicate the start and end time of the step. They are formatted as ISO8601.\n\n\nError responses for single job view\n\n\n404 Not Found\n\n{\"error\":\"no compendium with this ID found\"}\n\n\n\n\nJob status updates\n\n\nYou can subscribe to real time status updates on jobs using \nWebSockets\n. The implementation is based on \nsocket.io\n and using their client is recommended.\n\n\nThe job log is available at \nhttps://o2r.uni-muenster.de\n under the namespace \napi/v1/logs/job\n.\n\n\n# create a socket.io client:\nvar socket = io('https://o2r.uni-muenster.de/api/v1/logs/job');\n\n\n\n\nTODO\n: add documentation on messages on the socket.",
            "title": "Job"
        },
        {
            "location": "/job/#execute-a-compendium",
            "text": "Execution jobs are used to run the analysis in a compendium. When a new execution job is started, the contents of the research compendium are cloned to create a trackable execution. The status information, logs and final working directory data are saved in their final state, so that they can be reviewed later on.  All execution jobs are tied to a single research compendium and reflect the execution history of that research compendium.  A trivial execution job would be a completely unmodified research compendium, to test the executability/reproducibility of the contained data and code.",
            "title": "Execute a compendium"
        },
        {
            "location": "/job/#state-of-a-job",
            "text": "The property  >job>.state  shows the overall state of a job.  The status will be one of following:   success  - if state of all steps is  success .  failure  - if state of at least one step is  failure .  running  - if state of at least one step is  running  and no state is  failure .   More information about  steps  can be found in subsection  Steps  of section  View single job .",
            "title": "State of a job"
        },
        {
            "location": "/job/#steps-of-a-job",
            "text": "One job consists of a series of steps. All of these steps can be in one of three status:  running ,  failure , or  success . The are executed in order.   validate_bag \n  Validate the BagIt bag based on the npm library  bagit .  validate_compendium \n  Parses and validate the bagtainer configuration and metadata.  image_prepare \n  Create an archive of the payload of the BagIt bag, which allows to build and run the image also on remote Docker hosts.  image_build \n  Send the bag's payload as a tarballed archive to Docker to build an image, which is tagged  erc:<job_id> .  image_execute \n  Run the container and return based on status code of program that ran inside the container.  check \n  Run a check on the contents of the container. Validate the results of the executed calculations.  cleanup \n  Remove image or job files (depending on server-side settings).   The step status is one of:   queued  running  success  failure  warning  skipped",
            "title": "Steps of a job"
        },
        {
            "location": "/job/#new-job",
            "text": "Create and run a new execution job with an HTTP  POST  request using  multipart/form-data .\nRequires a  compendium_id .  curl -F compendium_id=$ID https://\u2026/api/v1/job  POST /api/v1/job  200 OK\n\n{\"job_id\":\"ngK4m\"}",
            "title": "New job"
        },
        {
            "location": "/job/#body-parameters-for-new-jobs",
            "text": "compendium_id  ( string ):  Required  The identifier of the compendium to base this job on.",
            "title": "Body parameters for new jobs"
        },
        {
            "location": "/job/#error-responses-for-new-jobs",
            "text": "404 Not Found\n\n{\"error\":\"no compendium with this ID found\"}  500 Internal Server Error\n\n{\"error\":\"could not create job\"}",
            "title": "Error responses for new jobs"
        },
        {
            "location": "/job/#list-jobs",
            "text": "Lists jobs with filtering and pagination, returning up to 100 results by default.  Results will be sorted by descending date of last change. The content of the response can be limited to certain properties of each result by providing a list of fields, i.e. the parameter  fields .  Results can be filtered:   by  compendium_id  i.e.  compendium_id=a4Dnm ,  by  status  i.e.  status=success  or  by  user  i.e.  user=0000-0000-0000-0001   curl https://\u2026/api/v1/job?limit=100&start=2&compendium_id=$ID&status=success&fields=status  GET /api/v1/job?limit=100&start=2&compendium_id=a4Dnm&status=success  200 OK\n\n{\n  \"results\":[\n    \"nkm4L\",\n    \"asdi5\",\n    \"nb2sg\",\n    \u2026\n  ]\n}  The overall job state can be added to the job list response:  GET /api/v1/job?limit=100&start=2&compendium_id=a4Dnm&status=success&fields=status  200 OK\n\n{\n  \"results\":[\n    {\n      \"id\":\"nkm4L\",\n      \"status\":\"failure\"\n    },\n    {\n      \"id\":\"asdi5\",\n      \"status\":\"success\"\n    },\n    {\n      \"id\":\"nb2sg\",\n      \"status\":\"running\"\n    },\n    \u2026\n  ]\n}",
            "title": "List jobs"
        },
        {
            "location": "/job/#get-query-parameters-for-listing-jobs",
            "text": "compendium_id  - Comma-separated list of related compendium ids to filter by.  start  - Starting point of the result list.  start - 1  results are skipped. Defaults to 1.  limit  - Limits the number of results in the response. Defaults to 100.  status  - Specify status to filter by. Can contain following  status :  success ,  failure ,  running .  user  - Public user identifier to filter by.  fields  - Specify if/which additional attributes results should contain. Can contain following  fields :  status . Defaults to none.",
            "title": "GET query parameters for listing jobs"
        },
        {
            "location": "/job/#view-single-job",
            "text": "View details for a single job. The file listing format is described in  compendium files  curl https://\u2026/api/v1/job/$ID?details=all  GET /api/v1/job/:id?details=all  200 OK\n\n{\n  \"id\": \"nkm4L\",\n  \"compendium_id\": \"a4Dnm\",\n  \"user\": \"0000-0001-6021-1617\",\n  \"status\": \"failure\",\n  \"steps\": {\n    \"validate-bag\": {\n      \"status\":\"skipped\",\n      \"text\": \"bag validation during job execution is disabled\"\n    },\n    \"validate_compendium\": {\n      \"text\": \"compendium is invalid, but execution may continue\",\n      \"status\": \"failure\",\n      \"start\": \"2017-10-23T08:44:30.768Z\",\n      \"end\": \"2017-10-23T08:44:30.785Z\"\n    },\n    \"image_prepare\": {\n     \"text\": \"payload with 12800 total bytes\",\n     \"status\": \"success\",\n     \"start\": \"2017-10-23T08:44:30.789Z\",\n     \"end\": \"2017-10-23T08:44:31.013Z\"\n    },\n    \"image_build\": {\n      \"text\": \"Step 1/6 : FROM alpine\\nStep 3/6 : ENV HOST 127.0.0.1\\nSuccessfully tagged erc:nkm4L\\n\",\n      \"status\": \"success\",\n      \"start\": \"2017-10-23T08:44:31.043Z\",\n      \"end\": \"2017-10-23T08:44:31.405Z\"\n    },\n    \"image_execute\": {\n      \"text\": \"PING 127.0.0.1 (127.0.0.1): 56 data bytes\\r\\n64 bytes from 127.0.0.1: seq=0 ttl=64 [TRUNCATED FOR EXAMPLE]\",\n      \"status\": \"success\",\n      \"start\": \"2017-10-23T08:44:31.561Z\",\n      \"end\": \"2017-10-23T08:45:01.160Z\",\n      \"statuscode\": 0\n    },\n    \"check\": {\n      \"status\": \"success\",\n      \"images\": [\n        {\n          \"imageIndex\": 0,\n          \"resizeOperationCode\": 0,\n          \"compareResults\": {\n            \"differences\": 0,\n            \"dimension\": 1290240\n          }\n        }\n      ],\n      \"display\": {\n        \"diff\": \"[merged HTML with difference highlighting for images]\"\n      },\n      \"start\": \"2017-10-23T08:45:01.168Z\",\n      \"end\": \"2017-10-23T08:45:02.193Z\",\n      \"errors\": []\n    },\n    \"cleanup\": {\n      \"text\": \"Done: removed container.\\nDone: kept image with tag erc:nkm4L for job nkm4L\\nDone: deleted tmp payload file.\",\n      \"status\": \"success\",\n      \"start\": \"2017-10-23T08:45:01.201Z\",\n      \"end\": \"2017-10-23T08:45:01.226Z\"\n    }\n  },  \n  \"createdAt\": \"2017-10-23T08:44:30.693Z\",\n  \"updatedAt\": \"2017-10-23T08:45:01.237Z\"\n}",
            "title": "View single job"
        },
        {
            "location": "/job/#url-parameters-for-single-job-view",
            "text": ":id  - id of the job to be viewed  details  - Details of steps to be loaded.     By default, only  status ,  start  and  end  of any step will be loaded.  details  may either be  all , or a comma separated list of one or more step identifiers. Any other step values for  details  than the listed ones will return the default (e.g.  details=no ).",
            "title": "URL parameters for single job view"
        },
        {
            "location": "/job/#steps",
            "text": "The answer will contain information regarding the job steps.  Additional explanations to their status will be transmitted in the  text  property. The  start  and  end  timestamps indicate the start and end time of the step. They are formatted as ISO8601.",
            "title": "Steps"
        },
        {
            "location": "/job/#error-responses-for-single-job-view",
            "text": "404 Not Found\n\n{\"error\":\"no compendium with this ID found\"}",
            "title": "Error responses for single job view"
        },
        {
            "location": "/job/#job-status-updates",
            "text": "You can subscribe to real time status updates on jobs using  WebSockets . The implementation is based on  socket.io  and using their client is recommended.  The job log is available at  https://o2r.uni-muenster.de  under the namespace  api/v1/logs/job .  # create a socket.io client:\nvar socket = io('https://o2r.uni-muenster.de/api/v1/logs/job');  TODO : add documentation on messages on the socket.",
            "title": "Job status updates"
        },
        {
            "location": "/search/",
            "text": "Search\n\n\nThe search uses a document database to provide high speed and powerful search capabilities for compendia, including spatial and temporal properties.\n\n\nThe search structure is based on \nElasticsearch\n and thereby eases an implementation, because the requests and responses shown here can be directly mapped to respectively from \nElasticsearch's API\n.\n\n\nIndexed information:\n\n\n\n\ncompendium \nmetadata\n (including harvested and user-edited metadata such as temporal ranges and spatial extents)\n\n\nfull texts\n of text files in a compendium\n\n\n\n\nSimple search\n\n\nA simple search allows searching for search terms using an \nHTTP GET\n request accepting \napplication/json\n content type.\n\n\ncurl -H 'Content-Type: application/json' https://.../api/v1/search?q=$SEARCHTERM\n\n\nGET /api/v1/search?q=Reproducible\n\n\nGET /api/v1/search?q=great reproducible research\n\n\nThe \nresponse\n is \nJSON\n with the root element is \nhits\n, which has the same as the \nhits\n element from an Elasticsearch response but may not include internal fields such as \n_index\n, \n_type\n, and \n_id\n.\n\n\n200 ok\n\n{\n  \"hits\": {\n    \"total\": 1,\n    \"max_score\": 1.0586987,\n    \"hits\": [\n      {\n        \"_score\": 1.0586987,\n        \"_source\": {\n          \"metadata\": {\n            \"o2r\": ...\n          },\n        }\n      }\n    ]\n  }\n}\n\n\n\n\n\n\nNote\n\n\nThe available metadata is a synced clone of the compendium metadata stored in the main database.\nFor more information on the mapping from the main database to the search database, take a look at the \no2r-finder\n microservice\n.\n\n\n\n\nQuery parameters for simple search\n\n\n\n\nq\n - search term(s), must be \nURL-encoded\n\n\n\n\nExample requests\n\n\n\n\nhttp://o2r.uni-muenster.de/api/v1/search?q=*\n\n\nhttp://o2r.uni-muenster.de/api/v1/search?q=europe temperature data analysis\n\n\nhttp://o2r.uni-muenster.de/api/v1/search?q=europe%20temperature%20data%20analysis\n\n\nhttp://o2r.uni-muenster.de/api/v1/search?q=10.5555%2F12345678\n\n\n\n\nComplex Search\n\n\nA complex search is enabled via \nPOST\n requests with a \nJSON\n payload as \nHTTP POST\n data (\nnot\n \nmultipart/form-data\n) accepting an \napplication/json\n content type as response.\nQueries can include filters, aggregation and spatio-temporal operations as defined in the \nElasticsearch Query DSL\n.\n\n\ncurl -X POST -H 'Content-Type: application/json' 'https://.../api/v1/search' -d '$QUERY_DSL'\n\n\nThe \nresponse\n structure is the same as for \nsimple search\n.\n\n\nQuery fields  for complex search\n\n\nThe following fields are especially relevant to build queries.\n\n\n\n\nmetadata.o2r.temporal.begin\n and \nmetadata.o2r.temporal.end\n provide a compendium's temporal extent\n\n\nmetadata.o2r.spatial.geometry\n has the compendium's spatial extent\n\n\n\n\nBesides these fields, all metadata of the \no2r\n metadata format\n can be used.\n\n\nExamples\n\n\nTemporal search\n\n\nPOST /api/v1/search -d '{\n  \"query\": {\n      \"bool\": {\n          \"must\": {\n              \"match_all\": {}\n          },\n          \"filter\": [\n              {\n                  \"range\": {\n                      \"metadata.o2r.temporal.begin\": {\n                          \"from\": \"2015-03-01T00:00:00.000Z\"\n                      }\n                  }\n              },\n              {\n                  \"range\": {\n                      \"metadata.o2r.temporal.end\": {\n                          \"to\": \"2017-10-01T00:00:00.000Z\"\n                      }\n                  }\n              }\n          ]\n      }\n  },\n  \"from\": 0,\n  \"size\": 10\n}'\n\n\n\n\nSpatial search\n\n\n{\n    \"bool\": {\n        \"must\": {\n            \"match_all\": {}\n         },\n         \"filter\": {\n              \"geo_shape\": {\n                   \"metadata.o2r.spatial.geometry\": {\n                        \"shape\": {\n                            \"type\": \"polygon\",\n                            \"coordinates\": [... GeoJSON coordinates...]\n                         },\n                         \"relation\": \"within\"\n                    }\n               }\n          }\n     }\n}\n\n\n\n\nIn this example a filter has been nested within a \nboolean/must match\n query.\nThe filter has been applied to the \nmetadata.o2r.spatial.geometry\n field of the dataset with a \nwithin\n relation so that only compendia with a spatial extent completely contained in the provided shape are fetched.\n\n\nResponse\n\n\n200 ok\n\n{\n  \"hits\": {\n    \"total\": 1,\n    \"max_score\": 1.0586987,\n    \"hits\": [\n      {\n        \"_score\": 1.0586987,\n        \"_source\": {\n          \"metadata\": {\n            \"o2r\": ...\n          },\n        }\n      }\n    ]\n  }\n}",
            "title": "Search"
        },
        {
            "location": "/search/#search",
            "text": "The search uses a document database to provide high speed and powerful search capabilities for compendia, including spatial and temporal properties.  The search structure is based on  Elasticsearch  and thereby eases an implementation, because the requests and responses shown here can be directly mapped to respectively from  Elasticsearch's API .  Indexed information:   compendium  metadata  (including harvested and user-edited metadata such as temporal ranges and spatial extents)  full texts  of text files in a compendium",
            "title": "Search"
        },
        {
            "location": "/search/#simple-search",
            "text": "A simple search allows searching for search terms using an  HTTP GET  request accepting  application/json  content type.  curl -H 'Content-Type: application/json' https://.../api/v1/search?q=$SEARCHTERM  GET /api/v1/search?q=Reproducible  GET /api/v1/search?q=great reproducible research  The  response  is  JSON  with the root element is  hits , which has the same as the  hits  element from an Elasticsearch response but may not include internal fields such as  _index ,  _type , and  _id .  200 ok\n\n{\n  \"hits\": {\n    \"total\": 1,\n    \"max_score\": 1.0586987,\n    \"hits\": [\n      {\n        \"_score\": 1.0586987,\n        \"_source\": {\n          \"metadata\": {\n            \"o2r\": ...\n          },\n        }\n      }\n    ]\n  }\n}   Note  The available metadata is a synced clone of the compendium metadata stored in the main database.\nFor more information on the mapping from the main database to the search database, take a look at the  o2r-finder  microservice .",
            "title": "Simple search"
        },
        {
            "location": "/search/#query-parameters-for-simple-search",
            "text": "q  - search term(s), must be  URL-encoded",
            "title": "Query parameters for simple search"
        },
        {
            "location": "/search/#example-requests",
            "text": "http://o2r.uni-muenster.de/api/v1/search?q=*  http://o2r.uni-muenster.de/api/v1/search?q=europe temperature data analysis  http://o2r.uni-muenster.de/api/v1/search?q=europe%20temperature%20data%20analysis  http://o2r.uni-muenster.de/api/v1/search?q=10.5555%2F12345678",
            "title": "Example requests"
        },
        {
            "location": "/search/#complex-search",
            "text": "A complex search is enabled via  POST  requests with a  JSON  payload as  HTTP POST  data ( not   multipart/form-data ) accepting an  application/json  content type as response.\nQueries can include filters, aggregation and spatio-temporal operations as defined in the  Elasticsearch Query DSL .  curl -X POST -H 'Content-Type: application/json' 'https://.../api/v1/search' -d '$QUERY_DSL'  The  response  structure is the same as for  simple search .",
            "title": "Complex Search"
        },
        {
            "location": "/search/#query-fields-for-complex-search",
            "text": "The following fields are especially relevant to build queries.   metadata.o2r.temporal.begin  and  metadata.o2r.temporal.end  provide a compendium's temporal extent  metadata.o2r.spatial.geometry  has the compendium's spatial extent   Besides these fields, all metadata of the  o2r  metadata format  can be used.",
            "title": "Query fields  for complex search"
        },
        {
            "location": "/search/#examples",
            "text": "",
            "title": "Examples"
        },
        {
            "location": "/search/#temporal-search",
            "text": "POST /api/v1/search -d '{\n  \"query\": {\n      \"bool\": {\n          \"must\": {\n              \"match_all\": {}\n          },\n          \"filter\": [\n              {\n                  \"range\": {\n                      \"metadata.o2r.temporal.begin\": {\n                          \"from\": \"2015-03-01T00:00:00.000Z\"\n                      }\n                  }\n              },\n              {\n                  \"range\": {\n                      \"metadata.o2r.temporal.end\": {\n                          \"to\": \"2017-10-01T00:00:00.000Z\"\n                      }\n                  }\n              }\n          ]\n      }\n  },\n  \"from\": 0,\n  \"size\": 10\n}'",
            "title": "Temporal search"
        },
        {
            "location": "/search/#spatial-search",
            "text": "{\n    \"bool\": {\n        \"must\": {\n            \"match_all\": {}\n         },\n         \"filter\": {\n              \"geo_shape\": {\n                   \"metadata.o2r.spatial.geometry\": {\n                        \"shape\": {\n                            \"type\": \"polygon\",\n                            \"coordinates\": [... GeoJSON coordinates...]\n                         },\n                         \"relation\": \"within\"\n                    }\n               }\n          }\n     }\n}  In this example a filter has been nested within a  boolean/must match  query.\nThe filter has been applied to the  metadata.o2r.spatial.geometry  field of the dataset with a  within  relation so that only compendia with a spatial extent completely contained in the provided shape are fetched.",
            "title": "Spatial search"
        },
        {
            "location": "/search/#response",
            "text": "200 ok\n\n{\n  \"hits\": {\n    \"total\": 1,\n    \"max_score\": 1.0586987,\n    \"hits\": [\n      {\n        \"_score\": 1.0586987,\n        \"_source\": {\n          \"metadata\": {\n            \"o2r\": ...\n          },\n        }\n      }\n    ]\n  }\n}",
            "title": "Response"
        },
        {
            "location": "/shipment/",
            "text": "Ship compendia and metadata\n\n\nShipments are used to deliver compendia and their metadata to third party repositories or archives.\nThis section covers shipment related requests, including repository file management.\n\n\nPackaging\n\n\nThe packaging of a compendium ensures a recipient can verify the integrity of the transported data.\nCurrently, the shipment process always creates \nBagIt\n bags to package a compendium.\n\n\nSupported recipients\n\n\nUse the \nrecipient\n endpoint to find out, which repositories are available and configured.\nThe response is list of tuples with \nid\n and \nlabel\n of each repository.\nThe \nid\n is the repository identifier to be used in requests to the \n/shipment\n endpoint, e.g. to define the recipient, while \nlabel\n is a human-readable text string suitable for display in user interfaces.\n\n\nGET /api/v1/recipient\n\n\n200\n\n{\n    \"recipients\": [{\n        \"id\": \"download\",\n        \"label\": \"Download\"\n    }, {\n        \"id\": \"b2share_sandbox\",\n        \"label\": \"Eudat b2share Sandbox\"\n    }, {\n        \"id\": \"zenodo_sandbox\",\n        \"label\": \"Zenodo Sandbox\"\n    }]\n}\n\n\n\n\nAn implementation may support one or more of the following repositories:\n\n\n\n\nb2share\n - \nEudat b2share\n\n\nb2share_sandbox\n - \nEudat b2share Sandbox\n\n\nzenodo\n - \nZenodo Sandbox\n\n\nzenodo_sandbox\n - \nZenodo Sandbox\n\n\n\n\nThe \ndownload\n recipient is a surrogate to enable shipping to the user's local storage.\n\n\nList shipments\n\n\nThis is a basic request to list all shipment identifiers.\n\n\nGET /api/v1/shipment\n\n\n200\n\n[\"dc351fc6-314f-4947-a235-734ab5971eff\", \"...\"]\n\n\n\n\n\nYou can also get only the shipment identifiers belonging to a compendium id (e.g. \n4XgD97\n).\n\n\nGET /api/v1/shipment?compendium_id=4XgD97\n\n\nURL parameter:\n\n\n\n\ncompendium_id\n - the identifier of a specific compendium\n\n\n\n\n200 \n\n[\"dc351fc6-314f-4947-a235-734ab5971eff\", \"...\"]\n\n\n\n\n\nGet a single shipment\n\n\nGET /api/v1/shipment/dc351fc6-314f-4947-a235-734ab5971eff\n\n\n200 \n\n{\n  \"last_modified\": \"2016-12-12 10:34:32.001475\",\n  \"recipient\": \"zenodo\",\n  \"id\": \"dc351fc6-314f-4947-a235-734ab5971eff\",\n  \"deposition_id\": \"63179\",\n  \"user\": \"0000-0001-6021-1617\",\n  \"status\": \"shipped\",\n  \"compendium_id\": \"4XgD97\",\n  \"deposition_url\": \"https://zenodo.org/record/63179\"\n}\n\n\n\n\n\n\nNote\n\n\nReturned deposition URLs from Zenodo as well as Eudat b2share (records) will only be functional after publishing.\n\n\n\n\nCreate a new shipment\n\n\nYou can start a initial creation of a shipment, leading to transmission to a repository and creation of a deposition, using a \nPOST\n request.\n\n\nPOST /api/v1/shipment\n\n\nThis \nrequires\n the following parameters as \nmultipart/form-data\n or \napplication/x-www-form-urlencoded\n encoded data:\n\n\n\n\ncompendium_id\n (\nstring\n): the id of the compendium\n\n\nrecipient\n (\nstring\n): identifier for the repository\n\n\n\n\nThe following are \noptional parameters\n:\n\n\n\n\nupdate_packaging\n (\nboolean\n, default: \nfalse\n): the shipment creation only succeeds if a valid package is already present under the provided compendium identifier, or if no packaging is present at all and a new package can be created. In case a partial or invalid package is given, this parameter can control the shipment creation process: If it is set to \ntrue\n, the shipment package is updated during the shipment creation in order to make it valid, if set to \nfalse\n the shipment creation will result in an error.\n\n\ncookie\n (\nstring\n): an authentication cookie must be set in the request header, but it may also be provided via a \ncookie\n form parameter as a fallback\n\n\nshipment_id\n (\nstring\n): a user-defined identifier for the shipment (see \nid\n in response)\n\n\n\n\n\n\nRequired user level\n\n\nThe user sending the request to create a shipment must have the required \nuser level\n.\n\n\n\n\nCreation response\n\n\nThe response contains the shipment identifier (\nid\n) and the \ndeposition_id\n, i.e. an identifier provided by the shipment recipient.\n\n\n201\n\n{\n  \"id\": \"9ff3d75e-23dc-423e-a6c6-6987ac5ffc3e\",\n  \"recipient\": \"zenodo\",\n  \"status\": \"shipped\",\n  \"deposition_id\": \"79102\"\n}\n\n\n\n\nIf the recipient is the \ndownload\n surrogate, the response will be \n202\n and a zip stream with the Content type \napplication/zip\n.\n\n\n202\n\n\n\n\n(zip stream starting point)\n\n\nThe download zip stream is also available under the url of the shipment plus \n/dl\n, once it has been created, e.g.:  \n\n\nhttp://localhost:8087/api/v1/shipment/22e7b17c-0047-4cb9-9041-bb87f30de388/dl\n\n\n\n\nShipment status\n\n\nA shipment can have three possible status:\n\n\n\n\nshipped\n - a deposition has been created at a repository and completed the necessary metadata for publication.\n\n\npublished\n - the contents of the shipment are published on the repository, in which case the publishment can not be undone.\n\n\nerror\n - an error occurred during shipment or publishing.\n\n\n\n\nTo get only a shipment's current status you may use the sub-resource \n/status\n:\n\n\nGET api/v1/shipment/<shipment_id>/status\n\n\n200\n\n{\n\"id\": \"9ff3d75e-23dc-423e-a6c6-6987ac5ffc3e\",\n\"status\": \"shipped\"\n}\n\n\n\n\nPublish a deposition\n\n\nThe publishment is supposed to have completed the status \nshipped\n where metadata requirements for publication have been checked.\n\n\n\n\nNote\n\n\nOnce published, a deposition can no longer be deleted on the supported repositories.\n\n\n\n\nPUT api/v1/shipment/<shipment_id>/publishment\n\n\n200\n\n{\n\"id\": \"9ff3d75e-23dc-423e-a6c6-6987ac5ffc3e\",\n\"status\": \"published\"\n}\n\n\n\n\nNote that a publishment is not possible if the recipient is the download surrogate which immediately results in a zip stream as a response.\n\n\nFiles in a deposition\n\n\nList deposition files\n\n\nYou can request a list of all files in a deposition and their properties with the sub-resource \n/publishment\n.\n\n\nGET api/v1/shipment/<shipment_id>/publishment\n\n\n200\n\n{\n\"files\": [{\n    \"filesize\": 393320,\n    \"id\": \"bae2a60c-bd59-47e1-a443-b34bb7d0a981\",\n    \"filename\": \"4XgD9.zip\",\n    \"checksum\": \"702f4db3e53b22176d1d5ddcda462a27\",\n    \"links\": {\n        \"self\": \"https://sandbox.zenodo.org/api/deposit/depositions/71552/files/bae2a60c-bd59-47e1-a443-b34bb7d0a981\",\n        \"download\": \"https://sandbox.zenodo.org/api/files/31dc8f3d-df00-4d8a-bd99-64ef341372b3/4XgD9.zip\"\n    }\n}]\n}\n\n\n\n\nYou can find the \nid\n of the file you want to interact with in this json list object at \nfiles[n].id\n, where \nn\n is the position of that file in the array.\nFiles can be identified in this response by either their id in the depot, their filename or their checksum.\n\n\nDelete a specific file from a deposition\n\n\nYou can delete files from a \nshipped\n shipment's deposition.\nYou must state a file's identifier, which can be retrieved from the shipment's deposition files property \nid\n, as the \nfile_id\n path parameter.\nFiles for a \npublished\n shipment usually cannot be deleted.\n\n\nDELETE api/v1/shipment/<shipment_id>/files/<file_id>\n\n\n204\n\n\n\n\nError responses\n\n\n400\n\n{\"error\":\"bad request\"}\n\n\n\n\n403\n\n{\"error\": \"insufficient permissions\"}",
            "title": "Shipment"
        },
        {
            "location": "/shipment/#ship-compendia-and-metadata",
            "text": "Shipments are used to deliver compendia and their metadata to third party repositories or archives.\nThis section covers shipment related requests, including repository file management.",
            "title": "Ship compendia and metadata"
        },
        {
            "location": "/shipment/#packaging",
            "text": "The packaging of a compendium ensures a recipient can verify the integrity of the transported data.\nCurrently, the shipment process always creates  BagIt  bags to package a compendium.",
            "title": "Packaging"
        },
        {
            "location": "/shipment/#supported-recipients",
            "text": "Use the  recipient  endpoint to find out, which repositories are available and configured.\nThe response is list of tuples with  id  and  label  of each repository.\nThe  id  is the repository identifier to be used in requests to the  /shipment  endpoint, e.g. to define the recipient, while  label  is a human-readable text string suitable for display in user interfaces.  GET /api/v1/recipient  200\n\n{\n    \"recipients\": [{\n        \"id\": \"download\",\n        \"label\": \"Download\"\n    }, {\n        \"id\": \"b2share_sandbox\",\n        \"label\": \"Eudat b2share Sandbox\"\n    }, {\n        \"id\": \"zenodo_sandbox\",\n        \"label\": \"Zenodo Sandbox\"\n    }]\n}  An implementation may support one or more of the following repositories:   b2share  -  Eudat b2share  b2share_sandbox  -  Eudat b2share Sandbox  zenodo  -  Zenodo Sandbox  zenodo_sandbox  -  Zenodo Sandbox   The  download  recipient is a surrogate to enable shipping to the user's local storage.",
            "title": "Supported recipients"
        },
        {
            "location": "/shipment/#list-shipments",
            "text": "This is a basic request to list all shipment identifiers.  GET /api/v1/shipment  200\n\n[\"dc351fc6-314f-4947-a235-734ab5971eff\", \"...\"]  You can also get only the shipment identifiers belonging to a compendium id (e.g.  4XgD97 ).  GET /api/v1/shipment?compendium_id=4XgD97  URL parameter:   compendium_id  - the identifier of a specific compendium   200 \n\n[\"dc351fc6-314f-4947-a235-734ab5971eff\", \"...\"]",
            "title": "List shipments"
        },
        {
            "location": "/shipment/#get-a-single-shipment",
            "text": "GET /api/v1/shipment/dc351fc6-314f-4947-a235-734ab5971eff  200 \n\n{\n  \"last_modified\": \"2016-12-12 10:34:32.001475\",\n  \"recipient\": \"zenodo\",\n  \"id\": \"dc351fc6-314f-4947-a235-734ab5971eff\",\n  \"deposition_id\": \"63179\",\n  \"user\": \"0000-0001-6021-1617\",\n  \"status\": \"shipped\",\n  \"compendium_id\": \"4XgD97\",\n  \"deposition_url\": \"https://zenodo.org/record/63179\"\n}   Note  Returned deposition URLs from Zenodo as well as Eudat b2share (records) will only be functional after publishing.",
            "title": "Get a single shipment"
        },
        {
            "location": "/shipment/#create-a-new-shipment",
            "text": "You can start a initial creation of a shipment, leading to transmission to a repository and creation of a deposition, using a  POST  request.  POST /api/v1/shipment  This  requires  the following parameters as  multipart/form-data  or  application/x-www-form-urlencoded  encoded data:   compendium_id  ( string ): the id of the compendium  recipient  ( string ): identifier for the repository   The following are  optional parameters :   update_packaging  ( boolean , default:  false ): the shipment creation only succeeds if a valid package is already present under the provided compendium identifier, or if no packaging is present at all and a new package can be created. In case a partial or invalid package is given, this parameter can control the shipment creation process: If it is set to  true , the shipment package is updated during the shipment creation in order to make it valid, if set to  false  the shipment creation will result in an error.  cookie  ( string ): an authentication cookie must be set in the request header, but it may also be provided via a  cookie  form parameter as a fallback  shipment_id  ( string ): a user-defined identifier for the shipment (see  id  in response)    Required user level  The user sending the request to create a shipment must have the required  user level .",
            "title": "Create a new shipment"
        },
        {
            "location": "/shipment/#creation-response",
            "text": "The response contains the shipment identifier ( id ) and the  deposition_id , i.e. an identifier provided by the shipment recipient.  201\n\n{\n  \"id\": \"9ff3d75e-23dc-423e-a6c6-6987ac5ffc3e\",\n  \"recipient\": \"zenodo\",\n  \"status\": \"shipped\",\n  \"deposition_id\": \"79102\"\n}  If the recipient is the  download  surrogate, the response will be  202  and a zip stream with the Content type  application/zip .  202  (zip stream starting point)  The download zip stream is also available under the url of the shipment plus  /dl , once it has been created, e.g.:    http://localhost:8087/api/v1/shipment/22e7b17c-0047-4cb9-9041-bb87f30de388/dl",
            "title": "Creation response"
        },
        {
            "location": "/shipment/#shipment-status",
            "text": "A shipment can have three possible status:   shipped  - a deposition has been created at a repository and completed the necessary metadata for publication.  published  - the contents of the shipment are published on the repository, in which case the publishment can not be undone.  error  - an error occurred during shipment or publishing.   To get only a shipment's current status you may use the sub-resource  /status :  GET api/v1/shipment/<shipment_id>/status  200\n\n{\n\"id\": \"9ff3d75e-23dc-423e-a6c6-6987ac5ffc3e\",\n\"status\": \"shipped\"\n}",
            "title": "Shipment status"
        },
        {
            "location": "/shipment/#publish-a-deposition",
            "text": "The publishment is supposed to have completed the status  shipped  where metadata requirements for publication have been checked.   Note  Once published, a deposition can no longer be deleted on the supported repositories.   PUT api/v1/shipment/<shipment_id>/publishment  200\n\n{\n\"id\": \"9ff3d75e-23dc-423e-a6c6-6987ac5ffc3e\",\n\"status\": \"published\"\n}  Note that a publishment is not possible if the recipient is the download surrogate which immediately results in a zip stream as a response.",
            "title": "Publish a deposition"
        },
        {
            "location": "/shipment/#files-in-a-deposition",
            "text": "",
            "title": "Files in a deposition"
        },
        {
            "location": "/shipment/#list-deposition-files",
            "text": "You can request a list of all files in a deposition and their properties with the sub-resource  /publishment .  GET api/v1/shipment/<shipment_id>/publishment  200\n\n{\n\"files\": [{\n    \"filesize\": 393320,\n    \"id\": \"bae2a60c-bd59-47e1-a443-b34bb7d0a981\",\n    \"filename\": \"4XgD9.zip\",\n    \"checksum\": \"702f4db3e53b22176d1d5ddcda462a27\",\n    \"links\": {\n        \"self\": \"https://sandbox.zenodo.org/api/deposit/depositions/71552/files/bae2a60c-bd59-47e1-a443-b34bb7d0a981\",\n        \"download\": \"https://sandbox.zenodo.org/api/files/31dc8f3d-df00-4d8a-bd99-64ef341372b3/4XgD9.zip\"\n    }\n}]\n}  You can find the  id  of the file you want to interact with in this json list object at  files[n].id , where  n  is the position of that file in the array.\nFiles can be identified in this response by either their id in the depot, their filename or their checksum.",
            "title": "List deposition files"
        },
        {
            "location": "/shipment/#delete-a-specific-file-from-a-deposition",
            "text": "You can delete files from a  shipped  shipment's deposition.\nYou must state a file's identifier, which can be retrieved from the shipment's deposition files property  id , as the  file_id  path parameter.\nFiles for a  published  shipment usually cannot be deleted.  DELETE api/v1/shipment/<shipment_id>/files/<file_id>  204",
            "title": "Delete a specific file from a deposition"
        },
        {
            "location": "/shipment/#error-responses",
            "text": "400\n\n{\"error\":\"bad request\"}  403\n\n{\"error\": \"insufficient permissions\"}",
            "title": "Error responses"
        },
        {
            "location": "/user/",
            "text": "User\n\n\nList users\n\n\nReturn a list of user ids. \nPagination (including defaults) as described for compendia\n is available for users.\n\n\ncurl https://\u2026/api/v1/user\n\n\nGET /api/v1/user\n\n\n200 OK\n\n{\n    \"results\": [\n        \"0000-0002-1825-0097\",\n        \"0000-0001-6021-1617\"\n    ]\n}\n\n\n\n\nView single user\n\n\nShow the details of a user.\n\n\ncurl https://\u2026/api/v1/user/$ID\n\n\nGET /api/v1/user/:id\n\n\n200 OK\n\n{\n    \"id\": \"0000-0001-6021-1617\",\n    \"name\": \"o2r\"\n}\n\n\n\n\nThe content of the response depends on the state and level of the user that requests the resource. The above response only contains the id and the publicly visible name. The following response contains more details and requires a certain user level of the authenticated user making the request:\n\n\ncurl --cookie \"connect.sid=<session cookie here>\" https://\u2026/api/v1/user/0000-0001-6021-1617\n\n\n200 OK\n\n{\n    \"id\": \"0000-0001-6021-1617\",\n    \"name\": \"o2r\",\n    \"level\": 0,\n    \"lastseen\": \"2016-08-15T12:32:23.972Z\"\n}\n\n\n\n\nURL parameters for single user view\n\n\n\n\n:id\n - the user id\n\n\n\n\nError responses for single user view\n\n\n404 Not Found\n\n{\"error\":\"no user with this id\"}\n\n\n\n\nAuthentication\n\n\nUser authentication is done via authenticated sessions, which are referenced with a cookie called \nconnect.sid\n. For every endpoint that needs user authentication, a cookie with an authenticated session is required.\n\n\nAccess authentication information for direct API access\n\n\nTo run commands which require authentication from the command line, a user must login on the website first. Then open you browser cookies and find a cookie issued by \no2r.uni-muenster.de\n with the name \nconnect.sid\n. Use the the contents of the cookie for your requests, for example as shown below when using curl.\n\n\ncurl [...] --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/endpoint\n\n\n\n\nAuthentication within microservices\n\n\nAttention:\n The authentication process \nrequires\n a secured connection, i.e. \nHTTPS\n.\n\n\nAuthentication provider\n\n\nSession authentication is done using the OAuth 2.0 protocol. Currently \nORCID\n is the only available authentication provider, therefore users need to be registered with ORCID. Because of its nature, the authentication workflow is not a RESTful service. Users will need to navigate to the login endpoint with their webbrowser and grant access to the o2r platform for their ORCID account. They will then be sent back to our authentication service, which verifies the authentification request and enriches the user session with the verified ORCID for this user.\n\n\nStart OAuth login\n\n\nNavigate the webbrowser (e.g. via a HTML \n<a>\n link) to \n/api/v1/auth/login\n, which will then redirect the user and request access to your ORCID profile. After granting access, ORCID will redirect the user back to the \n/api/v1/auth/login\n endpoint with a unique \ncode\n param that is used to verify the request.\n\n\nIf the verification was successful, the endpoint returns a session cookie named \nconnect.sid\n, which is tied to a authenticated session. The server answers with a \n301 redirect\n, which redirects the user back to \n/\n, where the o2r platform webinterface resides.\n\n\nIf the login is unsuccessful, the user is not redirected back to the site and no further redirects are configured.\n\n\nRequest authentication status\n\n\nAs the cookie is present in both authenticated and unauthenticated sessions, clients (e.g. webbrowsers) will need to know if their session is authenticated, and if so, as which ORCID user. For this, send a \nGET\n request to the \n/api/v1/auth/whoami\n endpoint, including your session cookie.\n\n\ncurl https://\u2026/api/v1/auth/whoami --cookie \"connect.sid=\u2026\n\n\nGET /api/v1/auth/whoami\n\n\n200 OK\n\n{\n  \"orcid\": \"0000-0001-6021-1617\",\n  \"name\": \"o2r\"\n}\n\n\n\n\nError response for requests requiring authentication\n\n\nWhen no session cookie was included, or the included session cookie does not belong to a authenticated session, the service will respond with a \n401 Unauthorized\n message.\n\n\n401 Unauthorized\n\n{\n  \"error\": \"not authenticated\"\n}\n\n\n\n\nUser levels\n\n\nUsers are authenticated via OAuth and the actions on the website are limited by the \nlevel\n assocciated with an account.\nOn registration, each account is assigned a level \n0\n.\nOnly admin users and the user herself can read the level of a user.\n\n\nThe following is a list of actions and the corresponding required \nminimum\n user level.\n\n\n\n\n0\n \nUsers\n (everybody)\n\n\nCreate new jobs\n\n\nView compendia, jobs, user details\n\n\n\n\n\n\n100\n \nKnown users\n\n\nCreate new compendium\n\n\nCreate shipments\n\n\nCreate substitutions\n\n\nDelete own candidates\n\n\n\n\n\n\n500\n \nEditors\n\n\nEdit user levels\n\n\nEdit metadata of other user's compendia\n\n\nView other user's candidates\n\n\n\n\n\n\n1000\n \nAdmins\n\n\nDelete candidates\n\n\nView status pages of microservices\n\n\n\n\n\n\n\n\nEdit user\n\n\nYou can update information of an existing user using the \nHTTP\n operation \nPATCH\n.\n\n\nChange user level request\n\n\nThe user level can be changed with an \nHTTP\n \nPATCH\n request.\nThe new level is passed to the API via a query parameter, i.e. \n..?level=<new level value>\n.\nThe value must be an \nint\n (integer).\nThe response is the full user document with the updated value.\n\n\n\n\nRequired user level\n\n\nThe user sending the request to change the level must have the required \nuser level\n.\n\n\n\n\ncurl --request PATCH --cookie \"connect.sid=<session cookie here>\" \\\n  https://\u2026/api/v1/user/0000-0001-6021-1617?level=42`\n\n\n\n\n200 OK\n\n{\n    \"id\": \"0000-0001-6021-1617\",\n    \"name\": \"o2r\",\n    \"level\": 42,\n    \"lastseen\": \"2016-08-15T12:32:23.972Z\"\n}\n\n\n\n\nError responses for user level change\n\n\n401 Unauthorized\n\n{\n  \"error\": \"user is not authenticated\"\n}\n\n\n\n\n401 Unauthorized\n\n{\n  \"error\": \"user level does not allow edit\"\n}\n\n\n\n\n400 Bad Request\n\n{\n  \"error\": \"parameter 'level' could not be parsed as an integer\"\n}",
            "title": "User"
        },
        {
            "location": "/user/#user",
            "text": "",
            "title": "User"
        },
        {
            "location": "/user/#list-users",
            "text": "Return a list of user ids.  Pagination (including defaults) as described for compendia  is available for users.  curl https://\u2026/api/v1/user  GET /api/v1/user  200 OK\n\n{\n    \"results\": [\n        \"0000-0002-1825-0097\",\n        \"0000-0001-6021-1617\"\n    ]\n}",
            "title": "List users"
        },
        {
            "location": "/user/#view-single-user",
            "text": "Show the details of a user.  curl https://\u2026/api/v1/user/$ID  GET /api/v1/user/:id  200 OK\n\n{\n    \"id\": \"0000-0001-6021-1617\",\n    \"name\": \"o2r\"\n}  The content of the response depends on the state and level of the user that requests the resource. The above response only contains the id and the publicly visible name. The following response contains more details and requires a certain user level of the authenticated user making the request:  curl --cookie \"connect.sid=<session cookie here>\" https://\u2026/api/v1/user/0000-0001-6021-1617  200 OK\n\n{\n    \"id\": \"0000-0001-6021-1617\",\n    \"name\": \"o2r\",\n    \"level\": 0,\n    \"lastseen\": \"2016-08-15T12:32:23.972Z\"\n}",
            "title": "View single user"
        },
        {
            "location": "/user/#url-parameters-for-single-user-view",
            "text": ":id  - the user id",
            "title": "URL parameters for single user view"
        },
        {
            "location": "/user/#error-responses-for-single-user-view",
            "text": "404 Not Found\n\n{\"error\":\"no user with this id\"}",
            "title": "Error responses for single user view"
        },
        {
            "location": "/user/#authentication",
            "text": "User authentication is done via authenticated sessions, which are referenced with a cookie called  connect.sid . For every endpoint that needs user authentication, a cookie with an authenticated session is required.",
            "title": "Authentication"
        },
        {
            "location": "/user/#access-authentication-information-for-direct-api-access",
            "text": "To run commands which require authentication from the command line, a user must login on the website first. Then open you browser cookies and find a cookie issued by  o2r.uni-muenster.de  with the name  connect.sid . Use the the contents of the cookie for your requests, for example as shown below when using curl.  curl [...] --cookie \"connect.sid=<code string here>\" \\\n     https://\u2026/api/v1/endpoint",
            "title": "Access authentication information for direct API access"
        },
        {
            "location": "/user/#authentication-within-microservices",
            "text": "Attention:  The authentication process  requires  a secured connection, i.e.  HTTPS .",
            "title": "Authentication within microservices"
        },
        {
            "location": "/user/#authentication-provider",
            "text": "Session authentication is done using the OAuth 2.0 protocol. Currently  ORCID  is the only available authentication provider, therefore users need to be registered with ORCID. Because of its nature, the authentication workflow is not a RESTful service. Users will need to navigate to the login endpoint with their webbrowser and grant access to the o2r platform for their ORCID account. They will then be sent back to our authentication service, which verifies the authentification request and enriches the user session with the verified ORCID for this user.",
            "title": "Authentication provider"
        },
        {
            "location": "/user/#start-oauth-login",
            "text": "Navigate the webbrowser (e.g. via a HTML  <a>  link) to  /api/v1/auth/login , which will then redirect the user and request access to your ORCID profile. After granting access, ORCID will redirect the user back to the  /api/v1/auth/login  endpoint with a unique  code  param that is used to verify the request.  If the verification was successful, the endpoint returns a session cookie named  connect.sid , which is tied to a authenticated session. The server answers with a  301 redirect , which redirects the user back to  / , where the o2r platform webinterface resides.  If the login is unsuccessful, the user is not redirected back to the site and no further redirects are configured.",
            "title": "Start OAuth login"
        },
        {
            "location": "/user/#request-authentication-status",
            "text": "As the cookie is present in both authenticated and unauthenticated sessions, clients (e.g. webbrowsers) will need to know if their session is authenticated, and if so, as which ORCID user. For this, send a  GET  request to the  /api/v1/auth/whoami  endpoint, including your session cookie.  curl https://\u2026/api/v1/auth/whoami --cookie \"connect.sid=\u2026  GET /api/v1/auth/whoami  200 OK\n\n{\n  \"orcid\": \"0000-0001-6021-1617\",\n  \"name\": \"o2r\"\n}",
            "title": "Request authentication status"
        },
        {
            "location": "/user/#error-response-for-requests-requiring-authentication",
            "text": "When no session cookie was included, or the included session cookie does not belong to a authenticated session, the service will respond with a  401 Unauthorized  message.  401 Unauthorized\n\n{\n  \"error\": \"not authenticated\"\n}",
            "title": "Error response for requests requiring authentication"
        },
        {
            "location": "/user/#user-levels",
            "text": "Users are authenticated via OAuth and the actions on the website are limited by the  level  assocciated with an account.\nOn registration, each account is assigned a level  0 .\nOnly admin users and the user herself can read the level of a user.  The following is a list of actions and the corresponding required  minimum  user level.   0   Users  (everybody)  Create new jobs  View compendia, jobs, user details    100   Known users  Create new compendium  Create shipments  Create substitutions  Delete own candidates    500   Editors  Edit user levels  Edit metadata of other user's compendia  View other user's candidates    1000   Admins  Delete candidates  View status pages of microservices",
            "title": "User levels"
        },
        {
            "location": "/user/#edit-user",
            "text": "You can update information of an existing user using the  HTTP  operation  PATCH .",
            "title": "Edit user"
        },
        {
            "location": "/user/#change-user-level-request",
            "text": "The user level can be changed with an  HTTP   PATCH  request.\nThe new level is passed to the API via a query parameter, i.e.  ..?level=<new level value> .\nThe value must be an  int  (integer).\nThe response is the full user document with the updated value.   Required user level  The user sending the request to change the level must have the required  user level .   curl --request PATCH --cookie \"connect.sid=<session cookie here>\" \\\n  https://\u2026/api/v1/user/0000-0001-6021-1617?level=42`  200 OK\n\n{\n    \"id\": \"0000-0001-6021-1617\",\n    \"name\": \"o2r\",\n    \"level\": 42,\n    \"lastseen\": \"2016-08-15T12:32:23.972Z\"\n}",
            "title": "Change user level request"
        },
        {
            "location": "/user/#error-responses-for-user-level-change",
            "text": "401 Unauthorized\n\n{\n  \"error\": \"user is not authenticated\"\n}  401 Unauthorized\n\n{\n  \"error\": \"user level does not allow edit\"\n}  400 Bad Request\n\n{\n  \"error\": \"parameter 'level' could not be parsed as an integer\"\n}",
            "title": "Error responses for user level change"
        }
    ]
}