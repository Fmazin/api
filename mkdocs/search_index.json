{
    "docs": [
        {
            "location": "/",
            "text": "o2r web API documentation\n\n\n\n\nCurrent version of the API\n: \nv1\n (subject to change)\n\n\nAbout\n\n\nThe o2r web API acts as the interface between the \no2r\n \nmicroservices\n and the \nweb interface\n.\n\n\nThe API provides services around the executable research compendium (ERC), or \"compendium\" for short, which is documented \nin the ERC spec\n.\n\n\nGeneral notes\n\n\nIt is implemented as a RESTful API. The entrypoint for the current version is \n/api/v1\n.\n\n\nUnless specified otherwise, responses are always in JSON format.\nBody parameters in \nPOST\n requests are expected in \nmultipart/form-data\n format.\nRequests to the API should always be made with a secure connection using \nHTTPS\n.\n\n\nWe also provide a \nsimple Postman collection\n (\ngetpostman.com\n), so that you can comfortably explore the API.\n\n\nLicense\n\n\n\n\nThe o2r Executable Research Compendium specification is licensed under \nCreative Commons CC0 1.0 Universal License\n, see file \nLICENSE\n.\nTo the extent possible under law, the people who associated CC0 with this work have waived all copyright and related or neighboring rights to this work.\nThis work is published from: Germany.",
            "title": "Home"
        },
        {
            "location": "/#o2r-web-api-documentation",
            "text": "Current version of the API :  v1  (subject to change)",
            "title": "o2r web API documentation"
        },
        {
            "location": "/#about",
            "text": "The o2r web API acts as the interface between the  o2r   microservices  and the  web interface .  The API provides services around the executable research compendium (ERC), or \"compendium\" for short, which is documented  in the ERC spec .",
            "title": "About"
        },
        {
            "location": "/#general-notes",
            "text": "It is implemented as a RESTful API. The entrypoint for the current version is  /api/v1 .  Unless specified otherwise, responses are always in JSON format.\nBody parameters in  POST  requests are expected in  multipart/form-data  format.\nRequests to the API should always be made with a secure connection using  HTTPS .  We also provide a  simple Postman collection  ( getpostman.com ), so that you can comfortably explore the API.",
            "title": "General notes"
        },
        {
            "location": "/#license",
            "text": "The o2r Executable Research Compendium specification is licensed under  Creative Commons CC0 1.0 Universal License , see file  LICENSE .\nTo the extent possible under law, the people who associated CC0 with this work have waived all copyright and related or neighboring rights to this work.\nThis work is published from: Germany.",
            "title": "License"
        },
        {
            "location": "/compendium/upload/",
            "text": "Upload via API\n\n\nUpload a unvalidated research compendium as a compressed \n.zip\n archive.\n\n\nThe upload is only allowed for logged in users. To run the upload from the command line, login on the website and open you browser cookies. Find a cookie issued by \no2r.uni-muenster.de\n with the name \nconnect.sid\n. Copy the contents of the cookie into the request example below.\n\n\nUpon successful extraction of archive, the \nid\n for the new compendium is returned.\n\n\ncurl -F \"compendium=@compendium.zip;type=application/zip\" \\\n    -F content_type=compendium_v1 http://\u2026/api/v1/compendium \\\n    --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/compendium \n\n\n\n\n200 OK\n\n{\"id\":\"a4Ndl\"}\n\n\n\n\nBody parameters for compendium upload\n\n\n\n\ncompendium\n - The archive file\n\n\ncontent_type\n - Form of archive. One of the following:\n\n\ncompendium_v1\n - \ndefault\n - compendium in Bagtainer format\n\n\nworkspace\n - \nWORK IN PROGRESS\n - formless workspace\n\n\n\n\nError responses for compendium upload\n\n\n401 Unauthorized\n\n{\"error\":\"missing or wrong api key\"}\n\n\n\n\nExample data\n\n\nFor local testing you can quickly upload some of the example compendia using a Docker image that is part of the \no2r-bagtainers\n project.\nThe following command executes the container and uploads 7 empty examples and two selected bagtainers to a server running at the Docker host IP.\n\n\ndocker run --rm o2rproject/examplecompendia -c <my cookie> -e 7 -b 0003 -b 0004 -b 0005\n\n\n\n\nFor more configuration details, see the project's README file.",
            "title": "API upload"
        },
        {
            "location": "/compendium/upload/#upload-via-api",
            "text": "Upload a unvalidated research compendium as a compressed  .zip  archive.  The upload is only allowed for logged in users. To run the upload from the command line, login on the website and open you browser cookies. Find a cookie issued by  o2r.uni-muenster.de  with the name  connect.sid . Copy the contents of the cookie into the request example below.  Upon successful extraction of archive, the  id  for the new compendium is returned.  curl -F \"compendium=@compendium.zip;type=application/zip\" \\\n    -F content_type=compendium_v1 http://\u2026/api/v1/compendium \\\n    --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/compendium   200 OK\n\n{\"id\":\"a4Ndl\"}",
            "title": "Upload via API"
        },
        {
            "location": "/compendium/upload/#body-parameters-for-compendium-upload",
            "text": "compendium  - The archive file  content_type  - Form of archive. One of the following:  compendium_v1  -  default  - compendium in Bagtainer format  workspace  -  WORK IN PROGRESS  - formless workspace",
            "title": "Body parameters for compendium upload"
        },
        {
            "location": "/compendium/upload/#error-responses-for-compendium-upload",
            "text": "401 Unauthorized\n\n{\"error\":\"missing or wrong api key\"}",
            "title": "Error responses for compendium upload"
        },
        {
            "location": "/compendium/upload/#example-data",
            "text": "For local testing you can quickly upload some of the example compendia using a Docker image that is part of the  o2r-bagtainers  project.\nThe following command executes the container and uploads 7 empty examples and two selected bagtainers to a server running at the Docker host IP.  docker run --rm o2rproject/examplecompendia -c <my cookie> -e 7 -b 0003 -b 0004 -b 0005  For more configuration details, see the project's README file.",
            "title": "Example data"
        },
        {
            "location": "/compendium/public_share/",
            "text": "Public share\n\n\nUpload an unvalidated research compendium by submitting a link to a cloud resource.\n\n\nCurrently, the following repositories are supported:\n\n\n\n\nSciebo (https://sciebo.de)\n\n\nZenodo or Zenodo Sandbox (https://zenodo.org or https://sandbox.zenodo.org)\n\n\n\n\nThe upload is only allowed for logged in users. To run the upload from the command line, login on the website and open you browser cookies. Find a cookie issued by \no2r.uni-muenster.de\n with the name \nconnect.sid\n. Copy the contents of the cookie into the request example below.\n\n\nUpon successful download from the public share, the \nid\n for the new compendium is returned.\n\n\ncurl -d \"content_type=compendium_v1\" \\\n    -d \"share_url=https://uni-muenster.sciebo.de/index.php/s/G8vxQ1h50V4HpuA\"  \\\n    --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/compendium\n\n\n\n\n200 OK\n\n{\"id\":\"b9Faz\"}\n\n\n\n\nBoth use the same API endpoint \nhttp://\u2026/api/v1/compendium\n but with different required/optional parameters:\n\n\nSciebo\n\n\nFile selection\n\n\nDepending on the file structure, the public share contents are treated differently:\n\n\n\n\nIf a file named \nbagit.txt\n is found, the directory will be treated as a research compendium\n\n\nIf a single zip file is found, the file will be extracted and treated as a research compendium\n\n\nIf a single subdirectory is found, the loader will look for subdirectories and analyze their contents \n(NOT_IMPLEMENTED)\n\n\nIf multiple files or subdirectories are found, the public share contents are treated as a workspace \n(NOT IMPLEMENTED)\n\n\n\n\nBody parameters for creating compendium from public share\n\n\n\n\nshare_url\n - The sciebo link to the public share (required)\n\n\ncontent_type\n - Form of archive. One of the following (required):\n\n\ncompendium_v1\n compendium in Bagtainer format\n\n\nworkspace\n - \n[NOT IMPLEMENTED]\n - formless workspace\n\n\n\n\n\n\npath\n - Path to a subdirectory in the public share (optional)\n\n\ndefault is \n/\n\n\n\n\n\n\n\n\nExamples\n\n\ncurl -d \"content_type=compendium_v1\" \\\n    -d \"share_url=https://uni-muenster.sciebo.de/index.php/s/G8vxQ1h50V4HpuA\"  \\\n    -d \"path=/metatainer\" \\\n    --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/compendium\n\n\n\n\nError responses for creating compendium from public share\n\n\n401 Unauthorized\n\n{\"error\":\"unauthorized: user level does not allow compendium creation\"}\n\n\n\n\n403 Forbidden\n\n{\"error\":\"public share host is not allowed\"}\n\n\n\n\nExample data\n\n\nFor testing purposes you can use the following public share. It contains a few ready-to-use compendia found in the \no2r-bagtainers\n project:\n\n\nhttps://uni-muenster.sciebo.de/index.php/s/7EoWgjLSFVV89AO\n\n\nZenodo\n\n\nBody parameters for creating compendium from a Zenodo record\n\n\n\n\nshare_url\n - The link to the zenodo record (optional). May be a link to https://zenodo.org or https://doi.org\n\n\ndoi\n - A \nDOI\n resolving to the zenodo record (optional)\n\n\nzenodo_record_id\n - The ID of the zenodo record (optional)\n\n\ncontent_type\n - Form of archive. One of the following (required):\n\n\ncompendium_v1\n compendium in Bagtainer format\n\n\nworkspace\n - \n[NOT IMPLEMENTED]\n - formless workspace\n\n\n\n\n\n\nfilename\n - Filename of your compendium. For now, only zip-files are supported. (optional)\n\n\nif no \nfilename\n is provided the first zip file is selected\n\n\nmultiple files are currently not supported\n\n\n\n\n\n\n\n\nThere must at least one url parameter that resolves to a zenodo record. I.e. one of the following:\n\n\n\n\nshare_url\n\n\ndoi\n\n\nzenodo_record_id\n\n\n\n\nExamples\n\n\n\n\nZenodo Record URL (with optional filename parameter)\n\n\n\n\ncurl -d \"content_type=compendium_v1\" \\\n    -d \"zenodo_url=https://sandbox.zenodo.org/record/69114\"  \\\n    -d \"filename=metatainer.zip\" \\\n    --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/compendium\n\n\n\n\n\n\nDOI\n\n\n\n\ncurl -d \"content_type=compendium_v1\" \\\n    -d \"doi=10.5072/zenodo.69114\"  \\\n    --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/compendium\n\n\n\n\n\n\nZenodo Record ID\n\n\n\n\ncurl -d \"content_type=compendium_v1\" \\\n    -d \"zenodo_record_id=69114\"  \\\n    --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/compendium\n\n\n\n\nIf the Zenodo record id is supplied through the \ndoi\n or \nzenodo_record_id\n parameter, or if the \nshare_url\n parameter is a \ndoi.org\n URL, a default base URL for the file download is used as selected by the API maintainer. This may be:\n\n\n\n\nhttps://zenodo.org\n or\n\n\nhttps://sandbox.zenodo.org\n\n\n\n\nError responses for creating compendium from a Zenodo record\n\n\n401 Unauthorized\n\n{\"error\":\"unauthorized: user level does not allow compendium creation\"}\n\n\n\n\n403 Forbidden\n\n{\"error\":\"host is not allowed\"}\n\n\n\n\n422 Unprocessable Entity\n\n{\"error\":\"public share URL is invalid\"}\n\n\n\n\n422 Unprocessable Entity\n\n{\"error\":\"DOI is invalid\"}\n\n\n\n\nExample data\n\n\nFor testing purposes you can use the following public shares. These contain the \nmetatainer\n compendium found in the \no2r-bagtainers\n project:\n\n\n\n\nSciebo: \nhttps://uni-muenster.sciebo.de/index.php/s/G8vxQ1h50V4HpuA\n\n\nZenodo: \nhttps://sandbox.zenodo.org/record/69114",
            "title": "Public share submission"
        },
        {
            "location": "/compendium/public_share/#public-share",
            "text": "Upload an unvalidated research compendium by submitting a link to a cloud resource.  Currently, the following repositories are supported:   Sciebo (https://sciebo.de)  Zenodo or Zenodo Sandbox (https://zenodo.org or https://sandbox.zenodo.org)   The upload is only allowed for logged in users. To run the upload from the command line, login on the website and open you browser cookies. Find a cookie issued by  o2r.uni-muenster.de  with the name  connect.sid . Copy the contents of the cookie into the request example below.  Upon successful download from the public share, the  id  for the new compendium is returned.  curl -d \"content_type=compendium_v1\" \\\n    -d \"share_url=https://uni-muenster.sciebo.de/index.php/s/G8vxQ1h50V4HpuA\"  \\\n    --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/compendium  200 OK\n\n{\"id\":\"b9Faz\"}  Both use the same API endpoint  http://\u2026/api/v1/compendium  but with different required/optional parameters:",
            "title": "Public share"
        },
        {
            "location": "/compendium/public_share/#sciebo",
            "text": "",
            "title": "Sciebo"
        },
        {
            "location": "/compendium/public_share/#file-selection",
            "text": "Depending on the file structure, the public share contents are treated differently:   If a file named  bagit.txt  is found, the directory will be treated as a research compendium  If a single zip file is found, the file will be extracted and treated as a research compendium  If a single subdirectory is found, the loader will look for subdirectories and analyze their contents  (NOT_IMPLEMENTED)  If multiple files or subdirectories are found, the public share contents are treated as a workspace  (NOT IMPLEMENTED)",
            "title": "File selection"
        },
        {
            "location": "/compendium/public_share/#body-parameters-for-creating-compendium-from-public-share",
            "text": "share_url  - The sciebo link to the public share (required)  content_type  - Form of archive. One of the following (required):  compendium_v1  compendium in Bagtainer format  workspace  -  [NOT IMPLEMENTED]  - formless workspace    path  - Path to a subdirectory in the public share (optional)  default is  /",
            "title": "Body parameters for creating compendium from public share"
        },
        {
            "location": "/compendium/public_share/#examples",
            "text": "curl -d \"content_type=compendium_v1\" \\\n    -d \"share_url=https://uni-muenster.sciebo.de/index.php/s/G8vxQ1h50V4HpuA\"  \\\n    -d \"path=/metatainer\" \\\n    --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/compendium",
            "title": "Examples"
        },
        {
            "location": "/compendium/public_share/#error-responses-for-creating-compendium-from-public-share",
            "text": "401 Unauthorized\n\n{\"error\":\"unauthorized: user level does not allow compendium creation\"}  403 Forbidden\n\n{\"error\":\"public share host is not allowed\"}",
            "title": "Error responses for creating compendium from public share"
        },
        {
            "location": "/compendium/public_share/#example-data",
            "text": "For testing purposes you can use the following public share. It contains a few ready-to-use compendia found in the  o2r-bagtainers  project:  https://uni-muenster.sciebo.de/index.php/s/7EoWgjLSFVV89AO",
            "title": "Example data"
        },
        {
            "location": "/compendium/public_share/#zenodo",
            "text": "",
            "title": "Zenodo"
        },
        {
            "location": "/compendium/public_share/#body-parameters-for-creating-compendium-from-a-zenodo-record",
            "text": "share_url  - The link to the zenodo record (optional). May be a link to https://zenodo.org or https://doi.org  doi  - A  DOI  resolving to the zenodo record (optional)  zenodo_record_id  - The ID of the zenodo record (optional)  content_type  - Form of archive. One of the following (required):  compendium_v1  compendium in Bagtainer format  workspace  -  [NOT IMPLEMENTED]  - formless workspace    filename  - Filename of your compendium. For now, only zip-files are supported. (optional)  if no  filename  is provided the first zip file is selected  multiple files are currently not supported     There must at least one url parameter that resolves to a zenodo record. I.e. one of the following:   share_url  doi  zenodo_record_id",
            "title": "Body parameters for creating compendium from a Zenodo record"
        },
        {
            "location": "/compendium/public_share/#examples_1",
            "text": "Zenodo Record URL (with optional filename parameter)   curl -d \"content_type=compendium_v1\" \\\n    -d \"zenodo_url=https://sandbox.zenodo.org/record/69114\"  \\\n    -d \"filename=metatainer.zip\" \\\n    --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/compendium   DOI   curl -d \"content_type=compendium_v1\" \\\n    -d \"doi=10.5072/zenodo.69114\"  \\\n    --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/compendium   Zenodo Record ID   curl -d \"content_type=compendium_v1\" \\\n    -d \"zenodo_record_id=69114\"  \\\n    --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/compendium  If the Zenodo record id is supplied through the  doi  or  zenodo_record_id  parameter, or if the  share_url  parameter is a  doi.org  URL, a default base URL for the file download is used as selected by the API maintainer. This may be:   https://zenodo.org  or  https://sandbox.zenodo.org",
            "title": "Examples"
        },
        {
            "location": "/compendium/public_share/#error-responses-for-creating-compendium-from-a-zenodo-record",
            "text": "401 Unauthorized\n\n{\"error\":\"unauthorized: user level does not allow compendium creation\"}  403 Forbidden\n\n{\"error\":\"host is not allowed\"}  422 Unprocessable Entity\n\n{\"error\":\"public share URL is invalid\"}  422 Unprocessable Entity\n\n{\"error\":\"DOI is invalid\"}",
            "title": "Error responses for creating compendium from a Zenodo record"
        },
        {
            "location": "/compendium/public_share/#example-data_1",
            "text": "For testing purposes you can use the following public shares. These contain the  metatainer  compendium found in the  o2r-bagtainers  project:   Sciebo:  https://uni-muenster.sciebo.de/index.php/s/G8vxQ1h50V4HpuA  Zenodo:  https://sandbox.zenodo.org/record/69114",
            "title": "Example data"
        },
        {
            "location": "/compendium/view/",
            "text": "View compendium\n\n\nList compendia\n\n\nWill return up to 100 results by default.\n\n\ncurl https://\u2026/api/v1/compendium?limit=100&start=2\n\n\nGET /api/v1/compendium?limit=100&start=2\n\n\n200 OK\n\n{\n  \"results\":[\n    \"nkm4b\",\n    \"asdis\",\n    \"nb2sm\",\n    \u2026\n  ]\n}\n\n\n\n\nYou can also filter the results:\n\n\n\n\nFilter by \nuser\n:\n\n\n\n\ncurl http://\u2026/api/v1/compendium?user=0000-0001-6021-1617\n\n\nGET /api/v1/compendium?user=0000-0001-6021-1617\n\n\n\n\nFilter by \ndoi\n:\n\n\n\n\ncurl http://\u2026/api/v1/compendium?doi=10.9999%2Ftest\n\n\nGET /api/v1/compendium?doi=10.9999%2Ftest\n\n\n200 OK\n\n{\n  \"results\":[\n    \"nkm4b\",\n    \"nb2sm\"\n  ]\n}\n\n\n\n\nURL parameters for compendium lists\n\n\n\n\njob_id\n - Comma-separated list of related job ids to filter by.\n\n\nuser\n - Public user identifier to filter by.\n\n\ndoi\n - A \nDOI\n to filter by.\n\n\nstart\n - Starting point of the result list. \nstart - 1\n results are skipped. Defaults to 1.\n\n\nlimit\n - Limits the number of results in the response. Defaults to 100.\n\n\n\n\nError responses for compendium lists\n\n\n404 Not Found\n\n{\"error\":\"no compendium found\"}\n\n\n\n\nView single compendium\n\n\nThis includes the complete metadata set, related job ids and a tree representation of the included \nfiles\n. The \ncreated\n timestamp refers to the upload of the compendium. It is formated as ISO8601.\n\n\ncurl https://\u2026/api/v1/$ID\n\n\nGET /api/v1/compendium/:id\n\n\n200 OK\n\n{\n  \"id\":\"comid\",\n  \"metadata\": \u2026 ,\n  \"created\": \"2016-08-01T13:57:40.760Z\",\n  \"files\": \u2026\n }\n\n\n\n\nURL parameters for single compendium view\n\n\n\n\n:id\n - the compendiums id\n\n\n\n\nError responses for single compendium view\n\n\n404 Not Found\n\n{\"error\":\"no compendium with this id\"}\n\n\n\n\nList related execution jobs\n\n\ncurl https://\u2026/api/v1/compendium/$ID/jobs\n\n\nGET /api/v1/compendium/:id/jobs\n\n\n200 OK\n{\n  \"results\":[\n    \"nkm4L\",\n    \"asdi5\",\n    \"nb2sg\",\n    \u2026\n  ]\n}\n\n\n\n\nURL parameters for related execution jobs\n\n\n\n\n:id\n - compendium id that the results should be related to\n\n\n\n\nError response for related execution jobs\n\n\n404 Not Found\n\n{\"error\":\"no job found\"}",
            "title": "View"
        },
        {
            "location": "/compendium/view/#view-compendium",
            "text": "",
            "title": "View compendium"
        },
        {
            "location": "/compendium/view/#list-compendia",
            "text": "Will return up to 100 results by default.  curl https://\u2026/api/v1/compendium?limit=100&start=2  GET /api/v1/compendium?limit=100&start=2  200 OK\n\n{\n  \"results\":[\n    \"nkm4b\",\n    \"asdis\",\n    \"nb2sm\",\n    \u2026\n  ]\n}  You can also filter the results:   Filter by  user :   curl http://\u2026/api/v1/compendium?user=0000-0001-6021-1617  GET /api/v1/compendium?user=0000-0001-6021-1617   Filter by  doi :   curl http://\u2026/api/v1/compendium?doi=10.9999%2Ftest  GET /api/v1/compendium?doi=10.9999%2Ftest  200 OK\n\n{\n  \"results\":[\n    \"nkm4b\",\n    \"nb2sm\"\n  ]\n}",
            "title": "List compendia"
        },
        {
            "location": "/compendium/view/#url-parameters-for-compendium-lists",
            "text": "job_id  - Comma-separated list of related job ids to filter by.  user  - Public user identifier to filter by.  doi  - A  DOI  to filter by.  start  - Starting point of the result list.  start - 1  results are skipped. Defaults to 1.  limit  - Limits the number of results in the response. Defaults to 100.",
            "title": "URL parameters for compendium lists"
        },
        {
            "location": "/compendium/view/#error-responses-for-compendium-lists",
            "text": "404 Not Found\n\n{\"error\":\"no compendium found\"}",
            "title": "Error responses for compendium lists"
        },
        {
            "location": "/compendium/view/#view-single-compendium",
            "text": "This includes the complete metadata set, related job ids and a tree representation of the included  files . The  created  timestamp refers to the upload of the compendium. It is formated as ISO8601.  curl https://\u2026/api/v1/$ID  GET /api/v1/compendium/:id  200 OK\n\n{\n  \"id\":\"comid\",\n  \"metadata\": \u2026 ,\n  \"created\": \"2016-08-01T13:57:40.760Z\",\n  \"files\": \u2026\n }",
            "title": "View single compendium"
        },
        {
            "location": "/compendium/view/#url-parameters-for-single-compendium-view",
            "text": ":id  - the compendiums id",
            "title": "URL parameters for single compendium view"
        },
        {
            "location": "/compendium/view/#error-responses-for-single-compendium-view",
            "text": "404 Not Found\n\n{\"error\":\"no compendium with this id\"}",
            "title": "Error responses for single compendium view"
        },
        {
            "location": "/compendium/view/#list-related-execution-jobs",
            "text": "curl https://\u2026/api/v1/compendium/$ID/jobs  GET /api/v1/compendium/:id/jobs  200 OK\n{\n  \"results\":[\n    \"nkm4L\",\n    \"asdi5\",\n    \"nb2sg\",\n    \u2026\n  ]\n}",
            "title": "List related execution jobs"
        },
        {
            "location": "/compendium/view/#url-parameters-for-related-execution-jobs",
            "text": ":id  - compendium id that the results should be related to",
            "title": "URL parameters for related execution jobs"
        },
        {
            "location": "/compendium/view/#error-response-for-related-execution-jobs",
            "text": "404 Not Found\n\n{\"error\":\"no job found\"}",
            "title": "Error response for related execution jobs"
        },
        {
            "location": "/compendium/download/",
            "text": "Download compendium\n\n\nDownload the complete compendium as an archive. Supported formats are as follows:\n\n\n\n\nzip\n\n\ntar\n\n\ntar.gz\n (gzipped tarball)\n\n\n\n\nRequests\n\n\ncurl https://\u2026/api/v1/compendium/$ID.zip\n\n\nwget https://\u2026/api/v1/compendium/$ID.zip\n\n\nGET /api/v1/compendium/:id.zip\nGET /api/v1/compendium/:id.tar\nGET /api/v1/compendium/:id.tar.gz\nGET /api/v1/compendium/:id.tar?gzip\nGET /api/v1/compendium/:id.zip?image=false\n\n\n\n\nURL parameters for compendium download\n\n\n\n\n:id\n - the compendiums id\n\n\n?gzip\n - \nonly for .tar endpoint\n - compress tarball with gzip\n\n\n?image=true\n or \n?image=false\n - include tarball of Docker image in the archive, default is \ntrue\n\n\n\n\nResponse\n\n\nThe response is a file attachment. The suggested file name is available in the HTTP header \ncontent-disposition\n using the respective file extension (i.e. \n.zip\n, \n.tar\n, and \n.tar.gz\n).\n\n\nThe \ncontent-type\n header also reflects the respective format, which can take the following values:\n\n\n\n\napplication/zip\n for ZIP archive\n\n\napplication/x-tar\n for TAR archive\n\n\napplication/octet-stream\n for gzipped TAR\n\n\n\n\n200 OK\nContent-Type: application/zip\nTransfer-Encoding: chunked\nContent-Disposition: attachment; filename=\"$ID.zip\"\nX-Response-Time: 13.556ms\n\n\n\n\nThe zip file contains a comment with the original URL.\n\n\n$ unzip -z CXE1c.zip\nArchive:  CXE1c.zip\nCreated by o2r [https://\u2026/api/v1/compendium/CXE1c.zip]\n\n\n\n\nError responses for compendium download\n\n\n404 Not Found\n\n{\"error\":\"no compendium with this id\"}\n\n\n\n\n500 Internal Server Error\n\n{\"error\":\"no job found for this compendium, run a job before downloading with image\"}",
            "title": "Download"
        },
        {
            "location": "/compendium/download/#download-compendium",
            "text": "Download the complete compendium as an archive. Supported formats are as follows:   zip  tar  tar.gz  (gzipped tarball)",
            "title": "Download compendium"
        },
        {
            "location": "/compendium/download/#requests",
            "text": "curl https://\u2026/api/v1/compendium/$ID.zip  wget https://\u2026/api/v1/compendium/$ID.zip  GET /api/v1/compendium/:id.zip\nGET /api/v1/compendium/:id.tar\nGET /api/v1/compendium/:id.tar.gz\nGET /api/v1/compendium/:id.tar?gzip\nGET /api/v1/compendium/:id.zip?image=false",
            "title": "Requests"
        },
        {
            "location": "/compendium/download/#url-parameters-for-compendium-download",
            "text": ":id  - the compendiums id  ?gzip  -  only for .tar endpoint  - compress tarball with gzip  ?image=true  or  ?image=false  - include tarball of Docker image in the archive, default is  true",
            "title": "URL parameters for compendium download"
        },
        {
            "location": "/compendium/download/#response",
            "text": "The response is a file attachment. The suggested file name is available in the HTTP header  content-disposition  using the respective file extension (i.e.  .zip ,  .tar , and  .tar.gz ).  The  content-type  header also reflects the respective format, which can take the following values:   application/zip  for ZIP archive  application/x-tar  for TAR archive  application/octet-stream  for gzipped TAR   200 OK\nContent-Type: application/zip\nTransfer-Encoding: chunked\nContent-Disposition: attachment; filename=\"$ID.zip\"\nX-Response-Time: 13.556ms  The zip file contains a comment with the original URL.  $ unzip -z CXE1c.zip\nArchive:  CXE1c.zip\nCreated by o2r [https://\u2026/api/v1/compendium/CXE1c.zip]",
            "title": "Response"
        },
        {
            "location": "/compendium/download/#error-responses-for-compendium-download",
            "text": "404 Not Found\n\n{\"error\":\"no compendium with this id\"}  500 Internal Server Error\n\n{\"error\":\"no job found for this compendium, run a job before downloading with image\"}",
            "title": "Error responses for compendium download"
        },
        {
            "location": "/compendium/metadata/",
            "text": "Compendium metadata\n\n\nBasics\n\n\nMetadata in a compendium is stored in a directory \n.erc\n. This directory contains the normative metadata documents using a file naming scheme \n<metadata_model>.<format>\n, sometimes preprended with \nmetadata_\n for clarity, e.g. \nmetadata_raw.json\n, \nmetadata_o2r.json\n, \nzenodo.json\n, or \ndatacite.xml\n.\n\n\nA copy of the files in this directory is kept in database for easier access, so every compendium returned by the API can contain different sub-properties in the metadata property. \nThis API always returns the database copy of the metadata elements.\n You can download the respective files to access the normative metadata documents.\n\n\nBoth the files and the sub-properties are only available \non-demand\n, so for example after a shipment to Zenodo is initiated. After creation the metadata is persisted to file and database.\n\n\nThe sub-properties and their features are\n\n\n\n\nraw\n contains raw metadata extracted automatically\n\n\no2r\n holds the \nmain information for display\n and is modelled according the the o2r metadata model. This metadata is first an automatic transformation of raw metadata and should then be checked by the uploading user during the upload process.\n\n\ndatacite\n (TBD) holds DataCite XML\n\n\nzenodo\n holds \nZenodo\n metadata for shipments made to Zenodo\n\n\n\n\nNote:\n The information in each sub-property are subject to independent workflows and may differ from one another.\n\n\nFuture sub-properties might expose \nenriched\n or \nharvested\n metadata.\n\n\nRequest and response\n\n\ncurl https://\u2026/api/v1/$ID\n\n\nGET /api/v1/compendium/:id\n\n\n200 OK\n\n{\n  \"id\":\"compendium_id\",\n  \"metadata\": {\n    \"raw\": {\n      \"title\": \"Programming with Data. Springer, New York, 1998. ISBN 978-0-387-98503-9.\",\n      \"author\": \"John M. Chambers.   \"\n    },\n    \"o2r\": {\n      \"title\": \"Programming with Data\",\n      \"creator\": \"John M. Chambers\",\n      \"year\": 1998\n    }, {\n      \u2026\n    }\n  },\n  \"created\": \u2026,\n  \"files\": \u2026\n}\n\n\n\n\nURL parameters for metadata\n\n\n\n\n:id\n - compendium id\n\n\n\n\nSpatial MD\n\n\nFor discovery purposes, the Metadata will included extracted geojson bounding boxes, if suggested by the source files in a workspace (shapefiles, geojson files \nTDB\n, geotiffs \nTDB\n or jpegs \nTDB\n).\n\n\nThe following structure will be made available per file:\n\n\n````{json}\n    \"spatial\": {\n        \"files\": [\n            {\n                \"geojson\": {\n                    \"bbox\": [\n                        -2.362060546875,\n                        52.0862573323384,\n                        -1.285400390625,\n                        52.649729197309426\n                    ],\n                    \"geometry\": {\n                        \"coordinates\": [\n                            [\n                                [\n                                    -2.362060546875,\n                                    52.0862573323384\n                                ],\n                                [\n                                    -1.285400390625,\n                                    52.649729197309426\n                                ]\n                            ]\n                        ],\n                        \"type\": \"Polygon\"\n                    },\n                    \"type\": \"Feature\"\n                },\n                \"source_file\": \"path/to/file1.geojson\"\n            },\n            {\n                \"geojson\": {\n                    \"bbox\": [\n                        7.595369517803192,\n                        51.96245837645124,\n                        7.62162297964096,\n                        51.96966694957956\n                    ],\n                    \"geometry\": {\n                        \"coordinates\": [\n                            [\n                                [\n                                    7.595369517803192,\n                                    51.96245837645124\n                                ],\n                                [\n                                    7.62162297964096,\n                                    51.96966694957956\n                                ]\n                            ]\n                        ],\n                        \"type\": \"Polygon\"\n                    },\n                    \"type\": \"Feature\"\n                },\n                \"source_file\": \"path/to/file2.shp\"\n            }\n        ],\n        \"union\": {\n            \"geojson\": {\n                \"bbox\": [\n                    -2.362060546875,\n                    51.96245837645124,\n                    7.62162297964096,\n                    51.96245837645124\n                ],\n                \"geometry\": {\n                    \"coordinates\": [\n                        [\n                            -2.362060546875,\n                            51.96245837645124\n                        ],\n                        [\n                            7.62162297964096,\n                            51.96245837645124\n                        ],\n                        [\n                            7.62162297964096,\n                            52.649729197309426\n                        ],\n                        [\n                            -2.362060546875,\n                            52.649729197309426\n                        ]\n                    ],\n                    \"type\": \"Polygon\"\n                },\n                \"type\": \"Feature\"\n            }\n        }\n    }\n\n\nThe `spatial` key has a `union` bounding box, that wraps all extracted bounding boxes.\n\n### URL parameters for metadata\n\n- `:id` - compendium id\n\n### GET metadata - example request and response\n\n`curl https://\u2026/api/v1/$ID`\n\n`GET /api/v1/compendium/:id`\n\n```json\n200 OK\n\n{\n  \"id\":\"compendium_id\",\n  \"metadata\": {\n    \"raw\": {\n      \"title\": \"Programming with Data. Springer, New York, 1998. ISBN 978-0-387-98503-9.\",\n      \"author\": \"John M. Chambers.   \"\n    },\n    \"o2r\": {\n      \"title\": \"Programming with Data\",\n      \"creator\": \"John M. Chambers\",\n      \"year\": 1998\n    }, {\n      \u2026\n    }\n  },\n  \"created\": \u2026,\n  \"files\": \u2026\n}\n\n\n\n\nUpdate metadata\n\n\nThe following endpoint can be used to update the \no2r\n metadata elements.\n\nOnly authors of a compendium can update the metadata.\n\nAll other metadata sub-properties are only updated by the platform itself.\n\n\nMetadata update request\n\n\ncurl -H 'Content-Type: application/json' \\\n  -X PUT \\\n  --cookie \"connect.sid=<code string here>\" \\\n  -d '{ \"o2r\": { \"title\": \"Blue Book\" } }' \\\n  /api/v1/compendium/:id/metadata\n\n\n\n\nThe request will \noverwrite\n the existing metadata properties, so the full o2r metadata must be put with a JSON object called \no2r\n at the root, even if only specific fields are changed.\n\n\nMetadata update response\n\n\nThe response contains an excerpt of a compendium with only the o2r metadata property.\n\n\n200 OK\n\n{\n  \"id\":\"compendium_id\",\n  \"metadata\": {\n    \"o2r\": {\n      \"title\": \"Blue Book\"\n    }\n  }\n}\n\n\n\n\nThis response is also available at \nGET /api/v1/compendium/:id/metadata\n.\n\n\nMetadata update error responses\n\n\n401 Unauthorized\n\n{\"error\":\"not authorized\"}\n\n\n\n\n400 Bad Request\n\n\"SyntaxError [...]\"\n\n\n\n\n422 Unprocessable Entity\n\n{\"error\":\"JSON with root element 'o2r' required\"}",
            "title": "Metadata"
        },
        {
            "location": "/compendium/metadata/#compendium-metadata",
            "text": "",
            "title": "Compendium metadata"
        },
        {
            "location": "/compendium/metadata/#basics",
            "text": "Metadata in a compendium is stored in a directory  .erc . This directory contains the normative metadata documents using a file naming scheme  <metadata_model>.<format> , sometimes preprended with  metadata_  for clarity, e.g.  metadata_raw.json ,  metadata_o2r.json ,  zenodo.json , or  datacite.xml .  A copy of the files in this directory is kept in database for easier access, so every compendium returned by the API can contain different sub-properties in the metadata property.  This API always returns the database copy of the metadata elements.  You can download the respective files to access the normative metadata documents.  Both the files and the sub-properties are only available  on-demand , so for example after a shipment to Zenodo is initiated. After creation the metadata is persisted to file and database.  The sub-properties and their features are   raw  contains raw metadata extracted automatically  o2r  holds the  main information for display  and is modelled according the the o2r metadata model. This metadata is first an automatic transformation of raw metadata and should then be checked by the uploading user during the upload process.  datacite  (TBD) holds DataCite XML  zenodo  holds  Zenodo  metadata for shipments made to Zenodo   Note:  The information in each sub-property are subject to independent workflows and may differ from one another.  Future sub-properties might expose  enriched  or  harvested  metadata.",
            "title": "Basics"
        },
        {
            "location": "/compendium/metadata/#request-and-response",
            "text": "curl https://\u2026/api/v1/$ID  GET /api/v1/compendium/:id  200 OK\n\n{\n  \"id\":\"compendium_id\",\n  \"metadata\": {\n    \"raw\": {\n      \"title\": \"Programming with Data. Springer, New York, 1998. ISBN 978-0-387-98503-9.\",\n      \"author\": \"John M. Chambers.   \"\n    },\n    \"o2r\": {\n      \"title\": \"Programming with Data\",\n      \"creator\": \"John M. Chambers\",\n      \"year\": 1998\n    }, {\n      \u2026\n    }\n  },\n  \"created\": \u2026,\n  \"files\": \u2026\n}",
            "title": "Request and response"
        },
        {
            "location": "/compendium/metadata/#url-parameters-for-metadata",
            "text": ":id  - compendium id",
            "title": "URL parameters for metadata"
        },
        {
            "location": "/compendium/metadata/#spatial-md",
            "text": "For discovery purposes, the Metadata will included extracted geojson bounding boxes, if suggested by the source files in a workspace (shapefiles, geojson files  TDB , geotiffs  TDB  or jpegs  TDB ).  The following structure will be made available per file:  ````{json}\n    \"spatial\": {\n        \"files\": [\n            {\n                \"geojson\": {\n                    \"bbox\": [\n                        -2.362060546875,\n                        52.0862573323384,\n                        -1.285400390625,\n                        52.649729197309426\n                    ],\n                    \"geometry\": {\n                        \"coordinates\": [\n                            [\n                                [\n                                    -2.362060546875,\n                                    52.0862573323384\n                                ],\n                                [\n                                    -1.285400390625,\n                                    52.649729197309426\n                                ]\n                            ]\n                        ],\n                        \"type\": \"Polygon\"\n                    },\n                    \"type\": \"Feature\"\n                },\n                \"source_file\": \"path/to/file1.geojson\"\n            },\n            {\n                \"geojson\": {\n                    \"bbox\": [\n                        7.595369517803192,\n                        51.96245837645124,\n                        7.62162297964096,\n                        51.96966694957956\n                    ],\n                    \"geometry\": {\n                        \"coordinates\": [\n                            [\n                                [\n                                    7.595369517803192,\n                                    51.96245837645124\n                                ],\n                                [\n                                    7.62162297964096,\n                                    51.96966694957956\n                                ]\n                            ]\n                        ],\n                        \"type\": \"Polygon\"\n                    },\n                    \"type\": \"Feature\"\n                },\n                \"source_file\": \"path/to/file2.shp\"\n            }\n        ],\n        \"union\": {\n            \"geojson\": {\n                \"bbox\": [\n                    -2.362060546875,\n                    51.96245837645124,\n                    7.62162297964096,\n                    51.96245837645124\n                ],\n                \"geometry\": {\n                    \"coordinates\": [\n                        [\n                            -2.362060546875,\n                            51.96245837645124\n                        ],\n                        [\n                            7.62162297964096,\n                            51.96245837645124\n                        ],\n                        [\n                            7.62162297964096,\n                            52.649729197309426\n                        ],\n                        [\n                            -2.362060546875,\n                            52.649729197309426\n                        ]\n                    ],\n                    \"type\": \"Polygon\"\n                },\n                \"type\": \"Feature\"\n            }\n        }\n    }  The `spatial` key has a `union` bounding box, that wraps all extracted bounding boxes.\n\n### URL parameters for metadata\n\n- `:id` - compendium id\n\n### GET metadata - example request and response\n\n`curl https://\u2026/api/v1/$ID`\n\n`GET /api/v1/compendium/:id`\n\n```json\n200 OK\n\n{\n  \"id\":\"compendium_id\",\n  \"metadata\": {\n    \"raw\": {\n      \"title\": \"Programming with Data. Springer, New York, 1998. ISBN 978-0-387-98503-9.\",\n      \"author\": \"John M. Chambers.   \"\n    },\n    \"o2r\": {\n      \"title\": \"Programming with Data\",\n      \"creator\": \"John M. Chambers\",\n      \"year\": 1998\n    }, {\n      \u2026\n    }\n  },\n  \"created\": \u2026,\n  \"files\": \u2026\n}",
            "title": "Spatial MD"
        },
        {
            "location": "/compendium/metadata/#update-metadata",
            "text": "The following endpoint can be used to update the  o2r  metadata elements. Only authors of a compendium can update the metadata. \nAll other metadata sub-properties are only updated by the platform itself.",
            "title": "Update metadata"
        },
        {
            "location": "/compendium/metadata/#metadata-update-request",
            "text": "curl -H 'Content-Type: application/json' \\\n  -X PUT \\\n  --cookie \"connect.sid=<code string here>\" \\\n  -d '{ \"o2r\": { \"title\": \"Blue Book\" } }' \\\n  /api/v1/compendium/:id/metadata  The request will  overwrite  the existing metadata properties, so the full o2r metadata must be put with a JSON object called  o2r  at the root, even if only specific fields are changed.",
            "title": "Metadata update request"
        },
        {
            "location": "/compendium/metadata/#metadata-update-response",
            "text": "The response contains an excerpt of a compendium with only the o2r metadata property.  200 OK\n\n{\n  \"id\":\"compendium_id\",\n  \"metadata\": {\n    \"o2r\": {\n      \"title\": \"Blue Book\"\n    }\n  }\n}  This response is also available at  GET /api/v1/compendium/:id/metadata .",
            "title": "Metadata update response"
        },
        {
            "location": "/compendium/metadata/#metadata-update-error-responses",
            "text": "401 Unauthorized\n\n{\"error\":\"not authorized\"}  400 Bad Request\n\n\"SyntaxError [...]\"  422 Unprocessable Entity\n\n{\"error\":\"JSON with root element 'o2r' required\"}",
            "title": "Metadata update error responses"
        },
        {
            "location": "/compendium/files/",
            "text": "Compendium file listing\n\n\nThe file listing is returned in the single view of a job or compendium. It includes the complete content of the bagtainer in its current state. If a job has been run and the programm outputs new data, this new data will be included as well.\n\n\nFile listings are represented as a Object. The file structure for a synthetic job \nnj141\n is as follows.\n\n\nnj141\n\u251c\u2500\u2500 bagit.txt\n\u2514\u2500\u2500 data\n    \u251c\u2500\u2500 paper.Rmd\n    \u2514\u2500\u2500 Dockerfile\n\n\n\n\nwill be represented as\n\n\n{\n  \"path\": \"/api/v1/job/nj141/data\",\n  \"name\": \"nj141\",\n  \"children\": [\n    {\n      \"path\": \"/api/v1/job/nj141/data/bagit.txt\",\n      \"name\": \"bagit.xt\",\n      \"type\": \"text/plain\",\n      \"size\": 55\n    },\n    {\n      \"path\": \"/api/v1/job/nj141/data/data\",\n      \"name\": \"data\",\n      \"children\": [\n        {\n          \"path\": \"/api/v1/job/nj141/data/data/paper.Rmd\",\n          \"name\": \"paper.Rmd\",\n          \"type\": \"text/plain\",\n          \"size\": 346512\n        }\n        {\n          \"path\": \"/api/v1/job/nj141/data/data/Dockerfile\",\n          \"name\": \"Dockerfile\",\n          \"type\": \"text/plain\",\n          \"size\": 1729\n        }\n      ]\n    }\n  ]\n}\n\n\n\n\npath\n property\n\n\nThe \npath\n property for each file in the listing is a link to the raw file. Additionally the \nGET\n parameter \n?size=\u2026\n can be appended to retrieve previews of the files. In the case of Images (\npng\n, \njpg\n, \ngif\n, \ntiff\n), the value defines the maximum width/height. For text files (\ntxt\n, \ncsv\n, scripts), the value defines the amount of lines returned.\n\n\ntype\n property\n\n\nThe \ntype\n property is a best guess for the MIME type of the file content. It is a result of the files extension. Look at the list of extension to type mapping below.\n\n\nFile extension to MIME type mappings\n\n\nThis list contains the custom mapping of file extensions to MIME types used in the server.\n\n\n\n\n\n\n\n\nExtension\n\n\nMIME type\n\n\n\n\n\n\n\n\n\n\n.R\n, \n.r\n\n\nscript/x-R",
            "title": "Files in a compendium"
        },
        {
            "location": "/compendium/files/#compendium-file-listing",
            "text": "The file listing is returned in the single view of a job or compendium. It includes the complete content of the bagtainer in its current state. If a job has been run and the programm outputs new data, this new data will be included as well.  File listings are represented as a Object. The file structure for a synthetic job  nj141  is as follows.  nj141\n\u251c\u2500\u2500 bagit.txt\n\u2514\u2500\u2500 data\n    \u251c\u2500\u2500 paper.Rmd\n    \u2514\u2500\u2500 Dockerfile  will be represented as  {\n  \"path\": \"/api/v1/job/nj141/data\",\n  \"name\": \"nj141\",\n  \"children\": [\n    {\n      \"path\": \"/api/v1/job/nj141/data/bagit.txt\",\n      \"name\": \"bagit.xt\",\n      \"type\": \"text/plain\",\n      \"size\": 55\n    },\n    {\n      \"path\": \"/api/v1/job/nj141/data/data\",\n      \"name\": \"data\",\n      \"children\": [\n        {\n          \"path\": \"/api/v1/job/nj141/data/data/paper.Rmd\",\n          \"name\": \"paper.Rmd\",\n          \"type\": \"text/plain\",\n          \"size\": 346512\n        }\n        {\n          \"path\": \"/api/v1/job/nj141/data/data/Dockerfile\",\n          \"name\": \"Dockerfile\",\n          \"type\": \"text/plain\",\n          \"size\": 1729\n        }\n      ]\n    }\n  ]\n}",
            "title": "Compendium file listing"
        },
        {
            "location": "/compendium/files/#path-property",
            "text": "The  path  property for each file in the listing is a link to the raw file. Additionally the  GET  parameter  ?size=\u2026  can be appended to retrieve previews of the files. In the case of Images ( png ,  jpg ,  gif ,  tiff ), the value defines the maximum width/height. For text files ( txt ,  csv , scripts), the value defines the amount of lines returned.",
            "title": "path property"
        },
        {
            "location": "/compendium/files/#type-property",
            "text": "The  type  property is a best guess for the MIME type of the file content. It is a result of the files extension. Look at the list of extension to type mapping below.",
            "title": "type property"
        },
        {
            "location": "/compendium/files/#file-extension-to-mime-type-mappings",
            "text": "This list contains the custom mapping of file extensions to MIME types used in the server.     Extension  MIME type      .R ,  .r  script/x-R",
            "title": "File extension to MIME type mappings"
        },
        {
            "location": "/job/",
            "text": "Execute a compendium\n\n\nExecution jobs are used to run the analysis in a compendium. When a new execution job is started, the contents of the research compendium are cloned to create a trackable execution. The status information, logs and final working directory data are saved in their final state, so that they can be reviewed later on.\n\n\nAll execution jobs are tied to a single research compendium and reflect the execution history of that research compendium.\n\n\nA trivial execution job would be a completely unmodified research compendium, to test the executability/reproducibility of the contained data and code.\n\n\nState of a job\n\n\nThe property \n>job>.state\n shows the overall state of a job.\n\n\nThe status will be one of following:\n\n\n\n\nsuccess\n - if state of all steps is \nsuccess\n.\n\n\nfailure\n - if state of at least one step is \nfailure\n.\n\n\nrunning\n - if state of at least one step is \nrunning\n and no state is \nfailure\n.\n\n\n\n\nMore information about \nsteps\n can be found in subsection \nSteps\n of section \nView single job\n.\n\n\nSteps of a job\n\n\nOne job consists of a series of steps. All of these steps can be in one of three status: \nrunning\n, \nfailure\n, or \nsuccess\n. The are executed in order.\n\n\n\n\nvalidate_bag\n\n  Validate the BagIt bag based on npm's \nbagit\n.\n\n\nvalidate_compendium\n\n  Parses and validate the bagtainer configuration and metadta.\n\n\nimage_prepare\n\n  Create an archive of the payload of the BagIt bag, which allows to build and run the image also on remote Docker hosts.\n\n\nimage_build\n\n  Send the bag's payload as a tarballed archive to Docker to build an image, which is tagged \nbagtainer:<jobid>\n.\n\n\nimage_execute\n\n  Run the container and return based on status code of program that ran inside the container.\n\n\ncleanup\n\n  Remove image or job files (depending on server-side settings).\n\n\n\n\nThe step status is one of:\n\n\n\n\nqueued\n\n\nrunning\n\n\nsuccess\n\n\nfailure\n\n\nwarning\n\n\nskipped\n\n\n\n\nNew job\n\n\nCreate and run a new execution job. Requires a \ncompendium_id\n.\n\n\ncurl -F compendium_id=$ID https://\u2026/api/v1/job\n\n\nPOST /api/v1/job\n\n\n200 OK\n\n{\"job_id\":\"ngK4m\"}\n\n\n\n\nBody parameters for new jobs\n\n\n\n\ncompendium_id\n - The \nid\n of the compendium to base this job on.\n\n\nsteps\n - \nTODO\n select steps that will be executed (skip some steps in successive executions?)\n\n\ninputs\n - \nproposal\n - Array with one or more \nFileDescriptor\n.\n\n\n\n\nError responses for new jobs\n\n\n404 Not Found\n\n{\"error\":\"no compendium with this ID found\"}\n\n\n\n\n500 Internal Server Error\n\n{\"error\":\"could not create job\"}\n\n\n\n\nList jobs\n\n\nLists jobs. Will return up to 100 results by default.\n\n\nResults will be sorted by descending date of last change. The content of the response can be limited to certain properties of each result by providing a list of fields, i.e. the parameter \nfields\n.\n\n\nResults can be filtered:\n- by \ncompendium_id\n i.e. \ncompendium_id=a4Dnm\n,\n- by \nstatus\n i.e. \nstatus=success\n or\n- by \nuser\n i.e. \nuser=0000-0000-0000-0001\n\n\ncurl -F compendium_id=$ID https://\u2026/api/v1/job?limit=100&start=2&compendium_id=$ID&status=success&fields=status\n\n\nGET /api/v1/job?limit=100&start=2&compendium_id=a4Dnm&status=success\n\n\n200 OK\n\n{\n  \"results\":[\n    \"nkm4L\",\n    \"asdi5\",\n    \"nb2sg\",\n    \u2026\n  ]\n}\n\n\n\n\nThe overall job state can be added to the job list response:\n\n\nGET /api/v1/job?limit=100&start=2&compendium_id=a4Dnm&status=success&fields=status\n\n\n200 OK\n\n{\n  \"results\":[\n    {\n      \"id\":\"nkm4L\",\n      \"status\":\"failure\"\n    },\n    {\n      \"id\":\"asdi5\",\n      \"status\":\"success\"\n    },\n    {\n      \"id\":\"nb2sg\",\n      \"status\":\"running\"\n    },\n    \u2026\n  ]\n}\n\n\n\n\nGET query parameters for listing jobs\n\n\n\n\ncompendium_id\n - Comma-separated list of related compendium ids to filter by.\n\n\nstart\n - Starting point of the result list. \nstart - 1\n results are skipped. Defaults to 1.\n\n\nlimit\n - Limits the number of results in the response. Defaults to 100.\n\n\nstatus\n - Specify status to filter by. Can contain following \nstatus\n: \nsuccess\n, \nfailure\n, \nrunning\n.\n\n\nuser\n - Public user identifier to filter by.\n\n\nfields\n - Specify if/which additional attributes results should contain. Can contain following \nfields\n: \nstatus\n. Defaults to none.\n\n\n\n\nView single job\n\n\nView details for a single job. The file listing format is described in \ncompendium files\n\n\ncurl https://\u2026/api/v1/job/$ID\n\n\nGET /api/v1/job/:id\n\n\n200 OK\n\n{\n  \"id\":\"nkm4L\",\n  \"compendium_id\":\"a4Dnm\",\n  \"creation_date\": Date,\n  \"status\": \"failure\",\n  \"steps\":{\n    \"unpack\":{\n      \"status\":\"failure\",\n      \"start\": Date,\n      \"end\": Date,\n      \"text\":\"not a valid archive\"\n    },\n    \u2026\n  },\n  \"files\":{\n    {FileListing}\n  }\n}\n\n\n\n\nURL parameters for single job view\n\n\n\n\n:id\n - id of the job to be viewed\n\n\n\n\nSteps\n\n\nThe answer will contain information regaring the job steps.\n\n\nAdditional explanations to their status will be transmitted in the \ntext\n property. The \nstart\n and \nend\n timestamps indicate the start and end time of the step. They are formatted as ISO8601.\n\n\nError responses for single job view\n\n\n404 Not Found\n\n{\"error\":\"no compendium with this ID found\"}\n\n\n\n\nJob status updates\n\n\nYou can subscribe to real time status updates on jobs using \nWebSockets\n. The implementation is based on \nsocket.io\n and using their client is recommended.\n\n\nThe job log is available at \nhttps://o2r.uni-muenster.de\n under the namespace \napi/v1/logs/job\n.\n\n\n# create a socket.io client:\nvar socket = io('https://o2r.uni-muenster.de/api/v1/logs/job');\n\n\n\n\nTODO\n: add documentation on messages on the socket.",
            "title": "Job"
        },
        {
            "location": "/job/#execute-a-compendium",
            "text": "Execution jobs are used to run the analysis in a compendium. When a new execution job is started, the contents of the research compendium are cloned to create a trackable execution. The status information, logs and final working directory data are saved in their final state, so that they can be reviewed later on.  All execution jobs are tied to a single research compendium and reflect the execution history of that research compendium.  A trivial execution job would be a completely unmodified research compendium, to test the executability/reproducibility of the contained data and code.",
            "title": "Execute a compendium"
        },
        {
            "location": "/job/#state-of-a-job",
            "text": "The property  >job>.state  shows the overall state of a job.  The status will be one of following:   success  - if state of all steps is  success .  failure  - if state of at least one step is  failure .  running  - if state of at least one step is  running  and no state is  failure .   More information about  steps  can be found in subsection  Steps  of section  View single job .",
            "title": "State of a job"
        },
        {
            "location": "/job/#steps-of-a-job",
            "text": "One job consists of a series of steps. All of these steps can be in one of three status:  running ,  failure , or  success . The are executed in order.   validate_bag \n  Validate the BagIt bag based on npm's  bagit .  validate_compendium \n  Parses and validate the bagtainer configuration and metadta.  image_prepare \n  Create an archive of the payload of the BagIt bag, which allows to build and run the image also on remote Docker hosts.  image_build \n  Send the bag's payload as a tarballed archive to Docker to build an image, which is tagged  bagtainer:<jobid> .  image_execute \n  Run the container and return based on status code of program that ran inside the container.  cleanup \n  Remove image or job files (depending on server-side settings).   The step status is one of:   queued  running  success  failure  warning  skipped",
            "title": "Steps of a job"
        },
        {
            "location": "/job/#new-job",
            "text": "Create and run a new execution job. Requires a  compendium_id .  curl -F compendium_id=$ID https://\u2026/api/v1/job  POST /api/v1/job  200 OK\n\n{\"job_id\":\"ngK4m\"}",
            "title": "New job"
        },
        {
            "location": "/job/#body-parameters-for-new-jobs",
            "text": "compendium_id  - The  id  of the compendium to base this job on.  steps  -  TODO  select steps that will be executed (skip some steps in successive executions?)  inputs  -  proposal  - Array with one or more  FileDescriptor .",
            "title": "Body parameters for new jobs"
        },
        {
            "location": "/job/#error-responses-for-new-jobs",
            "text": "404 Not Found\n\n{\"error\":\"no compendium with this ID found\"}  500 Internal Server Error\n\n{\"error\":\"could not create job\"}",
            "title": "Error responses for new jobs"
        },
        {
            "location": "/job/#list-jobs",
            "text": "Lists jobs. Will return up to 100 results by default.  Results will be sorted by descending date of last change. The content of the response can be limited to certain properties of each result by providing a list of fields, i.e. the parameter  fields .  Results can be filtered:\n- by  compendium_id  i.e.  compendium_id=a4Dnm ,\n- by  status  i.e.  status=success  or\n- by  user  i.e.  user=0000-0000-0000-0001  curl -F compendium_id=$ID https://\u2026/api/v1/job?limit=100&start=2&compendium_id=$ID&status=success&fields=status  GET /api/v1/job?limit=100&start=2&compendium_id=a4Dnm&status=success  200 OK\n\n{\n  \"results\":[\n    \"nkm4L\",\n    \"asdi5\",\n    \"nb2sg\",\n    \u2026\n  ]\n}  The overall job state can be added to the job list response:  GET /api/v1/job?limit=100&start=2&compendium_id=a4Dnm&status=success&fields=status  200 OK\n\n{\n  \"results\":[\n    {\n      \"id\":\"nkm4L\",\n      \"status\":\"failure\"\n    },\n    {\n      \"id\":\"asdi5\",\n      \"status\":\"success\"\n    },\n    {\n      \"id\":\"nb2sg\",\n      \"status\":\"running\"\n    },\n    \u2026\n  ]\n}",
            "title": "List jobs"
        },
        {
            "location": "/job/#get-query-parameters-for-listing-jobs",
            "text": "compendium_id  - Comma-separated list of related compendium ids to filter by.  start  - Starting point of the result list.  start - 1  results are skipped. Defaults to 1.  limit  - Limits the number of results in the response. Defaults to 100.  status  - Specify status to filter by. Can contain following  status :  success ,  failure ,  running .  user  - Public user identifier to filter by.  fields  - Specify if/which additional attributes results should contain. Can contain following  fields :  status . Defaults to none.",
            "title": "GET query parameters for listing jobs"
        },
        {
            "location": "/job/#view-single-job",
            "text": "View details for a single job. The file listing format is described in  compendium files  curl https://\u2026/api/v1/job/$ID  GET /api/v1/job/:id  200 OK\n\n{\n  \"id\":\"nkm4L\",\n  \"compendium_id\":\"a4Dnm\",\n  \"creation_date\": Date,\n  \"status\": \"failure\",\n  \"steps\":{\n    \"unpack\":{\n      \"status\":\"failure\",\n      \"start\": Date,\n      \"end\": Date,\n      \"text\":\"not a valid archive\"\n    },\n    \u2026\n  },\n  \"files\":{\n    {FileListing}\n  }\n}",
            "title": "View single job"
        },
        {
            "location": "/job/#url-parameters-for-single-job-view",
            "text": ":id  - id of the job to be viewed",
            "title": "URL parameters for single job view"
        },
        {
            "location": "/job/#steps",
            "text": "The answer will contain information regaring the job steps.  Additional explanations to their status will be transmitted in the  text  property. The  start  and  end  timestamps indicate the start and end time of the step. They are formatted as ISO8601.",
            "title": "Steps"
        },
        {
            "location": "/job/#error-responses-for-single-job-view",
            "text": "404 Not Found\n\n{\"error\":\"no compendium with this ID found\"}",
            "title": "Error responses for single job view"
        },
        {
            "location": "/job/#job-status-updates",
            "text": "You can subscribe to real time status updates on jobs using  WebSockets . The implementation is based on  socket.io  and using their client is recommended.  The job log is available at  https://o2r.uni-muenster.de  under the namespace  api/v1/logs/job .  # create a socket.io client:\nvar socket = io('https://o2r.uni-muenster.de/api/v1/logs/job');  TODO : add documentation on messages on the socket.",
            "title": "Job status updates"
        },
        {
            "location": "/search/",
            "text": "Search\n\n\nIndexed information\n\n\n\n\ncompendium metadata\n\n\ntext files in a compendium\n\n\nPDF documents in a compendium (TBD)\n\n\n\n\nSimple search\n\n\nThe search is based on \nElasticsearch\n and the regular \nElasticsearch search API\n is exposed at\n\n\nhttp://\u2026/api/v1/search\n\n\n\n\nExample requests\n\n\n\n\nhttp://o2r.uni-muenster.de/api/v1/search?q=*\n\n\nhttp://o2r.uni-muenster.de/api/v1/search?q=term\n\n\nhttp://o2r.uni-muenster.de/api/v1/search?q=*&fields=compendium_id\n\n\n\n\nSecurity\n\n\nOnly reading requsts, i.e. \nGET\n requests, are allowed at the moment. This means that Kibana cannot be run against this interface, and neither can complex queries requiring \nPOST\n requests. \nGET\n requests with payloads are allowed.\n\n\nExample query:\n\n\ncurl -XGET 'https://\u2026/api/v1/search' -d '{\n    \"query\": {\n            \"type\" : {\n                \"value\" : \"jobs\"\n            }\n        }\n    }\n}'\n\n\n\n\nSuggesters - WORK IN PROGRESS\n\n\nElasticsearch suggest API",
            "title": "Search"
        },
        {
            "location": "/search/#search",
            "text": "",
            "title": "Search"
        },
        {
            "location": "/search/#indexed-information",
            "text": "compendium metadata  text files in a compendium  PDF documents in a compendium (TBD)",
            "title": "Indexed information"
        },
        {
            "location": "/search/#simple-search",
            "text": "The search is based on  Elasticsearch  and the regular  Elasticsearch search API  is exposed at  http://\u2026/api/v1/search",
            "title": "Simple search"
        },
        {
            "location": "/search/#example-requests",
            "text": "http://o2r.uni-muenster.de/api/v1/search?q=*  http://o2r.uni-muenster.de/api/v1/search?q=term  http://o2r.uni-muenster.de/api/v1/search?q=*&fields=compendium_id",
            "title": "Example requests"
        },
        {
            "location": "/search/#security",
            "text": "Only reading requsts, i.e.  GET  requests, are allowed at the moment. This means that Kibana cannot be run against this interface, and neither can complex queries requiring  POST  requests.  GET  requests with payloads are allowed.  Example query:  curl -XGET 'https://\u2026/api/v1/search' -d '{\n    \"query\": {\n            \"type\" : {\n                \"value\" : \"jobs\"\n            }\n        }\n    }\n}'",
            "title": "Security"
        },
        {
            "location": "/search/#suggesters-work-in-progress",
            "text": "Elasticsearch suggest API",
            "title": "Suggesters - WORK IN PROGRESS"
        },
        {
            "location": "/shipment/",
            "text": "Ship compendia and metadata\n\n\nShipments are used to deliver ERCs or their metadata to third party repositories or archives. This section covers shipment related requests, including repository file management.\n\n\nList shipments\n\n\nThis is a basic request to list all available shipments (no pagination yet).\n\n\nGET /api/v1/shipment\n\n\n200\n\n{\n  \"shipments\": [\"dc351fc6-314f-4947-a235-734ab5971eff\", \"...\"]\n}\n\n\n\n\nGet a single specific shipment\n\n\nGET /api/v1/shipment/dc351fc6-314f-4947-a235-734ab5971eff\n\n\n200 \n\n{\n  \"last_modified\": \"2016-12-12 10:34:32.001475\",\n  \"recipient\": \"zenodo\",\n  \"id\": \"dc351fc6-314f-4947-a235-734ab5971eff\",\n  \"deposition_id\": \"63179\",\n  \"user\": \"0000-0001-6021-1617\",\n  \"status\": \"shipped\",\n  \"compendium_id\": \"4XgD9\",\n  \"deposition_url\": \"https://sandbox.zenodo.org/record/63179\"\n}\n\n\n\n\nYou can also get only the shipments belonging to a compendium id (e.g. \n4XgD97\n).\n\n\nGET /api/v1/shipment?compendium_id=4XgD97\n\n\nURL parameter:\n- \ncompendium_id\n - The identifier of a specific compendium.\n\n\n200 \n\n{\n  \"last_modified\": \"2016-12-12 10:34:32.001475\",\n  \"recipient\": \"zenodo\",\n  \"id\": \"dc351fc6-314f-4947-a235-734ab5971eff\",\n  \"deposition_id\": \"63179\",\n  \"user\": \"0000-0001-6021-1617\",\n  \"status\": \"shipped\",\n  \"compendium_id\": \"4XgD9\",\n  \"deposition_url\": \"https://sandbox.zenodo.org/record/63179\"\n}\n\n\n\n\nNote that returned deposition urls from Zenodo as well as Eudat b2share (records) will only be functional after publishing.\n\n\nCreate a new shipment\n\n\nYou can start a initial creation of a shipment, leading to transmission to a repository at the same endpoint using a \nPOST\n request.\n\n\nPOST /api/v1/shipment\n\n\nThis requires the following parameters and conditions:\n\n\n\n\ncompendium_id\n: the id of the compendium\n\n\nrecipient\n (name of the repository; currently only \nzenodo\n is possible)\n\n\ncookie\n user must be logged in with sufficient rights\n\n\n\n\nOptionally, you can specifiy a custom \nshipment_id\n.\n\n\n201\n\n{\n  \"id\": \"9ff3d75e-23dc-423e-a6c6-6987ac5ffc3e\",\n  \"recipient\": \"zenodo\",\n  \"status\": \"shipped\",\n  \"deposition_id\": \"79102\"\n}\n\n\n\n\nCurrently the following recipients are possible: \nzenodo\n (Zenodo.org) and \neudat\n (Eudat b2share).\n\n\nShipment status\n\n\nA shipment can have two possible status: Fristly its status can be \nshipped\n. That means a deposition has been created at a repository and completed the necessary metadata for publication. Secondly its status can be \npublished\n. That means the contents of the shipment are published on the repository, in which case it the publishment can not be undone. \n\n\nTo query a shipment for its current status you may use:\n\n\nGET api/v1/shipment/<shipment_id>/status\n\n\n200\n\n{\n\"id\": \"9ff3d75e-23dc-423e-a6c6-6987ac5ffc3e\",\n\"status\": \"shipped\"\n}\n\n\n\n\nPublish a deposition on a supported repository\n\n\nThe publishment is supposed to have completed the status \nshipped\n where metadata requirements for publication have been checked.\n\n\nNote that once published, a deposition can no longer be deleted on the supported repositories.\n\n\nPUT api/v1/shipment/<shipment_id>/publishment\n\n\n200\n\n{\n\"id\": \"9ff3d75e-23dc-423e-a6c6-6987ac5ffc3e\",\n\"status\": \"published\"\n}\n\n\n\n\nFile management in a repository depot\n\n\nGet a list of all files and their properties that are in a depot\n\n\nGET api/v1/shipment/<shipment_id>/publishment\n\n\n200\n\n{\n\"files\": [{\n    \"filesize\": 393320,\n    \"id\": \"bae2a60c-bd59-47e1-a443-b34bb7d0a981\",\n    \"filename\": \"4XgD9.zip\",\n    \"checksum\": \"702f4db3e53b22176d1d5ddcda462a27\",\n    \"links\": {\n        \"self\": \"https://sandbox.zenodo.org/api/deposit/depositions/71552/files/bae2a60c-bd59-47e1-a443-b34bb7d0a981\",\n        \"download\": \"https://sandbox.zenodo.org/api/files/31dc8f3d-df00-4d8a-bd99-64ef341372b3/4XgD9.zip\"\n    }\n}]\n}\n\n\n\n\nYou can find the \nid\n of the file you want to interact with in this json list object at \nfiles[n].id\n, where \nn\n is the position of that file in the array. Files can be identified in this response by either their id in the depot, their filename or their checksum.\n\n\nDelete a specific file from a depot\n\n\nDELETE api/v1/shipment/<shipment_id>/files/<file_id>\n\n\n204\n\n{\n\"deleted\": \"110d667c-7691-4fc9-93e7-5652a52df6f2\"\n}\n\n\n\n\nIn order to delete from a depot, you need state the \nfile_id\n that can be retrieve from querying a shipments files object.\n\n\nError responses\n\n\n400\n\n{\"error\":\"bad request\"}\n\n\n\n\n403\n\n{\"error\": \"insufficient permissions\"}",
            "title": "Shipment"
        },
        {
            "location": "/shipment/#ship-compendia-and-metadata",
            "text": "Shipments are used to deliver ERCs or their metadata to third party repositories or archives. This section covers shipment related requests, including repository file management.",
            "title": "Ship compendia and metadata"
        },
        {
            "location": "/shipment/#list-shipments",
            "text": "This is a basic request to list all available shipments (no pagination yet).  GET /api/v1/shipment  200\n\n{\n  \"shipments\": [\"dc351fc6-314f-4947-a235-734ab5971eff\", \"...\"]\n}",
            "title": "List shipments"
        },
        {
            "location": "/shipment/#get-a-single-specific-shipment",
            "text": "GET /api/v1/shipment/dc351fc6-314f-4947-a235-734ab5971eff  200 \n\n{\n  \"last_modified\": \"2016-12-12 10:34:32.001475\",\n  \"recipient\": \"zenodo\",\n  \"id\": \"dc351fc6-314f-4947-a235-734ab5971eff\",\n  \"deposition_id\": \"63179\",\n  \"user\": \"0000-0001-6021-1617\",\n  \"status\": \"shipped\",\n  \"compendium_id\": \"4XgD9\",\n  \"deposition_url\": \"https://sandbox.zenodo.org/record/63179\"\n}  You can also get only the shipments belonging to a compendium id (e.g.  4XgD97 ).  GET /api/v1/shipment?compendium_id=4XgD97  URL parameter:\n-  compendium_id  - The identifier of a specific compendium.  200 \n\n{\n  \"last_modified\": \"2016-12-12 10:34:32.001475\",\n  \"recipient\": \"zenodo\",\n  \"id\": \"dc351fc6-314f-4947-a235-734ab5971eff\",\n  \"deposition_id\": \"63179\",\n  \"user\": \"0000-0001-6021-1617\",\n  \"status\": \"shipped\",\n  \"compendium_id\": \"4XgD9\",\n  \"deposition_url\": \"https://sandbox.zenodo.org/record/63179\"\n}  Note that returned deposition urls from Zenodo as well as Eudat b2share (records) will only be functional after publishing.",
            "title": "Get a single specific shipment"
        },
        {
            "location": "/shipment/#create-a-new-shipment",
            "text": "You can start a initial creation of a shipment, leading to transmission to a repository at the same endpoint using a  POST  request.  POST /api/v1/shipment  This requires the following parameters and conditions:   compendium_id : the id of the compendium  recipient  (name of the repository; currently only  zenodo  is possible)  cookie  user must be logged in with sufficient rights   Optionally, you can specifiy a custom  shipment_id .  201\n\n{\n  \"id\": \"9ff3d75e-23dc-423e-a6c6-6987ac5ffc3e\",\n  \"recipient\": \"zenodo\",\n  \"status\": \"shipped\",\n  \"deposition_id\": \"79102\"\n}  Currently the following recipients are possible:  zenodo  (Zenodo.org) and  eudat  (Eudat b2share).",
            "title": "Create a new shipment"
        },
        {
            "location": "/shipment/#shipment-status",
            "text": "A shipment can have two possible status: Fristly its status can be  shipped . That means a deposition has been created at a repository and completed the necessary metadata for publication. Secondly its status can be  published . That means the contents of the shipment are published on the repository, in which case it the publishment can not be undone.   To query a shipment for its current status you may use:  GET api/v1/shipment/<shipment_id>/status  200\n\n{\n\"id\": \"9ff3d75e-23dc-423e-a6c6-6987ac5ffc3e\",\n\"status\": \"shipped\"\n}",
            "title": "Shipment status"
        },
        {
            "location": "/shipment/#publish-a-deposition-on-a-supported-repository",
            "text": "The publishment is supposed to have completed the status  shipped  where metadata requirements for publication have been checked.  Note that once published, a deposition can no longer be deleted on the supported repositories.  PUT api/v1/shipment/<shipment_id>/publishment  200\n\n{\n\"id\": \"9ff3d75e-23dc-423e-a6c6-6987ac5ffc3e\",\n\"status\": \"published\"\n}",
            "title": "Publish a deposition on a supported repository"
        },
        {
            "location": "/shipment/#file-management-in-a-repository-depot",
            "text": "",
            "title": "File management in a repository depot"
        },
        {
            "location": "/shipment/#get-a-list-of-all-files-and-their-properties-that-are-in-a-depot",
            "text": "GET api/v1/shipment/<shipment_id>/publishment  200\n\n{\n\"files\": [{\n    \"filesize\": 393320,\n    \"id\": \"bae2a60c-bd59-47e1-a443-b34bb7d0a981\",\n    \"filename\": \"4XgD9.zip\",\n    \"checksum\": \"702f4db3e53b22176d1d5ddcda462a27\",\n    \"links\": {\n        \"self\": \"https://sandbox.zenodo.org/api/deposit/depositions/71552/files/bae2a60c-bd59-47e1-a443-b34bb7d0a981\",\n        \"download\": \"https://sandbox.zenodo.org/api/files/31dc8f3d-df00-4d8a-bd99-64ef341372b3/4XgD9.zip\"\n    }\n}]\n}  You can find the  id  of the file you want to interact with in this json list object at  files[n].id , where  n  is the position of that file in the array. Files can be identified in this response by either their id in the depot, their filename or their checksum.",
            "title": "Get a list of all files and their properties that are in a depot"
        },
        {
            "location": "/shipment/#delete-a-specific-file-from-a-depot",
            "text": "DELETE api/v1/shipment/<shipment_id>/files/<file_id>  204\n\n{\n\"deleted\": \"110d667c-7691-4fc9-93e7-5652a52df6f2\"\n}  In order to delete from a depot, you need state the  file_id  that can be retrieve from querying a shipments files object.",
            "title": "Delete a specific file from a depot"
        },
        {
            "location": "/shipment/#error-responses",
            "text": "400\n\n{\"error\":\"bad request\"}  403\n\n{\"error\": \"insufficient permissions\"}",
            "title": "Error responses"
        },
        {
            "location": "/user/",
            "text": "User\n\n\nList users\n\n\nReturn a list of user ids. \nPagination (including defaults) as described for compendia\n is available for users.\n\n\ncurl https://\u2026/api/v1/user\n\n\nGET /api/v1/user\n\n\n200 OK\n\n{\n    \"results\": [\n        \"0000-0002-0024-5046\",\n        \"0000-0001-6021-1617\"\n    ]\n}\n\n\n\n\nView single user\n\n\nShow the details of a user.\n\n\ncurl https://\u2026/api/v1/user/$ID\n\n\nGET /api/v1/user/:id\n\n\n200 OK\n\n{\n    \"id\": \"0000-0001-6021-1617\",\n    \"name\": \"o2r\"\n}\n\n\n\n\nThe content of the response depends on the state and level of the user that requests the resource. The above response only contains the id and the publicly visible name. The following response contains more details and requires a certain user level of the authenticated user making the request:\n\n\ncurl --cookie \"connect.sid=<session cookie here>\" https://\u2026/api/v1/user/0000-0001-6021-1617\n\n\n200 OK\n\n{\n    \"id\": \"0000-0001-6021-1617\",\n    \"name\": \"o2r\",\n    \"level\": 0,\n    \"lastseen\": \"2016-08-15T12:32:23.972Z\"\n}\n\n\n\n\nURL parameters for single user view\n\n\n\n\n:id\n - the user id\n\n\n\n\nError responses for single user view\n\n\n404 Not Found\n\n{\"error\":\"no user with this id\"}\n\n\n\n\nAuthentication\n\n\nUser authentication is done via authenticated sessions, which are referenced with a cookie called \nconnect.sid\n. For every endpoint that needs user authentication, a cookie with an authenticated session is required.\n\n\nAccess authentication information for direct API access\n\n\nTo run commands which require authentication from the command line, a user must login on the website first. Then open you browser cookies and find a cookie issued by \no2r.uni-muenster.de\n with the name \nconnect.sid\n. Use the the contents of the cookie for your requests, for example as shown below when using curl.\n\n\ncurl [...] --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/endpoint\n\n\n\n\nAuthentication within microservices\n\n\nAttention:\n The authentication process \nrequires\n a secured connection, i.e. \nHTTPS\n.\n\n\nAuthentication provider\n\n\nSession authentication is done using the OAuth 2.0 protocol. Currently \nORCID\n is the only available authentication provider, therefore users need to be registered with ORCID. Because of its nature, the authentication workflow is not a RESTful service. Users will need to navigate to the login endpoint with their webbrowser and grant access to the o2r platform for their ORCID account. They will then be sent back to our authentication service, which verifies the authentification request and enriches the user session with the verified ORCID for this user.\n\n\nStart OAuth login\n\n\nNavigate the webbrowser (e.g. via a HTML \n<a>\n link) to \n/api/v1/auth/login\n, which will then redirect the user and request access to your ORCID profile. After granting access, ORCID will redirect the user back to the \n/api/v1/auth/login\n endpoint with a unique \ncode\n param that is used to verify the request.\n\n\nIf the verification was successful, the endpoint returns a session cookie named \nconnect.sid\n, which is tied to a authenticated session. The server answers with a \n301 redirect\n, which redirects the user back to \n/\n, where the o2r platform webinterface resides.\n\n\nIf the login is unsuccessful, the user is not redirected back to the site and no further redirects are configured.\n\n\nRequest authentication status\n\n\nAs the cookie is present in both authenticated and unauthenticated sessions, clients (e.g. webbrowsers) will need to know if their session is authenticated, and if so, as which ORCID user. For this, send a \nGET\n request to the \n/api/v1/auth/whoami\n endpoint, including your session cookie.\n\n\ncurl https://\u2026/api/v1/auth/whoami --cookie \"connect.sid=\u2026\n\n\nGET /api/v1/auth/whoami\n\n\n200 OK\n\n{\n  \"orcid\": \"0000-0001-6021-1617\",\n  \"name\": \"o2r\"\n}\n\n\n\n\nError response for requests requiring authentication\n\n\nWhen no session cookie was included, or the included session cookie does not belong to a authenticated session, the service will respond with a \n401 Unauthorized\n message.\n\n\n401 Unauthorized\n\n{\n  \"error\": \"not authenticated\"\n}\n\n\n\n\nUser levels\n\n\nUsers are authenticated via OAuth and the actions on the website are limited by the \nlevel\n assocciated with an account.\nOn registration, each account is assigned a level \n0\n.\nOnly admin users and the user herself can read the level of a user.\n\n\nThe following is a list of actions and the corresponding required user level.\n\n\n0\n \nUsers\n (everybody)\n\n\n\n\nCreate new jobs\n\n\nView compendia, jobs, user details\n\n\n\n\n100\n \nKnown users\n\n\n\n\nUpload new compendium\n\n\nCreate shipments\n\n\n\n\n500\n \nEditors\n\n\n\n\nEdit user levels\n\n\n\n\n1000\n and above are \nAdmins\n\n\n\n\nView status pages of microservices\n\n\n\n\nEdit user\n\n\nYou can update information of an existing user using the \nHTTP\n operation \nPATCH\n.\n\n\nRequest for user level change\n\n\nThe request must be made by an authenticated user with an appropriate level. The new level is passed to the API via a query parameter, i.e. \n..?level=<new level value>\n.\nThe value must be an \nint\n.\nThe response is the full user document with the updated value.\n\n\ncurl --request PATCH --cookie \"connect.sid=<session cookie here>\" \\\n  https://\u2026/api/v1/user/0000-0001-6021-1617?level=42`\n\n\n\n\n200 OK\n\n{\n    \"id\": \"0000-0001-6021-1617\",\n    \"name\": \"o2r\",\n    \"level\": 42,\n    \"lastseen\": \"2016-08-15T12:32:23.972Z\"\n}\n\n\n\n\nError responses for user level change\n\n\n401 Unauthorized\n\n{\n  \"error\": \"user is not authenticated\"\n}\n\n\n\n\n401 Unauthorized\n\n{\n  \"error\": \"user level does not allow edit\"\n}\n\n\n\n\n400 Bad Request\n\n{\n  \"error\": \"parameter 'level' could not be parsed as an integer\"\n}",
            "title": "User"
        },
        {
            "location": "/user/#user",
            "text": "",
            "title": "User"
        },
        {
            "location": "/user/#list-users",
            "text": "Return a list of user ids.  Pagination (including defaults) as described for compendia  is available for users.  curl https://\u2026/api/v1/user  GET /api/v1/user  200 OK\n\n{\n    \"results\": [\n        \"0000-0002-0024-5046\",\n        \"0000-0001-6021-1617\"\n    ]\n}",
            "title": "List users"
        },
        {
            "location": "/user/#view-single-user",
            "text": "Show the details of a user.  curl https://\u2026/api/v1/user/$ID  GET /api/v1/user/:id  200 OK\n\n{\n    \"id\": \"0000-0001-6021-1617\",\n    \"name\": \"o2r\"\n}  The content of the response depends on the state and level of the user that requests the resource. The above response only contains the id and the publicly visible name. The following response contains more details and requires a certain user level of the authenticated user making the request:  curl --cookie \"connect.sid=<session cookie here>\" https://\u2026/api/v1/user/0000-0001-6021-1617  200 OK\n\n{\n    \"id\": \"0000-0001-6021-1617\",\n    \"name\": \"o2r\",\n    \"level\": 0,\n    \"lastseen\": \"2016-08-15T12:32:23.972Z\"\n}",
            "title": "View single user"
        },
        {
            "location": "/user/#url-parameters-for-single-user-view",
            "text": ":id  - the user id",
            "title": "URL parameters for single user view"
        },
        {
            "location": "/user/#error-responses-for-single-user-view",
            "text": "404 Not Found\n\n{\"error\":\"no user with this id\"}",
            "title": "Error responses for single user view"
        },
        {
            "location": "/user/#authentication",
            "text": "User authentication is done via authenticated sessions, which are referenced with a cookie called  connect.sid . For every endpoint that needs user authentication, a cookie with an authenticated session is required.",
            "title": "Authentication"
        },
        {
            "location": "/user/#access-authentication-information-for-direct-api-access",
            "text": "To run commands which require authentication from the command line, a user must login on the website first. Then open you browser cookies and find a cookie issued by  o2r.uni-muenster.de  with the name  connect.sid . Use the the contents of the cookie for your requests, for example as shown below when using curl.  curl [...] --cookie \"connect.sid=<code string here>\" \\\n     http://\u2026/api/v1/endpoint",
            "title": "Access authentication information for direct API access"
        },
        {
            "location": "/user/#authentication-within-microservices",
            "text": "Attention:  The authentication process  requires  a secured connection, i.e.  HTTPS .",
            "title": "Authentication within microservices"
        },
        {
            "location": "/user/#authentication-provider",
            "text": "Session authentication is done using the OAuth 2.0 protocol. Currently  ORCID  is the only available authentication provider, therefore users need to be registered with ORCID. Because of its nature, the authentication workflow is not a RESTful service. Users will need to navigate to the login endpoint with their webbrowser and grant access to the o2r platform for their ORCID account. They will then be sent back to our authentication service, which verifies the authentification request and enriches the user session with the verified ORCID for this user.",
            "title": "Authentication provider"
        },
        {
            "location": "/user/#start-oauth-login",
            "text": "Navigate the webbrowser (e.g. via a HTML  <a>  link) to  /api/v1/auth/login , which will then redirect the user and request access to your ORCID profile. After granting access, ORCID will redirect the user back to the  /api/v1/auth/login  endpoint with a unique  code  param that is used to verify the request.  If the verification was successful, the endpoint returns a session cookie named  connect.sid , which is tied to a authenticated session. The server answers with a  301 redirect , which redirects the user back to  / , where the o2r platform webinterface resides.  If the login is unsuccessful, the user is not redirected back to the site and no further redirects are configured.",
            "title": "Start OAuth login"
        },
        {
            "location": "/user/#request-authentication-status",
            "text": "As the cookie is present in both authenticated and unauthenticated sessions, clients (e.g. webbrowsers) will need to know if their session is authenticated, and if so, as which ORCID user. For this, send a  GET  request to the  /api/v1/auth/whoami  endpoint, including your session cookie.  curl https://\u2026/api/v1/auth/whoami --cookie \"connect.sid=\u2026  GET /api/v1/auth/whoami  200 OK\n\n{\n  \"orcid\": \"0000-0001-6021-1617\",\n  \"name\": \"o2r\"\n}",
            "title": "Request authentication status"
        },
        {
            "location": "/user/#error-response-for-requests-requiring-authentication",
            "text": "When no session cookie was included, or the included session cookie does not belong to a authenticated session, the service will respond with a  401 Unauthorized  message.  401 Unauthorized\n\n{\n  \"error\": \"not authenticated\"\n}",
            "title": "Error response for requests requiring authentication"
        },
        {
            "location": "/user/#user-levels",
            "text": "Users are authenticated via OAuth and the actions on the website are limited by the  level  assocciated with an account.\nOn registration, each account is assigned a level  0 .\nOnly admin users and the user herself can read the level of a user.  The following is a list of actions and the corresponding required user level.",
            "title": "User levels"
        },
        {
            "location": "/user/#0-users-everybody",
            "text": "Create new jobs  View compendia, jobs, user details",
            "title": "0 Users (everybody)"
        },
        {
            "location": "/user/#100-known-users",
            "text": "Upload new compendium  Create shipments",
            "title": "100 Known users"
        },
        {
            "location": "/user/#500-editors",
            "text": "Edit user levels",
            "title": "500 Editors"
        },
        {
            "location": "/user/#1000-and-above-are-admins",
            "text": "View status pages of microservices",
            "title": "1000 and above are Admins"
        },
        {
            "location": "/user/#edit-user",
            "text": "You can update information of an existing user using the  HTTP  operation  PATCH .",
            "title": "Edit user"
        },
        {
            "location": "/user/#request-for-user-level-change",
            "text": "The request must be made by an authenticated user with an appropriate level. The new level is passed to the API via a query parameter, i.e.  ..?level=<new level value> .\nThe value must be an  int .\nThe response is the full user document with the updated value.  curl --request PATCH --cookie \"connect.sid=<session cookie here>\" \\\n  https://\u2026/api/v1/user/0000-0001-6021-1617?level=42`  200 OK\n\n{\n    \"id\": \"0000-0001-6021-1617\",\n    \"name\": \"o2r\",\n    \"level\": 42,\n    \"lastseen\": \"2016-08-15T12:32:23.972Z\"\n}",
            "title": "Request for user level change"
        },
        {
            "location": "/user/#error-responses-for-user-level-change",
            "text": "401 Unauthorized\n\n{\n  \"error\": \"user is not authenticated\"\n}  401 Unauthorized\n\n{\n  \"error\": \"user level does not allow edit\"\n}  400 Bad Request\n\n{\n  \"error\": \"parameter 'level' could not be parsed as an integer\"\n}",
            "title": "Error responses for user level change"
        }
    ]
}